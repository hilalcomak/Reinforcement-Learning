{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02944396",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9652bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from degree_freedom_queen import *\n",
    "from degree_freedom_king1 import *\n",
    "from degree_freedom_king2 import *\n",
    "from generate_game import *\n",
    "from Chess_env import *\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "\n",
    "size_board = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bceca7c",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You can find the environment in the file Chess_env, which contains the class Chess_env. To define an object, you need to provide the board size considered as input. In our example, size_board=4. \n",
    "Chess_env is composed by the following methods:\n",
    "\n",
    "1. Initialise_game. The method initialises an episode by placing the three pieces considered (Agent's king and queen, enemy's king) in the chess board. The outputs of the method are described below in order.\n",
    "\n",
    "     S $\\;$ A matrix representing the board locations filled with 4 numbers: 0, no piece in that position; 1, location of the \n",
    "     agent's king; 2 location of the queen; 3 location of the enemy king.\n",
    "     \n",
    "     X $\\;$ The features, that is the input to the neural network. See the assignment for more information regarding the            definition of the features adopted. To personalise this, go into the Features method of the class Chess_env() and change        accordingly.\n",
    "     \n",
    "     allowed_a $\\;$ The allowed actions that the agent can make. The agent is moving a king, with a total number of 8                possible actions, and a queen, with a total number of $(board_{size}-1)\\times 8$ actions. The total number of possible actions correspond      to the sum of the two, but not all actions are allowed in a given position (movements to locations outside the borders or      against chess rules). Thus, the variable allowed_a is a vector that is one (zero) for an action that the agent can (can't)      make. Be careful, apply the policy considered on the actions that are allowed only.\n",
    "     \n",
    "\n",
    "2. OneStep. The method performs a one step update of the system. Given as input the action selected by the agent, it updates the chess board by performing that action and the response of the enemy king (which is a random allowed action in the settings considered). The first three outputs are the same as for the Initialise_game method, but the variables are computed for the position reached after the update of the system. The fourth and fifth outputs are:\n",
    "\n",
    "     R $\\;$ The reward. To change this, look at the OneStep method of the class where the rewards are set.\n",
    "     \n",
    "     Done $\\;$ A variable that is 1 if the episode has ended (checkmate or draw).\n",
    "     \n",
    "     \n",
    "3. Features. Given the chessboard position, the method computes the features.\n",
    "\n",
    "This information and a quick analysis of the class should be all you need to get going. The other functions that the class exploits are uncommented and constitute an example on how not to write a python code. You can take a look at them if you want, but it is not necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9593a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE THE ENVIRONMENT\n",
    "\n",
    "env=Chess_Env(size_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc05bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 2 0 0]]\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[3 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 0]\n",
      " [3 0 0 0]\n",
      " [0 0 1 2]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  2\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 2]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  3\n",
      "\n",
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [2 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n"
     ]
    }
   ],
   "source": [
    "## PRINT 5 STEPS OF AN EPISODE CONSIDERING A RANDOM AGENT\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()                       # INTIALISE GAME\n",
    "\n",
    "print(S)                                                  # PRINT CHESS BOARD (SEE THE DESCRIPTION ABOVE)\n",
    "\n",
    "print('check? ',env.check)                                # PRINT VARIABLE THAT TELLS IF ENEMY KING IS IN CHECK (1) OR NOT (0)\n",
    "print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))    # PRINT THE NUMBER OF LOCATIONS THAT THE ENEMY KING CAN MOVE TO\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    a,_=np.where(allowed_a==1)                  # FIND WHAT THE ALLOWED ACTIONS ARE\n",
    "    a_agent=np.random.permutation(a)[0]         # MAKE A RANDOM ACTION\n",
    "\n",
    "    S,X,allowed_a,R,Done=env.OneStep(a_agent)   # UPDATE THE ENVIRONMENT\n",
    "    \n",
    "    \n",
    "    ## PRINT CHESS BOARD AND VARIABLES\n",
    "    print('')\n",
    "    print(S)\n",
    "    print(R,'', Done)\n",
    "    print('check? ',env.check)\n",
    "    print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))\n",
    "    \n",
    "    \n",
    "    # TERMINATE THE EPISODE IF Done=True (DRAW OR CHECKMATE)\n",
    "    if Done:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc16cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Agent, Average reward: 0.198 Number of steps:  6.981\n"
     ]
    }
   ],
   "source": [
    "# PERFORM N_episodes=1000 EPISODES MAKING RANDOM ACTIONS AND COMPUTE THE AVERAGE REWARD AND NUMBER OF MOVES \n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_episodes=1000\n",
    "\n",
    "# VARIABLES WHERE TO SAVE THE FINAL REWARD IN AN EPISODE AND THE NUMBER OF MOVES \n",
    "R_save_random = np.zeros([N_episodes, 1])\n",
    "N_moves_save_random = np.zeros([N_episodes, 1])\n",
    "\n",
    "for n in range(N_episodes):\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()     # INITIALISE GAME\n",
    "    Done=0                                  # SET Done=0 AT THE BEGINNING\n",
    "    i=1                                     # COUNTER FOR THE NUMBER OF ACTIONS (MOVES) IN AN EPISODE\n",
    "    \n",
    "    # UNTIL THE EPISODE IS NOT OVER...(Done=0)\n",
    "    while Done==0:\n",
    "        \n",
    "        # SAME AS THE CELL BEFORE, BUT SAVING THE RESULTS WHEN THE EPISODE TERMINATES \n",
    "        \n",
    "        a,_=np.where(allowed_a==1)\n",
    "        a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "        S,X,allowed_a,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        \n",
    "        if Done:\n",
    "            \n",
    "            R_save_random[n]=np.copy(R)\n",
    "            N_moves_save_random[n]=np.copy(i)\n",
    "\n",
    "            break\n",
    "\n",
    "        i=i+1                               # UPDATE THE COUNTER\n",
    "\n",
    "\n",
    "\n",
    "# AS YOU SEE, THE PERFORMANCE OF A RANDOM AGENT ARE NOT GREAT, SINCE THE MAJORITY OF THE POSITIONS END WITH A DRAW \n",
    "# (THE ENEMY KING IS NOT IN CHECK AND CAN'T MOVE)\n",
    "\n",
    "print('Random_Agent, Average reward:',np.mean(R_save_random),'Number of steps: ',np.mean(N_moves_save_random))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece20429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE THE PARAMETERS OF YOUR NEURAL NETWORK AND...\n",
    "# PLEASE CONSIDER TO USE A MASK OF ONE FOR THE ACTION MADE AND ZERO OTHERWISE IF YOU ARE NOT USING VANILLA GRADIENT DESCENT...\n",
    "# WE SUGGEST A NETWORK WITH ONE HIDDEN LAYER WITH SIZE 200. \n",
    "\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_a=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in=np.shape(X)[0]    ## INPUT SIZE\n",
    "N_h=200                ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "################## INITALISE YOUR NEURAL NETWORK.########################################\n",
    "#Epsilon_Greedy Policy. Filter for the valid ones.\n",
    "#https://keras.io/examples/rl/deep_q_network_breakout/\n",
    "\n",
    "def EpsilonGreedy_Policy(Qvalues, epsilon, allowed_a):\n",
    "    rand_value=np.random.uniform(0,1)\n",
    "    rand_a=rand_value<epsilon\n",
    "    if rand_a==True:\n",
    "        a,_=np.where(allowed_a==1)\n",
    "        return np.random.permutation(a)[0]\n",
    "    else:#\n",
    "        Qvalues = Qvalues.numpy()\n",
    "        #set the qvalues for not allowed actions to negative infinity, so that they won't be picked.\n",
    "        Qvalues[np.transpose(allowed_a)==0] = np.NINF\n",
    "        result = np.argmax(Qvalues)\n",
    "        return result\n",
    "\n",
    "    \n",
    "#Network    \n",
    "def define_q_model(N_in, N_h, N_a):\n",
    "    #input layer\n",
    "    inputs =layers.Input(shape=(N_in,))\n",
    "    #hidden layer 1\n",
    "    # Initializing weights at 0s made it start from a much better state (compared to random one).\n",
    "    layer1 = layers.Dense(N_h, activation=\"relu\", bias_initializer='zeros', kernel_initializer='zeros')(inputs)\n",
    "    #output layer\n",
    "    action = layers.Dense(N_a, activation=\"linear\", bias_initializer='zeros', kernel_initializer='zeros')(layer1)\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "#update our model\n",
    "def update_q_model(model, frozen_model, optimizer, gamma, state_history, state_next_history, action_history, rewards_history, done_history):\n",
    "    # Pick batch_size random states from history to build a training batch.\n",
    "    # \n",
    "    indices = np.random.choice(range(len(state_history)), size = batch_size)\n",
    "    sample_state_history = [state_history[i] for i in indices]\n",
    "    sample_action_history = [action_history[i] for i in indices]\n",
    "    sample_state_next_history = [state_next_history[i] for i in indices]\n",
    "    sample_rewards_history = [rewards_history[i] for i in indices]\n",
    "    # done= 0 or 1 depending on the game's state(finished or not)\n",
    "    sample_done_history = [done_history[i] for i in indices]\n",
    "    \n",
    "    #masks for actions taken\n",
    "    masks = tf.one_hot(np.array(sample_action_history), N_a)\n",
    "    #q values for every action taken in S' from the frozen (target) network!!! *not* model.\n",
    "    future_q_values = frozen_model(np.array(sample_state_next_history))\n",
    "    # Q-learning, pick the max q value\n",
    "    max_future_q_values = tf.reduce_max(future_q_values, axis=1)\n",
    "    \n",
    "    \n",
    "    # Only consider stuff inside tape when computing gradients for the model!\n",
    "    with tf.GradientTape() as tape:\n",
    "        #q values for every action taken\n",
    "        q_values = model(np.array(sample_state_history))\n",
    "        q_values_masked = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "        updated_q_values = np.array(sample_rewards_history) + gamma * max_future_q_values * (1 - np.array(sample_done_history))\n",
    "        loss = loss_function(updated_q_values, q_values_masked)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    #Pass the gradients and variables to optimizer so it can do it's thing.\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2     # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.0001      # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.85        # THE DISCOUNT FACTOR\n",
    "eta = 0.0035        # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 100000 # THE NUMBER OF GAMES TO BE PLAYED \n",
    "\n",
    "# SAVING VARIABLES\n",
    "R_save = np.zeros([N_episodes, 1])\n",
    "N_moves_save = np.zeros([N_episodes, 1])\n",
    "\n",
    "# History buffer(how far I should know betwen past and present) size.\n",
    "H_size = 100000\n",
    "batch_size = 64\n",
    "# How many batches to train when updating model.\n",
    "batches_per_training = 2\n",
    "update_after_actions = 2\n",
    "update_frozen_model_actions = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ba1f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.32085561497326204 Number of steps:  1.427807486631016 Episodes:  374\n",
      "Q_Agent, Average reward: 0.4169014084507042 Number of steps:  1.3957746478873239 Episodes:  710\n",
      "Q_Agent, Average reward: 0.46314831665150136 Number of steps:  1.3939945404913558 Episodes:  1099\n",
      "Q_Agent, Average reward: 0.46615491974877876 Number of steps:  1.4068387997208653 Episodes:  1433\n",
      "Q_Agent, Average reward: 0.4733595064498037 Number of steps:  1.4054963544587773 Episodes:  1783\n",
      "Q_Agent, Average reward: 0.4835216572504708 Number of steps:  1.4067796610169492 Episodes:  2124\n",
      "Q_Agent, Average reward: 0.49299719887955185 Number of steps:  1.4061624649859943 Episodes:  2499\n",
      "Q_Agent, Average reward: 0.4946808510638298 Number of steps:  1.4113475177304964 Episodes:  2820\n",
      "Q_Agent, Average reward: 0.4996839443742099 Number of steps:  1.4102402022756004 Episodes:  3164\n",
      "Q_Agent, Average reward: 0.5073654390934844 Number of steps:  1.406515580736544 Episodes:  3530\n",
      "Q_Agent, Average reward: 0.5164355418592707 Number of steps:  1.4049820236260915 Episodes:  3894\n",
      "Q_Agent, Average reward: 0.5188005711565921 Number of steps:  1.403379343169919 Episodes:  4202\n",
      "Q_Agent, Average reward: 0.5218153913615435 Number of steps:  1.4047358035518527 Episodes:  4561\n",
      "Q_Agent, Average reward: 0.5261550987176877 Number of steps:  1.404437207408915 Episodes:  4913\n",
      "Q_Agent, Average reward: 0.5313575525812619 Number of steps:  1.4036328871892925 Episodes:  5230\n",
      "Q_Agent, Average reward: 0.5340172786177105 Number of steps:  1.4020878329733621 Episodes:  5556\n",
      "Q_Agent, Average reward: 0.5365978501962122 Number of steps:  1.404709094011261 Episodes:  5861\n",
      "Q_Agent, Average reward: 0.539909880914065 Number of steps:  1.4018345671065335 Episodes:  6214\n",
      "Q_Agent, Average reward: 0.5429405438623445 Number of steps:  1.4023659548317713 Episodes:  6509\n",
      "Q_Agent, Average reward: 0.5424750146972369 Number of steps:  1.4031452087007643 Episodes:  6804\n",
      "Q_Agent, Average reward: 0.5418186921133876 Number of steps:  1.4040134717934325 Episodes:  7126\n",
      "Q_Agent, Average reward: 0.5425930886686311 Number of steps:  1.4053040450040182 Episodes:  7466\n",
      "Q_Agent, Average reward: 0.5424811549763638 Number of steps:  1.4044972530982496 Episodes:  7827\n",
      "Q_Agent, Average reward: 0.5441122185308231 Number of steps:  1.4042081949058693 Episodes:  8127\n",
      "Q_Agent, Average reward: 0.544949793266391 Number of steps:  1.4033077377436503 Episodes:  8465\n",
      "Q_Agent, Average reward: 0.5466072652501713 Number of steps:  1.403472698195111 Episodes:  8754\n",
      "Q_Agent, Average reward: 0.5463940193491644 Number of steps:  1.4012752858399296 Episodes:  9096\n",
      "Q_Agent, Average reward: 0.5488721804511278 Number of steps:  1.4018849941755798 Episodes:  9443\n",
      "Q_Agent, Average reward: 0.5493518424007349 Number of steps:  1.3998162702868224 Episodes:  9797\n",
      "Q_Agent, Average reward: 0.5522962962962963 Number of steps:  1.3982222222222223 Episodes:  10125\n",
      "Q_Agent, Average reward: 0.5511826103610074 Number of steps:  1.3996935746433017 Episodes:  10443\n",
      "Q_Agent, Average reward: 0.5522790697674419 Number of steps:  1.4006511627906977 Episodes:  10750\n",
      "Q_Agent, Average reward: 0.5515019511752428 Number of steps:  1.4015790906615846 Episodes:  11019\n",
      "Q_Agent, Average reward: 0.5530202529406563 Number of steps:  1.4031131157689927 Episodes:  11307\n",
      "Q_Agent, Average reward: 0.5534239504473503 Number of steps:  1.4034755677907778 Episodes:  11624\n",
      "Q_Agent, Average reward: 0.5534934497816594 Number of steps:  1.4046019482700705 Episodes:  11908\n",
      "Q_Agent, Average reward: 0.5542385351099485 Number of steps:  1.4040709556118696 Episodes:  12233\n",
      "Q_Agent, Average reward: 0.5559446124462836 Number of steps:  1.4042654782747095 Episodes:  12566\n",
      "Q_Agent, Average reward: 0.5561705776876901 Number of steps:  1.4034458563966632 Episodes:  12827\n",
      "Q_Agent, Average reward: 0.5570208873303857 Number of steps:  1.403948772678762 Episodes:  13118\n",
      "Q_Agent, Average reward: 0.5563769414575866 Number of steps:  1.4042712066905616 Episodes:  13392\n",
      "Q_Agent, Average reward: 0.5575428822753262 Number of steps:  1.4049992669696525 Episodes:  13642\n",
      "Q_Agent, Average reward: 0.5582712155963303 Number of steps:  1.4036697247706422 Episodes:  13952\n",
      "Q_Agent, Average reward: 0.558137901980059 Number of steps:  1.404297149276787 Episodes:  14242\n",
      "Q_Agent, Average reward: 0.5591612237882434 Number of steps:  1.404193881058783 Episodes:  14545\n",
      "Q_Agent, Average reward: 0.5603042132184681 Number of steps:  1.404630502086418 Episodes:  14858\n",
      "Q_Agent, Average reward: 0.5616870319274734 Number of steps:  1.404546051767179 Episodes:  15222\n",
      "Q_Agent, Average reward: 0.5629309789263388 Number of steps:  1.4038151704582071 Episodes:  15517\n",
      "Q_Agent, Average reward: 0.5630050505050505 Number of steps:  1.4029040404040405 Episodes:  15840\n",
      "Q_Agent, Average reward: 0.5641470825323991 Number of steps:  1.4032368078377875 Episodes:  16127\n",
      "Q_Agent, Average reward: 0.5645554202192449 Number of steps:  1.402679658952497 Episodes:  16420\n",
      "Q_Agent, Average reward: 0.5649958028540593 Number of steps:  1.4035855618179638 Episodes:  16678\n",
      "Q_Agent, Average reward: 0.5651302605210421 Number of steps:  1.403571849581516 Episodes:  16966\n",
      "Q_Agent, Average reward: 0.5660694613555981 Number of steps:  1.4033165188148664 Episodes:  17247\n",
      "Q_Agent, Average reward: 0.5661378680666515 Number of steps:  1.4028760556950468 Episodes:  17524\n",
      "Q_Agent, Average reward: 0.5668647012666741 Number of steps:  1.402533348279341 Episodes:  17842\n",
      "Q_Agent, Average reward: 0.5675377050991658 Number of steps:  1.4030164079332634 Episodes:  18101\n",
      "Q_Agent, Average reward: 0.5689420723415828 Number of steps:  1.403154745716617 Episodes:  18385\n",
      "Q_Agent, Average reward: 0.5701519691780822 Number of steps:  1.402504280821918 Episodes:  18688\n",
      "Q_Agent, Average reward: 0.5705531195520102 Number of steps:  1.4025040942469227 Episodes:  18929\n",
      "Q_Agent, Average reward: 0.5714211402413649 Number of steps:  1.402621722846442 Episodes:  19224\n",
      "Q_Agent, Average reward: 0.5716923076923077 Number of steps:  1.4026666666666667 Episodes:  19500\n",
      "Q_Agent, Average reward: 0.5721727695731337 Number of steps:  1.4028929799716772 Episodes:  19772\n",
      "Q_Agent, Average reward: 0.5724117295032914 Number of steps:  1.40295232395771 Episodes:  20052\n",
      "Q_Agent, Average reward: 0.5727147495818163 Number of steps:  1.4033749877004822 Episodes:  20326\n",
      "Q_Agent, Average reward: 0.5730162581897598 Number of steps:  1.403445765590876 Episodes:  20605\n",
      "Q_Agent, Average reward: 0.5737540096710873 Number of steps:  1.4028821755158711 Episodes:  20887\n",
      "Q_Agent, Average reward: 0.5740600435647315 Number of steps:  1.403021119424188 Episodes:  21118\n",
      "Q_Agent, Average reward: 0.5752150336574421 Number of steps:  1.4030946148092744 Episodes:  21392\n",
      "Q_Agent, Average reward: 0.5755183081682597 Number of steps:  1.403056748395438 Episodes:  21657\n",
      "Q_Agent, Average reward: 0.5760069492067846 Number of steps:  1.4031454304393545 Episodes:  21873\n",
      "Q_Agent, Average reward: 0.5765932478786785 Number of steps:  1.4030059577541072 Episodes:  22156\n",
      "Q_Agent, Average reward: 0.5767205212889405 Number of steps:  1.4027938944925467 Episodes:  22406\n",
      "Q_Agent, Average reward: 0.5770775409329626 Number of steps:  1.4024449446136193 Episodes:  22659\n",
      "Q_Agent, Average reward: 0.5772953178132357 Number of steps:  1.402127474060511 Episodes:  22938\n",
      "Q_Agent, Average reward: 0.5771435961546751 Number of steps:  1.4025520541449326 Episodes:  23197\n",
      "Q_Agent, Average reward: 0.5773675009593655 Number of steps:  1.4023365880697565 Episodes:  23453\n",
      "Q_Agent, Average reward: 0.5771016205266711 Number of steps:  1.402177582714382 Episodes:  23696\n",
      "Q_Agent, Average reward: 0.5777962924390752 Number of steps:  1.402499479275151 Episodes:  24005\n",
      "Q_Agent, Average reward: 0.5784358140109551 Number of steps:  1.4025781475227543 Episodes:  24281\n",
      "Q_Agent, Average reward: 0.5781243637252107 Number of steps:  1.4029808201327523 Episodes:  24557\n",
      "Q_Agent, Average reward: 0.5791024295746227 Number of steps:  1.4034223908305754 Episodes:  24778\n",
      "Q_Agent, Average reward: 0.5794523286028384 Number of steps:  1.4034779132520487 Episodes:  25015\n",
      "Q_Agent, Average reward: 0.5800585119000553 Number of steps:  1.403613505179094 Episodes:  25294\n",
      "Q_Agent, Average reward: 0.5798772622444592 Number of steps:  1.4033537896259234 Episodes:  25583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5798940161683364 Number of steps:  1.4033187637798321 Episodes:  25853\n",
      "Q_Agent, Average reward: 0.5795441486305305 Number of steps:  1.4032560812104962 Episodes:  26105\n",
      "Q_Agent, Average reward: 0.5796881520543268 Number of steps:  1.4037330702985698 Episodes:  26359\n",
      "Q_Agent, Average reward: 0.5804662319166479 Number of steps:  1.4030057716812832 Episodes:  26682\n",
      "Q_Agent, Average reward: 0.5803995840760546 Number of steps:  1.4034833630421866 Episodes:  26928\n",
      "Q_Agent, Average reward: 0.5801566003749586 Number of steps:  1.4031540638900122 Episodes:  27203\n",
      "Q_Agent, Average reward: 0.5809763022824069 Number of steps:  1.403552837537767 Episodes:  27471\n",
      "Q_Agent, Average reward: 0.5813332370881005 Number of steps:  1.4032915869635831 Episodes:  27707\n",
      "Q_Agent, Average reward: 0.5819467257016354 Number of steps:  1.4032350210669142 Episodes:  28006\n",
      "Q_Agent, Average reward: 0.5819280941775374 Number of steps:  1.4033301516597732 Episodes:  28287\n",
      "Q_Agent, Average reward: 0.5819118007635994 Number of steps:  1.4031664856912676 Episodes:  28549\n",
      "Q_Agent, Average reward: 0.5818112368914508 Number of steps:  1.403882214042642 Episodes:  28798\n",
      "Q_Agent, Average reward: 0.5822379739866492 Number of steps:  1.403826302387998 Episodes:  29062\n",
      "Q_Agent, Average reward: 0.5821399345335515 Number of steps:  1.4034369885433715 Episodes:  29328\n",
      "Q_Agent, Average reward: 0.5822075114833829 Number of steps:  1.4038097811402324 Episodes:  29608\n",
      "Q_Agent, Average reward: 0.5827872141233115 Number of steps:  1.403370335696135 Episodes:  29908\n",
      "Q_Agent, Average reward: 0.5827994821920537 Number of steps:  1.403458691539151 Episodes:  30127\n",
      "Q_Agent, Average reward: 0.5834703676905874 Number of steps:  1.4033743340130238 Episodes:  30406\n",
      "Q_Agent, Average reward: 0.5835995045955283 Number of steps:  1.4031679812267779 Episodes:  30682\n",
      "Q_Agent, Average reward: 0.5839573918657198 Number of steps:  1.403260167850226 Episodes:  30980\n",
      "Q_Agent, Average reward: 0.58363502386826 Number of steps:  1.403069233973024 Episodes:  31213\n",
      "Q_Agent, Average reward: 0.5839209707134235 Number of steps:  1.403214535290007 Episodes:  31482\n",
      "Q_Agent, Average reward: 0.5841334802455532 Number of steps:  1.403525893278766 Episodes:  31765\n",
      "Q_Agent, Average reward: 0.5843243749414739 Number of steps:  1.4030027780378937 Episodes:  32037\n",
      "Q_Agent, Average reward: 0.5843632871790106 Number of steps:  1.4027816497847163 Episodes:  32283\n",
      "Q_Agent, Average reward: 0.5844008232728166 Number of steps:  1.402666420913587 Episodes:  32553\n",
      "Q_Agent, Average reward: 0.5846318036286019 Number of steps:  1.4021344717182498 Episodes:  32795\n",
      "Q_Agent, Average reward: 0.5849748469604218 Number of steps:  1.4023274137826536 Episodes:  32998\n",
      "Q_Agent, Average reward: 0.5852306950969762 Number of steps:  1.4026623298397782 Episodes:  33204\n",
      "Q_Agent, Average reward: 0.5851366316482596 Number of steps:  1.402621890993984 Episodes:  33411\n",
      "Q_Agent, Average reward: 0.5854725006692644 Number of steps:  1.4024807400577055 Episodes:  33619\n",
      "Q_Agent, Average reward: 0.585761951161898 Number of steps:  1.402279505122981 Episodes:  33867\n",
      "Q_Agent, Average reward: 0.5858413835628505 Number of steps:  1.402119975335467 Episodes:  34057\n",
      "Q_Agent, Average reward: 0.5859313482457931 Number of steps:  1.402023972702616 Episodes:  34289\n",
      "Q_Agent, Average reward: 0.5863466604904317 Number of steps:  1.401928143365855 Episodes:  34541\n",
      "Q_Agent, Average reward: 0.5866467478740519 Number of steps:  1.4018041829464492 Episodes:  34808\n",
      "Q_Agent, Average reward: 0.586986946959527 Number of steps:  1.4017308845791323 Episodes:  35011\n",
      "Q_Agent, Average reward: 0.5875198457700159 Number of steps:  1.4016783851213428 Episodes:  35272\n",
      "Q_Agent, Average reward: 0.5873990034064356 Number of steps:  1.4015089665268432 Episodes:  35521\n",
      "Q_Agent, Average reward: 0.5873322147651007 Number of steps:  1.401258389261745 Episodes:  35760\n",
      "Q_Agent, Average reward: 0.5877743817727147 Number of steps:  1.401083634342873 Episodes:  35990\n",
      "Q_Agent, Average reward: 0.5879008665893912 Number of steps:  1.4008941877794336 Episodes:  36234\n",
      "Q_Agent, Average reward: 0.5881433546299597 Number of steps:  1.4003400148070964 Episodes:  36469\n",
      "Q_Agent, Average reward: 0.5884308329473311 Number of steps:  1.400425056537969 Episodes:  36701\n",
      "Q_Agent, Average reward: 0.5887053087757314 Number of steps:  1.4004062838569882 Episodes:  36920\n",
      "Q_Agent, Average reward: 0.5885565179964491 Number of steps:  1.4003873675149299 Episodes:  37174\n",
      "Q_Agent, Average reward: 0.5891951076216418 Number of steps:  1.4003898947818192 Episodes:  37446\n",
      "Q_Agent, Average reward: 0.5895722279682818 Number of steps:  1.4002970270772006 Episodes:  37707\n",
      "Q_Agent, Average reward: 0.5897577672459189 Number of steps:  1.4000263296471827 Episodes:  37980\n",
      "Q_Agent, Average reward: 0.5901514953295481 Number of steps:  1.4001412909809257 Episodes:  38219\n",
      "Q_Agent, Average reward: 0.590144761805754 Number of steps:  1.4004470202978403 Episodes:  38477\n",
      "Q_Agent, Average reward: 0.5899217398042204 Number of steps:  1.4004442492961748 Episodes:  38717\n",
      "Q_Agent, Average reward: 0.5899094105268561 Number of steps:  1.4004927246131342 Episodes:  38967\n",
      "Q_Agent, Average reward: 0.5900216919739696 Number of steps:  1.4005869592956488 Episodes:  39185\n",
      "Q_Agent, Average reward: 0.5904397026361861 Number of steps:  1.400375510618324 Episodes:  39413\n",
      "Q_Agent, Average reward: 0.5906031810047135 Number of steps:  1.4002722254429965 Episodes:  39673\n",
      "Q_Agent, Average reward: 0.5903387703889585 Number of steps:  1.4003764115432873 Episodes:  39850\n",
      "Q_Agent, Average reward: 0.5906197738561765 Number of steps:  1.4004443002271423 Episodes:  40063\n",
      "Q_Agent, Average reward: 0.5905584083748853 Number of steps:  1.4004862196422814 Episodes:  40311\n",
      "Q_Agent, Average reward: 0.5906691009572683 Number of steps:  1.4007944340274352 Episodes:  40532\n",
      "Q_Agent, Average reward: 0.5907429664696215 Number of steps:  1.4006230223944665 Episodes:  40769\n",
      "Q_Agent, Average reward: 0.5907747184285749 Number of steps:  1.4009430504996214 Episodes:  40931\n",
      "Q_Agent, Average reward: 0.5910305621689909 Number of steps:  1.401170982945435 Episodes:  41162\n",
      "Q_Agent, Average reward: 0.5912528693971245 Number of steps:  1.4012564938987555 Episodes:  41385\n",
      "Q_Agent, Average reward: 0.5917249333237223 Number of steps:  1.4013070953170428 Episodes:  41619\n",
      "Q_Agent, Average reward: 0.5920775993883792 Number of steps:  1.4010177752293578 Episodes:  41856\n",
      "Q_Agent, Average reward: 0.5924447612259444 Number of steps:  1.4013067236873367 Episodes:  42090\n",
      "Q_Agent, Average reward: 0.592733547655068 Number of steps:  1.4012622919818456 Episodes:  42304\n",
      "Q_Agent, Average reward: 0.5929598646489331 Number of steps:  1.4014005075665006 Episodes:  42556\n",
      "Q_Agent, Average reward: 0.592940626460963 Number of steps:  1.4014726507713886 Episodes:  42780\n",
      "Q_Agent, Average reward: 0.5929919137466307 Number of steps:  1.4013151779905195 Episodes:  43036\n",
      "Q_Agent, Average reward: 0.5931055211319708 Number of steps:  1.4012300009248126 Episodes:  43252\n",
      "Q_Agent, Average reward: 0.5931185270425777 Number of steps:  1.401150747986191 Episodes:  43450\n",
      "Q_Agent, Average reward: 0.592725938496113 Number of steps:  1.401219987616667 Episodes:  43607\n",
      "Q_Agent, Average reward: 0.5931083206089474 Number of steps:  1.4012625629572233 Episodes:  43879\n",
      "Q_Agent, Average reward: 0.5931596017327799 Number of steps:  1.4011022657685241 Episodes:  44091\n",
      "Q_Agent, Average reward: 0.5933832821808991 Number of steps:  1.4011103087199857 Episodes:  44312\n",
      "Q_Agent, Average reward: 0.5930423072606891 Number of steps:  1.4015486477387498 Episodes:  44555\n",
      "Q_Agent, Average reward: 0.5934164098441199 Number of steps:  1.4017374603599981 Episodes:  44778\n",
      "Q_Agent, Average reward: 0.5935987925600391 Number of steps:  1.4018733075864518 Episodes:  45054\n",
      "Q_Agent, Average reward: 0.5935016775560656 Number of steps:  1.401885043263288 Episodes:  45304\n",
      "Q_Agent, Average reward: 0.5933576257792607 Number of steps:  1.402076565106682 Episodes:  45556\n",
      "Q_Agent, Average reward: 0.5937397681880688 Number of steps:  1.4019164865867766 Episodes:  45813\n",
      "Q_Agent, Average reward: 0.5938355271732048 Number of steps:  1.4017767930839742 Episodes:  46038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5934244088020405 Number of steps:  1.4016687562146037 Episodes:  46262\n",
      "Q_Agent, Average reward: 0.5936848888411557 Number of steps:  1.4017828375040275 Episodes:  46555\n",
      "Q_Agent, Average reward: 0.5938435228730227 Number of steps:  1.4015604959384351 Episodes:  46780\n",
      "Q_Agent, Average reward: 0.5938722571865963 Number of steps:  1.4015563871406702 Episodes:  47032\n",
      "Q_Agent, Average reward: 0.5939655537218061 Number of steps:  1.4015911302949515 Episodes:  47262\n",
      "Q_Agent, Average reward: 0.5941217340042529 Number of steps:  1.4014990420447606 Episodes:  47497\n",
      "Q_Agent, Average reward: 0.5937074509311046 Number of steps:  1.4013699490982217 Episodes:  47739\n",
      "Q_Agent, Average reward: 0.5934221482098252 Number of steps:  1.401353039134055 Episodes:  48040\n",
      "Q_Agent, Average reward: 0.5935720350390358 Number of steps:  1.4014785976102218 Episodes:  48289\n",
      "Q_Agent, Average reward: 0.5935503812075005 Number of steps:  1.4015660416237379 Episodes:  48530\n",
      "Q_Agent, Average reward: 0.5932255486567898 Number of steps:  1.4015901313497674 Episodes:  48801\n",
      "Q_Agent, Average reward: 0.5930810943042362 Number of steps:  1.4015778529783505 Episodes:  49054\n",
      "Q_Agent, Average reward: 0.5929576893432316 Number of steps:  1.4014644436331183 Episodes:  49302\n",
      "Q_Agent, Average reward: 0.5931735247273241 Number of steps:  1.401524162819298 Episodes:  49601\n",
      "Q_Agent, Average reward: 0.592989425951564 Number of steps:  1.4016131944862458 Episodes:  49839\n",
      "Q_Agent, Average reward: 0.5928706939590614 Number of steps:  1.401497753369945 Episodes:  50075\n",
      "Q_Agent, Average reward: 0.5927412943234218 Number of steps:  1.4013555414215297 Episodes:  50312\n",
      "Q_Agent, Average reward: 0.5929422475557139 Number of steps:  1.401377508609429 Episodes:  50526\n",
      "Q_Agent, Average reward: 0.5928916018509403 Number of steps:  1.4013192871910998 Episodes:  50785\n",
      "Q_Agent, Average reward: 0.5929066624887391 Number of steps:  1.4009439504915593 Episodes:  51062\n",
      "Q_Agent, Average reward: 0.5929572796225164 Number of steps:  1.4009593074268334 Episodes:  51287\n",
      "Q_Agent, Average reward: 0.5933031990222516 Number of steps:  1.40081867033969 Episodes:  51547\n",
      "Q_Agent, Average reward: 0.5933719806763285 Number of steps:  1.400753623188406 Episodes:  51750\n",
      "Q_Agent, Average reward: 0.5934682736481941 Number of steps:  1.40093804663322 Episodes:  52023\n",
      "Q_Agent, Average reward: 0.5936758288033076 Number of steps:  1.401424086976495 Episodes:  52244\n",
      "Q_Agent, Average reward: 0.5936767480418501 Number of steps:  1.4013683227564653 Episodes:  52473\n",
      "Q_Agent, Average reward: 0.5938976490009678 Number of steps:  1.401377582968065 Episodes:  52701\n",
      "Q_Agent, Average reward: 0.5937559022400182 Number of steps:  1.4011823367204321 Episodes:  52946\n",
      "Q_Agent, Average reward: 0.5939187536455491 Number of steps:  1.4010198129715694 Episodes:  53147\n",
      "Q_Agent, Average reward: 0.5939445069366329 Number of steps:  1.4012373453318334 Episodes:  53340\n",
      "Q_Agent, Average reward: 0.5940427755589563 Number of steps:  1.4013101414654174 Episodes:  53582\n",
      "Q_Agent, Average reward: 0.5942239072256913 Number of steps:  1.401074189711567 Episodes:  53808\n",
      "Q_Agent, Average reward: 0.5944045592480202 Number of steps:  1.4009695803419435 Episodes:  54044\n",
      "Q_Agent, Average reward: 0.5944521242281817 Number of steps:  1.4008294166436273 Episodes:  54255\n",
      "Q_Agent, Average reward: 0.5943768467030043 Number of steps:  1.4009249573308373 Episodes:  54489\n",
      "Q_Agent, Average reward: 0.5942349522016487 Number of steps:  1.4009212378219307 Episodes:  54709\n",
      "Q_Agent, Average reward: 0.5944632521568199 Number of steps:  1.4008226857413273 Episodes:  54942\n",
      "Q_Agent, Average reward: 0.594413326807693 Number of steps:  1.4010549785197672 Episodes:  55167\n",
      "Q_Agent, Average reward: 0.5943041860801098 Number of steps:  1.4008018203489 Episodes:  55374\n",
      "Q_Agent, Average reward: 0.5944068528649582 Number of steps:  1.400752231500144 Episodes:  55568\n",
      "Q_Agent, Average reward: 0.5944255242875067 Number of steps:  1.4008424448825954 Episodes:  55790\n",
      "Q_Agent, Average reward: 0.5943020451906761 Number of steps:  1.4009109582923998 Episodes:  55985\n",
      "Q_Agent, Average reward: 0.5942849008932066 Number of steps:  1.4009287925696594 Episodes:  56202\n",
      "Q_Agent, Average reward: 0.5942642552211574 Number of steps:  1.4011124298088675 Episodes:  56453\n",
      "Q_Agent, Average reward: 0.5944667102173414 Number of steps:  1.4011370257243243 Episodes:  56639\n",
      "Q_Agent, Average reward: 0.5945099970105685 Number of steps:  1.4010410255508468 Episodes:  56867\n",
      "Q_Agent, Average reward: 0.5944842570041876 Number of steps:  1.4010302594922293 Episodes:  57073\n",
      "Q_Agent, Average reward: 0.5946096816397732 Number of steps:  1.4009594417793283 Episodes:  57325\n",
      "Q_Agent, Average reward: 0.5948018080667594 Number of steps:  1.4008692628650905 Episodes:  57520\n",
      "Q_Agent, Average reward: 0.5950739598849898 Number of steps:  1.4008036858696782 Episodes:  57734\n",
      "Q_Agent, Average reward: 0.5951674145667932 Number of steps:  1.4008111839834312 Episodes:  57940\n",
      "Q_Agent, Average reward: 0.5951692815854666 Number of steps:  1.400856729975227 Episodes:  58128\n",
      "Q_Agent, Average reward: 0.5951058064958672 Number of steps:  1.4008814349898824 Episodes:  58314\n",
      "Q_Agent, Average reward: 0.5952372817656907 Number of steps:  1.4009703098841777 Episodes:  58538\n",
      "Q_Agent, Average reward: 0.5952052813366682 Number of steps:  1.4009664301635105 Episodes:  58773\n",
      "Q_Agent, Average reward: 0.5950662464843618 Number of steps:  1.4009352444851073 Episodes:  59022\n",
      "Q_Agent, Average reward: 0.5951355459842919 Number of steps:  1.40116544210793 Episodes:  59205\n",
      "Q_Agent, Average reward: 0.5950477216489639 Number of steps:  1.4010975137610047 Episodes:  59407\n",
      "Q_Agent, Average reward: 0.5951921625203402 Number of steps:  1.4009327137608831 Episodes:  59611\n",
      "Q_Agent, Average reward: 0.5951768166321278 Number of steps:  1.4009626311919245 Episodes:  59836\n",
      "Q_Agent, Average reward: 0.595249983356634 Number of steps:  1.4010052593036415 Episodes:  60084\n",
      "Q_Agent, Average reward: 0.5954478342374625 Number of steps:  1.4012508502131753 Episodes:  60279\n",
      "Q_Agent, Average reward: 0.5955390334572491 Number of steps:  1.40122263527468 Episodes:  60525\n",
      "Q_Agent, Average reward: 0.5957702238229151 Number of steps:  1.4011544723469338 Episodes:  60807\n",
      "Q_Agent, Average reward: 0.5960335396809799 Number of steps:  1.4012315351609839 Episodes:  61062\n",
      "Q_Agent, Average reward: 0.5958631273059719 Number of steps:  1.4012309400202436 Episodes:  61254\n",
      "Q_Agent, Average reward: 0.5961525952907506 Number of steps:  1.4012618706907767 Episodes:  61496\n",
      "Q_Agent, Average reward: 0.5962763113120412 Number of steps:  1.401163450164471 Episodes:  61713\n",
      "Q_Agent, Average reward: 0.5964053870748959 Number of steps:  1.4011400704066144 Episodes:  61926\n",
      "Q_Agent, Average reward: 0.5964551098529932 Number of steps:  1.401100138321485 Episodes:  62174\n",
      "Q_Agent, Average reward: 0.5963360100014425 Number of steps:  1.400955265983876 Episodes:  62391\n",
      "Q_Agent, Average reward: 0.5963707229800965 Number of steps:  1.4009137088271941 Episodes:  62602\n",
      "Q_Agent, Average reward: 0.5962827883865008 Number of steps:  1.4008345410820366 Episodes:  62789\n",
      "Q_Agent, Average reward: 0.5962307252998287 Number of steps:  1.400755124056095 Episodes:  63036\n",
      "Q_Agent, Average reward: 0.5963697308920722 Number of steps:  1.4008791069790976 Episodes:  63246\n",
      "Q_Agent, Average reward: 0.5965901928652464 Number of steps:  1.4006838522627 Episodes:  63464\n",
      "Q_Agent, Average reward: 0.5963871494263697 Number of steps:  1.4006936924211748 Episodes:  63717\n",
      "Q_Agent, Average reward: 0.5963885585529198 Number of steps:  1.4007010076985666 Episodes:  63908\n",
      "Q_Agent, Average reward: 0.5963317060997864 Number of steps:  1.400876522607109 Episodes:  64117\n",
      "Q_Agent, Average reward: 0.5965473344304033 Number of steps:  1.4008600614773186 Episodes:  64414\n",
      "Q_Agent, Average reward: 0.5966364452145929 Number of steps:  1.401011851347588 Episodes:  64634\n",
      "Q_Agent, Average reward: 0.596766729398698 Number of steps:  1.4010427914725574 Episodes:  64826\n",
      "Q_Agent, Average reward: 0.5970904393559598 Number of steps:  1.401048795115875 Episodes:  65027\n",
      "Q_Agent, Average reward: 0.5971513116538645 Number of steps:  1.4010701746316483 Episodes:  65223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5971070277535933 Number of steps:  1.4011364157081978 Episodes:  65469\n",
      "Q_Agent, Average reward: 0.5969013484308892 Number of steps:  1.4011657991659818 Episodes:  65706\n",
      "Q_Agent, Average reward: 0.5969441118067029 Number of steps:  1.4010246926679906 Episodes:  65971\n",
      "Q_Agent, Average reward: 0.5970838616192718 Number of steps:  1.401135060073658 Episodes:  66252\n",
      "Q_Agent, Average reward: 0.5971549727827734 Number of steps:  1.401221015909296 Episodes:  66502\n",
      "Q_Agent, Average reward: 0.5972141004303301 Number of steps:  1.4013014859130644 Episodes:  66693\n",
      "Q_Agent, Average reward: 0.597057505601195 Number of steps:  1.4011799850634803 Episodes:  66950\n",
      "Q_Agent, Average reward: 0.5971426445420046 Number of steps:  1.4011905647741647 Episodes:  67195\n",
      "Q_Agent, Average reward: 0.5972584856396866 Number of steps:  1.4013321860906718 Episodes:  67408\n",
      "Q_Agent, Average reward: 0.5970804213885729 Number of steps:  1.401220431140202 Episodes:  67681\n",
      "Q_Agent, Average reward: 0.5971156254143158 Number of steps:  1.4014554453987007 Episodes:  67883\n",
      "Q_Agent, Average reward: 0.5970136105360525 Number of steps:  1.4014594253329222 Episodes:  68109\n",
      "Q_Agent, Average reward: 0.5970140515222483 Number of steps:  1.4014197892271663 Episodes:  68320\n",
      "Q_Agent, Average reward: 0.5970861043052152 Number of steps:  1.40136798506592 Episodes:  68568\n",
      "Q_Agent, Average reward: 0.5971032617389155 Number of steps:  1.4014570942457865 Episodes:  68767\n",
      "Q_Agent, Average reward: 0.5969240581558845 Number of steps:  1.4014524475625842 Episodes:  68987\n",
      "Q_Agent, Average reward: 0.5969288995464131 Number of steps:  1.4011931933088724 Episodes:  69226\n",
      "Q_Agent, Average reward: 0.5968419840515876 Number of steps:  1.4012004490888679 Episodes:  69474\n",
      "Q_Agent, Average reward: 0.5969192375543221 Number of steps:  1.4012305838819328 Episodes:  69723\n",
      "Q_Agent, Average reward: 0.5969538791562389 Number of steps:  1.4012870933142654 Episodes:  69925\n",
      "Q_Agent, Average reward: 0.5972176689425146 Number of steps:  1.401200165343444 Episodes:  70157\n",
      "Q_Agent, Average reward: 0.5971452918619514 Number of steps:  1.4013634426927992 Episodes:  70410\n",
      "Q_Agent, Average reward: 0.5972691899540149 Number of steps:  1.4012875840113195 Episodes:  70675\n",
      "Q_Agent, Average reward: 0.5973853812633093 Number of steps:  1.401274873429325 Episodes:  70909\n",
      "Q_Agent, Average reward: 0.5974548266891654 Number of steps:  1.4013780496379105 Episodes:  71115\n",
      "Q_Agent, Average reward: 0.5975780680607725 Number of steps:  1.401637046588552 Episodes:  71348\n",
      "Q_Agent, Average reward: 0.5975492182369462 Number of steps:  1.4016543475527115 Episodes:  71569\n",
      "Q_Agent, Average reward: 0.5977118809397731 Number of steps:  1.4015495666230038 Episodes:  71762\n",
      "Q_Agent, Average reward: 0.5977833641199428 Number of steps:  1.4016610880404439 Episodes:  72001\n",
      "Q_Agent, Average reward: 0.5978229257551207 Number of steps:  1.401830847424765 Episodes:  72207\n",
      "Q_Agent, Average reward: 0.5979576347202098 Number of steps:  1.4018215690333264 Episodes:  72465\n",
      "Q_Agent, Average reward: 0.5982090044981223 Number of steps:  1.4019973313891907 Episodes:  72697\n",
      "Q_Agent, Average reward: 0.59846719131317 Number of steps:  1.402286873783213 Episodes:  72938\n",
      "Q_Agent, Average reward: 0.5985971341063224 Number of steps:  1.4022232553051848 Episodes:  73136\n",
      "Q_Agent, Average reward: 0.5985665036041806 Number of steps:  1.4022102007167483 Episodes:  73387\n",
      "Q_Agent, Average reward: 0.5988059701492537 Number of steps:  1.4019945725915874 Episodes:  73700\n",
      "Q_Agent, Average reward: 0.5987751128897061 Number of steps:  1.4021036692534408 Episodes:  73966\n",
      "Q_Agent, Average reward: 0.5986446797618086 Number of steps:  1.4021097728558727 Episodes:  74226\n",
      "Q_Agent, Average reward: 0.598565441650548 Number of steps:  1.4019449817322158 Episodes:  74448\n",
      "Q_Agent, Average reward: 0.5986776947991114 Number of steps:  1.401911186059584 Episodes:  74718\n",
      "Q_Agent, Average reward: 0.5989061562062296 Number of steps:  1.4018942173014073 Episodes:  74965\n",
      "Q_Agent, Average reward: 0.598920456811625 Number of steps:  1.40181076086523 Episodes:  75217\n",
      "Q_Agent, Average reward: 0.5989000066264661 Number of steps:  1.4018554105095753 Episodes:  75455\n",
      "Q_Agent, Average reward: 0.598834520395893 Number of steps:  1.4017072558373085 Episodes:  75677\n",
      "Q_Agent, Average reward: 0.598895377193098 Number of steps:  1.4016977973452145 Episodes:  75863\n",
      "Q_Agent, Average reward: 0.5989645611868126 Number of steps:  1.4014427814935022 Episodes:  76103\n",
      "Q_Agent, Average reward: 0.5991484344294511 Number of steps:  1.4013625049128784 Episodes:  76330\n",
      "Q_Agent, Average reward: 0.5990723804546643 Number of steps:  1.4013718317219754 Episodes:  76540\n",
      "Q_Agent, Average reward: 0.5991273200911755 Number of steps:  1.4015890589384565 Episodes:  76775\n",
      "Q_Agent, Average reward: 0.5990879800446915 Number of steps:  1.401613573767084 Episodes:  76972\n",
      "Q_Agent, Average reward: 0.5990284974093264 Number of steps:  1.4014507772020726 Episodes:  77200\n",
      "Q_Agent, Average reward: 0.598909687504037 Number of steps:  1.401464945936519 Episodes:  77409\n",
      "Q_Agent, Average reward: 0.5988814865404688 Number of steps:  1.4015179825522208 Episodes:  77603\n",
      "Q_Agent, Average reward: 0.5990030960547783 Number of steps:  1.4014722318572475 Episodes:  77841\n",
      "Q_Agent, Average reward: 0.5990520719912893 Number of steps:  1.4013194133094216 Episodes:  78065\n",
      "Q_Agent, Average reward: 0.5994921072444904 Number of steps:  1.4015032604673123 Episodes:  78363\n",
      "Q_Agent, Average reward: 0.5993176841998065 Number of steps:  1.4016497785019604 Episodes:  78556\n",
      "Q_Agent, Average reward: 0.5994946545112877 Number of steps:  1.401686177912085 Episodes:  78758\n",
      "Q_Agent, Average reward: 0.5995364800344474 Number of steps:  1.4016159876394676 Episodes:  78961\n",
      "Q_Agent, Average reward: 0.5995679199514857 Number of steps:  1.401682838083687 Episodes:  79152\n",
      "Q_Agent, Average reward: 0.5996672925934794 Number of steps:  1.4017063857137455 Episodes:  79349\n",
      "Q_Agent, Average reward: 0.5995802121562516 Number of steps:  1.401638932180383 Episodes:  79564\n",
      "Q_Agent, Average reward: 0.599741874044558 Number of steps:  1.4016991203668898 Episodes:  79806\n",
      "Q_Agent, Average reward: 0.5997101521701107 Number of steps:  1.4017390869793358 Episodes:  80042\n",
      "Q_Agent, Average reward: 0.5996909772843383 Number of steps:  1.4018790574807172 Episodes:  80253\n",
      "Q_Agent, Average reward: 0.5996893445169307 Number of steps:  1.4017645231438336 Episodes:  80475\n",
      "Q_Agent, Average reward: 0.5996479877043592 Number of steps:  1.4019013621884258 Episodes:  80679\n",
      "Q_Agent, Average reward: 0.5996019629899749 Number of steps:  1.4017454293731535 Episodes:  80897\n",
      "Q_Agent, Average reward: 0.5996055469953775 Number of steps:  1.401848998459168 Episodes:  81125\n",
      "Q_Agent, Average reward: 0.5996263244585393 Number of steps:  1.4018364186149421 Episodes:  81354\n",
      "Q_Agent, Average reward: 0.5997549620191129 Number of steps:  1.4018010291595198 Episodes:  81620\n",
      "Q_Agent, Average reward: 0.5998069238571236 Number of steps:  1.4020749575354685 Episodes:  81833\n",
      "Q_Agent, Average reward: 0.5998000341405126 Number of steps:  1.4021874314141487 Episodes:  82014\n",
      "Q_Agent, Average reward: 0.5998735393183283 Number of steps:  1.4021328080351172 Episodes:  82239\n",
      "Q_Agent, Average reward: 0.599854404270808 Number of steps:  1.4021718029604464 Episodes:  82420\n",
      "Q_Agent, Average reward: 0.5998427387648945 Number of steps:  1.4022016572914777 Episodes:  82665\n",
      "Q_Agent, Average reward: 0.6000217097645697 Number of steps:  1.4023181204168276 Episodes:  82912\n",
      "Q_Agent, Average reward: 0.6000072168296468 Number of steps:  1.4022901406078976 Episodes:  83139\n",
      "Q_Agent, Average reward: 0.5999831961014955 Number of steps:  1.4023213385505438 Episodes:  83314\n",
      "Q_Agent, Average reward: 0.6 Number of steps:  1.4023947793809495 Episodes:  83515\n",
      "Q_Agent, Average reward: 0.6001050407629779 Number of steps:  1.4023538680067322 Episodes:  83777\n",
      "Q_Agent, Average reward: 0.6002381094112745 Number of steps:  1.4024049050538723 Episodes:  83995\n",
      "Q_Agent, Average reward: 0.6003323442136499 Number of steps:  1.4024094955489614 Episodes:  84250\n",
      "Q_Agent, Average reward: 0.6004120439987213 Number of steps:  1.4022993949583813 Episodes:  84457\n",
      "Q_Agent, Average reward: 0.6003662354539547 Number of steps:  1.4021383424892198 Episodes:  84645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.6003112436778628 Number of steps:  1.402270664104408 Episodes:  84821\n",
      "Q_Agent, Average reward: 0.6004115226337449 Number of steps:  1.4024573780129335 Episodes:  85050\n",
      "Q_Agent, Average reward: 0.6005533541231917 Number of steps:  1.402424441370255 Episodes:  85298\n",
      "Q_Agent, Average reward: 0.600549418434742 Number of steps:  1.4023613302939972 Episodes:  85545\n",
      "Q_Agent, Average reward: 0.6007506614912986 Number of steps:  1.4022333344989568 Episodes:  85791\n",
      "Q_Agent, Average reward: 0.6007878041412005 Number of steps:  1.4020706002649252 Episodes:  86062\n",
      "Q_Agent, Average reward: 0.6008555331432148 Number of steps:  1.4021237624910157 Episodes:  86262\n",
      "Q_Agent, Average reward: 0.6008928674693221 Number of steps:  1.4021026334964088 Episodes:  86463\n",
      "Q_Agent, Average reward: 0.6009644781319582 Number of steps:  1.4021043159242723 Episodes:  86679\n",
      "Q_Agent, Average reward: 0.600925243969803 Number of steps:  1.4021473945866323 Episodes:  86896\n",
      "Q_Agent, Average reward: 0.6009892922314164 Number of steps:  1.402143849058336 Episodes:  87133\n",
      "Q_Agent, Average reward: 0.6010233399342956 Number of steps:  1.402124517805428 Episodes:  87361\n",
      "Q_Agent, Average reward: 0.6010912120900821 Number of steps:  1.4021048065837984 Episodes:  87609\n",
      "Q_Agent, Average reward: 0.60109743741533 Number of steps:  1.4019876822895914 Episodes:  87841\n",
      "Q_Agent, Average reward: 0.6012697042656612 Number of steps:  1.4021487302957343 Episodes:  88052\n",
      "Q_Agent, Average reward: 0.6014839988671764 Number of steps:  1.4021636930048145 Episodes:  88275\n",
      "Q_Agent, Average reward: 0.601771911585228 Number of steps:  1.4020928445509198 Episodes:  88492\n",
      "Q_Agent, Average reward: 0.6018230575085632 Number of steps:  1.4020078420767983 Episodes:  88752\n",
      "Q_Agent, Average reward: 0.6018083263984166 Number of steps:  1.4020602325633702 Episodes:  88922\n",
      "Q_Agent, Average reward: 0.6019138648627425 Number of steps:  1.4022033004633214 Episodes:  89139\n",
      "Q_Agent, Average reward: 0.6019504439443306 Number of steps:  1.402091520831234 Episodes:  89313\n",
      "Q_Agent, Average reward: 0.6020242869750763 Number of steps:  1.402198563337169 Episodes:  89513\n",
      "Q_Agent, Average reward: 0.6019886078630269 Number of steps:  1.4023698320161406 Episodes:  89711\n",
      "Q_Agent, Average reward: 0.6021028037383177 Number of steps:  1.402425456163774 Episodes:  89880\n",
      "Q_Agent, Average reward: 0.6020134079204404 Number of steps:  1.4024152015627775 Episodes:  90096\n",
      "Q_Agent, Average reward: 0.60214125175762 Number of steps:  1.402508829618804 Episodes:  90321\n",
      "Q_Agent, Average reward: 0.6023593346146199 Number of steps:  1.4025117635363509 Episodes:  90534\n",
      "Q_Agent, Average reward: 0.6024024685915803 Number of steps:  1.402457571082213 Episodes:  90740\n",
      "Q_Agent, Average reward: 0.6025828433258229 Number of steps:  1.4024179809858768 Episodes:  90985\n",
      "Q_Agent, Average reward: 0.6026952640985997 Number of steps:  1.402403587837319 Episodes:  91197\n",
      "Q_Agent, Average reward: 0.6028938906752411 Number of steps:  1.402552660935757 Episodes:  91434\n",
      "Q_Agent, Average reward: 0.6029859542284648 Number of steps:  1.4026127099499066 Episodes:  91629\n",
      "Q_Agent, Average reward: 0.6030356481783933 Number of steps:  1.4026480259576228 Episodes:  91842\n",
      "Q_Agent, Average reward: 0.603110473956297 Number of steps:  1.402537034623572 Episodes:  92076\n",
      "Q_Agent, Average reward: 0.6032618118768964 Number of steps:  1.4024599046380581 Episodes:  92280\n",
      "Q_Agent, Average reward: 0.6034313142560621 Number of steps:  1.4025037567161436 Episodes:  92501\n",
      "Q_Agent, Average reward: 0.6034361889148934 Number of steps:  1.4024633570249896 Episodes:  92719\n",
      "Q_Agent, Average reward: 0.6034169275624267 Number of steps:  1.402295882688356 Episodes:  92949\n",
      "Q_Agent, Average reward: 0.6034282892900844 Number of steps:  1.4022068136444625 Episodes:  93166\n",
      "Q_Agent, Average reward: 0.6035034745644748 Number of steps:  1.402150054072575 Episodes:  93393\n",
      "Q_Agent, Average reward: 0.6035088844012779 Number of steps:  1.4020578901817482 Episodes:  93591\n",
      "Q_Agent, Average reward: 0.6034988219992964 Number of steps:  1.4021086745626472 Episodes:  93803\n",
      "Q_Agent, Average reward: 0.6035079130258942 Number of steps:  1.4021328451771518 Episodes:  93959\n",
      "Q_Agent, Average reward: 0.6034735500318674 Number of steps:  1.4022200977267898 Episodes:  94140\n",
      "Q_Agent, Average reward: 0.6035736238580724 Number of steps:  1.4023506220988151 Episodes:  94358\n",
      "Q_Agent, Average reward: 0.6035029826120066 Number of steps:  1.40227186191141 Episodes:  94548\n",
      "Q_Agent, Average reward: 0.603619288804474 Number of steps:  1.402363617178432 Episodes:  94770\n",
      "Q_Agent, Average reward: 0.6036365167770397 Number of steps:  1.402290984512692 Episodes:  94981\n",
      "Q_Agent, Average reward: 0.6036903624200544 Number of steps:  1.4021801913443463 Episodes:  95221\n",
      "Q_Agent, Average reward: 0.6037686442098207 Number of steps:  1.4020969498910676 Episodes:  95472\n",
      "Q_Agent, Average reward: 0.603722931965612 Number of steps:  1.4020432252875243 Episodes:  95731\n",
      "Q_Agent, Average reward: 0.6036868760551052 Number of steps:  1.4020341385131614 Episodes:  95962\n",
      "Q_Agent, Average reward: 0.6037412314886984 Number of steps:  1.4020265003897117 Episodes:  96225\n",
      "Q_Agent, Average reward: 0.6037508941808267 Number of steps:  1.4020029650517847 Episodes:  96457\n",
      "Q_Agent, Average reward: 0.6038854234552959 Number of steps:  1.40197995220805 Episodes:  96669\n",
      "Q_Agent, Average reward: 0.6039844007923407 Number of steps:  1.4018446682073291 Episodes:  96928\n",
      "Q_Agent, Average reward: 0.6039229003941424 Number of steps:  1.4019017628353554 Episodes:  97173\n",
      "Q_Agent, Average reward: 0.6040126499096435 Number of steps:  1.401901593560046 Episodes:  97392\n",
      "Q_Agent, Average reward: 0.6041158755198623 Number of steps:  1.4019278441334946 Episodes:  97622\n",
      "Q_Agent, Average reward: 0.6040964003188815 Number of steps:  1.4019235093313709 Episodes:  97842\n",
      "Q_Agent, Average reward: 0.604125456288109 Number of steps:  1.4019515875767279 Episodes:  98074\n",
      "Q_Agent, Average reward: 0.6041647601907493 Number of steps:  1.4019257948733592 Episodes:  98349\n",
      "Q_Agent, Average reward: 0.604272159926937 Number of steps:  1.402049824953067 Episodes:  98545\n",
      "Q_Agent, Average reward: 0.6042373138709776 Number of steps:  1.4019779530109628 Episodes:  98789\n",
      "Q_Agent, Average reward: 0.6041435180508697 Number of steps:  1.4020182225903555 Episodes:  98998\n",
      "Q_Agent, Average reward: 0.6042750030233401 Number of steps:  1.4018825331559641 Episodes:  99228\n",
      "Q_Agent, Average reward: 0.6042925965783942 Number of steps:  1.4017419815543062 Episodes:  99427\n",
      "Q_Agent, Average reward: 0.6044504220573917 Number of steps:  1.4017223554917646 Episodes:  99631\n",
      "Q_Agent, Average reward: 0.604466396826033 Number of steps:  1.4017953753055745 Episodes:  99812\n",
      "Q_Agent, Average reward: 0.6044544008960806 Number of steps:  1.4016961526537388 Episodes:  99991\n",
      "Q_Agent, Average reward: 0.60444 Number of steps:  1.4017\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "# Create a q model\n",
    "q_model = define_q_model(N_in, N_h, N_a)\n",
    "# And a frozen copy\n",
    "frozen_model = define_q_model(N_in, N_h, N_a)\n",
    "frozen_model.set_weights(q_model.get_weights())\n",
    "\n",
    "# Create an Adam optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=eta, clipnorm=1.0)\n",
    "loss_function = keras.losses.Huber()\n",
    "\n",
    "#accumulate history for batch \n",
    "state_history      = []\n",
    "state_next_history = []\n",
    "action_history     = []\n",
    "rewards_history    = []\n",
    "done_history       = []\n",
    "\n",
    "R_save_q = []\n",
    "N_moves_save_q = []\n",
    "N_actions = 0\n",
    "\n",
    "for n in range(N_episodes):\n",
    "\n",
    "    epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "    Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "    i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "    \n",
    "    while Done==0:                           ## START THE EPISODE\n",
    "        ## THIS IS A RANDOM AGENT, CHANGE IT...\n",
    "        #a,_=np.where(allowed_a==1)\n",
    "        #a_agent=np.random.permutation(a)[0]\n",
    "        \n",
    "        #applying my model to the state\n",
    "        Qvalues = q_model(tf.expand_dims(X, 0), training=False)\n",
    "        \n",
    "        a_agent = EpsilonGreedy_Policy(Qvalues, epsilon_f, allowed_a)\n",
    "        S_next,X_next,allowed_a_next,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        # Add new values to history\n",
    "        if (len(state_history) < H_size):\n",
    "            state_history.append(np.copy(X))\n",
    "            state_next_history.append(np.copy(X_next))\n",
    "            action_history.append(a_agent)\n",
    "            rewards_history.append(R)\n",
    "            done_history.append(Done)\n",
    "        # Reuse old history once buffers are full.\n",
    "        else:\n",
    "            state_history[N_actions % H_size]      = np.copy(X)\n",
    "            state_next_history[N_actions % H_size] = np.copy(X_next)\n",
    "            action_history[N_actions % H_size]     = a_agent\n",
    "            rewards_history[N_actions % H_size]    = R\n",
    "            done_history[N_actions % H_size]       = Done\n",
    "        N_actions += 1\n",
    "        # Update model's variables.\n",
    "        if N_actions % update_after_actions == 0 and len(state_history) > batch_size:\n",
    "            for i in range(batches_per_training):\n",
    "                update_q_model(\n",
    "                    q_model,\n",
    "                    frozen_model,\n",
    "                    optimizer, \n",
    "                    gamma, \n",
    "                    state_history, \n",
    "                    state_next_history, \n",
    "                    action_history, \n",
    "                    rewards_history, \n",
    "                    done_history)\n",
    "\n",
    "        # Update frozen model with current model\n",
    "        if N_actions % update_frozen_model_actions == 0:\n",
    "            frozen_model.set_weights(q_model.get_weights())\n",
    "            print('Q_Agent, Average reward:',np.mean(R_save_q),'Number of steps: ',np.mean(N_moves_save_q), 'Episodes: ', n)\n",
    "        ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "        if Done==1:\n",
    "            # Keep a reward and moves history to make pretty graphs.\n",
    "            R_save_q.append(R)\n",
    "            N_moves_save_q.append(i)\n",
    "            break\n",
    "        # IF THE EPISODE IS NOT OVER...\n",
    "        else:\n",
    "            ## ONLY TO PUT SUMETHING\n",
    "            PIPPO=1            \n",
    "        # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "        S=np.copy(S_next)\n",
    "        X=np.copy(X_next)\n",
    "        allowed_a=np.copy(allowed_a_next)\n",
    "        \n",
    "        i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "print('Q_Agent, Average reward:',np.mean(R_save_q),'Number of steps: ',np.mean(N_moves_save_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b288ad57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "R_ma_q = pd.DataFrame({'R': R_save_q}).ewm(com=400).mean()\n",
    "\n",
    "plt.plot(R_ma_q, label=\"Q-Learning - beta = 0.0001\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward per game\")\n",
    "plt.savefig(f\"q_rewards_{N_episodes}_beta_0.0001.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4e403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4181f2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "N_ma_q = pd.DataFrame({'N': N_moves_save_q}).ewm(com=400).mean()\n",
    "plt.plot(N_ma_q, label=\"Q-Learning Steps - beta = 0.0001\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"q_steps_{N_episodes}_beta_0.0001.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
