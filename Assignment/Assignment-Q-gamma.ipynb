{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02944396",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9652bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from degree_freedom_queen import *\n",
    "from degree_freedom_king1 import *\n",
    "from degree_freedom_king2 import *\n",
    "from generate_game import *\n",
    "from Chess_env import *\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "\n",
    "size_board = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bceca7c",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You can find the environment in the file Chess_env, which contains the class Chess_env. To define an object, you need to provide the board size considered as input. In our example, size_board=4. \n",
    "Chess_env is composed by the following methods:\n",
    "\n",
    "1. Initialise_game. The method initialises an episode by placing the three pieces considered (Agent's king and queen, enemy's king) in the chess board. The outputs of the method are described below in order.\n",
    "\n",
    "     S $\\;$ A matrix representing the board locations filled with 4 numbers: 0, no piece in that position; 1, location of the \n",
    "     agent's king; 2 location of the queen; 3 location of the enemy king.\n",
    "     \n",
    "     X $\\;$ The features, that is the input to the neural network. See the assignment for more information regarding the            definition of the features adopted. To personalise this, go into the Features method of the class Chess_env() and change        accordingly.\n",
    "     \n",
    "     allowed_a $\\;$ The allowed actions that the agent can make. The agent is moving a king, with a total number of 8                possible actions, and a queen, with a total number of $(board_{size}-1)\\times 8$ actions. The total number of possible actions correspond      to the sum of the two, but not all actions are allowed in a given position (movements to locations outside the borders or      against chess rules). Thus, the variable allowed_a is a vector that is one (zero) for an action that the agent can (can't)      make. Be careful, apply the policy considered on the actions that are allowed only.\n",
    "     \n",
    "\n",
    "2. OneStep. The method performs a one step update of the system. Given as input the action selected by the agent, it updates the chess board by performing that action and the response of the enemy king (which is a random allowed action in the settings considered). The first three outputs are the same as for the Initialise_game method, but the variables are computed for the position reached after the update of the system. The fourth and fifth outputs are:\n",
    "\n",
    "     R $\\;$ The reward. To change this, look at the OneStep method of the class where the rewards are set.\n",
    "     \n",
    "     Done $\\;$ A variable that is 1 if the episode has ended (checkmate or draw).\n",
    "     \n",
    "     \n",
    "3. Features. Given the chessboard position, the method computes the features.\n",
    "\n",
    "This information and a quick analysis of the class should be all you need to get going. The other functions that the class exploits are uncommented and constitute an example on how not to write a python code. You can take a look at them if you want, but it is not necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9593a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE THE ENVIRONMENT\n",
    "\n",
    "env=Chess_Env(size_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc05bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 2 0 0]]\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[3 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 0]\n",
      " [3 0 0 0]\n",
      " [0 0 1 2]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  2\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 2]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  3\n",
      "\n",
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [2 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n"
     ]
    }
   ],
   "source": [
    "## PRINT 5 STEPS OF AN EPISODE CONSIDERING A RANDOM AGENT\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()                       # INTIALISE GAME\n",
    "\n",
    "print(S)                                                  # PRINT CHESS BOARD (SEE THE DESCRIPTION ABOVE)\n",
    "\n",
    "print('check? ',env.check)                                # PRINT VARIABLE THAT TELLS IF ENEMY KING IS IN CHECK (1) OR NOT (0)\n",
    "print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))    # PRINT THE NUMBER OF LOCATIONS THAT THE ENEMY KING CAN MOVE TO\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    a,_=np.where(allowed_a==1)                  # FIND WHAT THE ALLOWED ACTIONS ARE\n",
    "    a_agent=np.random.permutation(a)[0]         # MAKE A RANDOM ACTION\n",
    "\n",
    "    S,X,allowed_a,R,Done=env.OneStep(a_agent)   # UPDATE THE ENVIRONMENT\n",
    "    \n",
    "    \n",
    "    ## PRINT CHESS BOARD AND VARIABLES\n",
    "    print('')\n",
    "    print(S)\n",
    "    print(R,'', Done)\n",
    "    print('check? ',env.check)\n",
    "    print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))\n",
    "    \n",
    "    \n",
    "    # TERMINATE THE EPISODE IF Done=True (DRAW OR CHECKMATE)\n",
    "    if Done:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc16cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Agent, Average reward: 0.198 Number of steps:  6.981\n"
     ]
    }
   ],
   "source": [
    "# PERFORM N_episodes=1000 EPISODES MAKING RANDOM ACTIONS AND COMPUTE THE AVERAGE REWARD AND NUMBER OF MOVES \n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_episodes=1000\n",
    "\n",
    "# VARIABLES WHERE TO SAVE THE FINAL REWARD IN AN EPISODE AND THE NUMBER OF MOVES \n",
    "R_save_random = np.zeros([N_episodes, 1])\n",
    "N_moves_save_random = np.zeros([N_episodes, 1])\n",
    "\n",
    "for n in range(N_episodes):\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()     # INITIALISE GAME\n",
    "    Done=0                                  # SET Done=0 AT THE BEGINNING\n",
    "    i=1                                     # COUNTER FOR THE NUMBER OF ACTIONS (MOVES) IN AN EPISODE\n",
    "    \n",
    "    # UNTIL THE EPISODE IS NOT OVER...(Done=0)\n",
    "    while Done==0:\n",
    "        \n",
    "        # SAME AS THE CELL BEFORE, BUT SAVING THE RESULTS WHEN THE EPISODE TERMINATES \n",
    "        \n",
    "        a,_=np.where(allowed_a==1)\n",
    "        a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "        S,X,allowed_a,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        \n",
    "        if Done:\n",
    "            \n",
    "            R_save_random[n]=np.copy(R)\n",
    "            N_moves_save_random[n]=np.copy(i)\n",
    "\n",
    "            break\n",
    "\n",
    "        i=i+1                               # UPDATE THE COUNTER\n",
    "\n",
    "\n",
    "\n",
    "# AS YOU SEE, THE PERFORMANCE OF A RANDOM AGENT ARE NOT GREAT, SINCE THE MAJORITY OF THE POSITIONS END WITH A DRAW \n",
    "# (THE ENEMY KING IS NOT IN CHECK AND CAN'T MOVE)\n",
    "\n",
    "print('Random_Agent, Average reward:',np.mean(R_save_random),'Number of steps: ',np.mean(N_moves_save_random))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece20429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE THE PARAMETERS OF YOUR NEURAL NETWORK AND...\n",
    "# PLEASE CONSIDER TO USE A MASK OF ONE FOR THE ACTION MADE AND ZERO OTHERWISE IF YOU ARE NOT USING VANILLA GRADIENT DESCENT...\n",
    "# WE SUGGEST A NETWORK WITH ONE HIDDEN LAYER WITH SIZE 200. \n",
    "\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_a=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in=np.shape(X)[0]    ## INPUT SIZE\n",
    "N_h=200                ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "################## INITALISE YOUR NEURAL NETWORK.########################################\n",
    "#Epsilon_Greedy Policy. Filter for the valid ones.\n",
    "#https://keras.io/examples/rl/deep_q_network_breakout/\n",
    "\n",
    "def EpsilonGreedy_Policy(Qvalues, epsilon, allowed_a):\n",
    "    rand_value=np.random.uniform(0,1)\n",
    "    rand_a=rand_value<epsilon\n",
    "    if rand_a==True:\n",
    "        a,_=np.where(allowed_a==1)\n",
    "        return np.random.permutation(a)[0]\n",
    "    else:#\n",
    "        Qvalues = Qvalues.numpy()\n",
    "        #set the qvalues for not allowed actions to negative infinity, so that they won't be picked.\n",
    "        Qvalues[np.transpose(allowed_a)==0] = np.NINF\n",
    "        result = np.argmax(Qvalues)\n",
    "        return result\n",
    "\n",
    "    \n",
    "#Network    \n",
    "def define_q_model(N_in, N_h, N_a):\n",
    "    #input layer\n",
    "    inputs =layers.Input(shape=(N_in,))\n",
    "    #hidden layer 1\n",
    "    # Initializing weights at 0s made it start from a much better state (compared to random one).\n",
    "    layer1 = layers.Dense(N_h, activation=\"relu\", bias_initializer='zeros', kernel_initializer='zeros')(inputs)\n",
    "    #output layer\n",
    "    action = layers.Dense(N_a, activation=\"linear\", bias_initializer='zeros', kernel_initializer='zeros')(layer1)\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "#update our model\n",
    "def update_q_model(model, frozen_model, optimizer, gamma, state_history, state_next_history, action_history, rewards_history, done_history):\n",
    "    # Pick batch_size random states from history to build a training batch.\n",
    "    # \n",
    "    indices = np.random.choice(range(len(state_history)), size = batch_size)\n",
    "    sample_state_history = [state_history[i] for i in indices]\n",
    "    sample_action_history = [action_history[i] for i in indices]\n",
    "    sample_state_next_history = [state_next_history[i] for i in indices]\n",
    "    sample_rewards_history = [rewards_history[i] for i in indices]\n",
    "    # done= 0 or 1 depending on the game's state(finished or not)\n",
    "    sample_done_history = [done_history[i] for i in indices]\n",
    "    \n",
    "    #masks for actions taken\n",
    "    masks = tf.one_hot(np.array(sample_action_history), N_a)\n",
    "    #q values for every action taken in S' from the frozen (target) network!!! *not* model.\n",
    "    future_q_values = frozen_model(np.array(sample_state_next_history))\n",
    "    # Q-learning, pick the max q value\n",
    "    max_future_q_values = tf.reduce_max(future_q_values, axis=1)\n",
    "    \n",
    "    \n",
    "    # Only consider stuff inside tape when computing gradients for the model!\n",
    "    with tf.GradientTape() as tape:\n",
    "        #q values for every action taken\n",
    "        q_values = model(np.array(sample_state_history))\n",
    "        q_values_masked = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "        updated_q_values = np.array(sample_rewards_history) + gamma * max_future_q_values * (1 - np.array(sample_done_history))\n",
    "        loss = loss_function(updated_q_values, q_values_masked)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    #Pass the gradients and variables to optimizer so it can do it's thing.\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2     # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.00005      # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.6         # THE DISCOUNT FACTOR\n",
    "eta = 0.0035        # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 100000 # THE NUMBER OF GAMES TO BE PLAYED \n",
    "\n",
    "# SAVING VARIABLES\n",
    "R_save = np.zeros([N_episodes, 1])\n",
    "N_moves_save = np.zeros([N_episodes, 1])\n",
    "\n",
    "# History buffer(how far I should know betwen past and present) size.\n",
    "H_size = 100000\n",
    "batch_size = 64\n",
    "# How many batches to train when updating model.\n",
    "batches_per_training = 2\n",
    "update_after_actions = 2\n",
    "update_frozen_model_actions = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ba1f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.28293736501079914 Number of steps:  1.4168466522678185 Episodes:  463\n",
      "Q_Agent, Average reward: 0.3280943025540275 Number of steps:  1.3899803536345776 Episodes:  1018\n",
      "Q_Agent, Average reward: 0.3756063756063756 Number of steps:  1.3825363825363826 Episodes:  1443\n",
      "Q_Agent, Average reward: 0.405982905982906 Number of steps:  1.3808760683760684 Episodes:  1872\n",
      "Q_Agent, Average reward: 0.43535045711798 Number of steps:  1.3822377013495863 Episodes:  2297\n",
      "Q_Agent, Average reward: 0.4500907441016334 Number of steps:  1.3742286751361161 Episodes:  2755\n",
      "Q_Agent, Average reward: 0.45723270440251573 Number of steps:  1.3783018867924528 Episodes:  3180\n",
      "Q_Agent, Average reward: 0.45953436807095344 Number of steps:  1.3794345898004434 Episodes:  3608\n",
      "Q_Agent, Average reward: 0.4679012345679012 Number of steps:  1.3797530864197531 Episodes:  4050\n",
      "Q_Agent, Average reward: 0.4696564033913431 Number of steps:  1.3761713520749665 Episodes:  4482\n",
      "Q_Agent, Average reward: 0.4753930978149888 Number of steps:  1.378394935674903 Episodes:  4897\n",
      "Q_Agent, Average reward: 0.4783180026281209 Number of steps:  1.380514360803454 Episodes:  5327\n",
      "Q_Agent, Average reward: 0.481642596137115 Number of steps:  1.382634417957195 Episodes:  5747\n",
      "Q_Agent, Average reward: 0.48242027800490594 Number of steps:  1.3816843826655765 Episodes:  6115\n",
      "Q_Agent, Average reward: 0.48375834851244687 Number of steps:  1.3816029143897997 Episodes:  6588\n",
      "Q_Agent, Average reward: 0.48569785827224377 Number of steps:  1.3822049734080781 Episodes:  6957\n",
      "Q_Agent, Average reward: 0.487841124020535 Number of steps:  1.3815185085112132 Episodes:  7402\n",
      "Q_Agent, Average reward: 0.4886929858183212 Number of steps:  1.383288616328095 Episodes:  7827\n",
      "Q_Agent, Average reward: 0.48951388047036004 Number of steps:  1.3844102315432174 Episodes:  8249\n",
      "Q_Agent, Average reward: 0.4904986755729587 Number of steps:  1.3862720257975354 Episodes:  8683\n",
      "Q_Agent, Average reward: 0.4919938583022593 Number of steps:  1.3838561087957886 Episodes:  9118\n",
      "Q_Agent, Average reward: 0.4920601755119097 Number of steps:  1.3868575010447137 Episodes:  9572\n",
      "Q_Agent, Average reward: 0.49205079492050796 Number of steps:  1.3862613738626137 Episodes:  10001\n",
      "Q_Agent, Average reward: 0.49079225014387107 Number of steps:  1.385862267408402 Episodes:  10426\n",
      "Q_Agent, Average reward: 0.48901808785529716 Number of steps:  1.3863049095607236 Episodes:  10836\n",
      "Q_Agent, Average reward: 0.4900416039656546 Number of steps:  1.3876250331946534 Episodes:  11297\n",
      "Q_Agent, Average reward: 0.49036165131354487 Number of steps:  1.3899692937563972 Episodes:  11724\n",
      "Q_Agent, Average reward: 0.4908732116428219 Number of steps:  1.3896563065285314 Episodes:  12162\n",
      "Q_Agent, Average reward: 0.4919163100332858 Number of steps:  1.389839911237914 Episodes:  12618\n",
      "Q_Agent, Average reward: 0.4909972299168975 Number of steps:  1.3899661434287474 Episodes:  12996\n",
      "Q_Agent, Average reward: 0.489450533064937 Number of steps:  1.389174681279356 Episodes:  13413\n",
      "Q_Agent, Average reward: 0.4899732136393253 Number of steps:  1.389705350032578 Episodes:  13813\n",
      "Q_Agent, Average reward: 0.4891808346213292 Number of steps:  1.3900519881972742 Episodes:  14234\n",
      "Q_Agent, Average reward: 0.48935734752353666 Number of steps:  1.3900259244098785 Episodes:  14658\n",
      "Q_Agent, Average reward: 0.4901322346999801 Number of steps:  1.3903913881321017 Episodes:  15049\n",
      "Q_Agent, Average reward: 0.4915790152932826 Number of steps:  1.3909788991417693 Episodes:  15497\n",
      "Q_Agent, Average reward: 0.493048128342246 Number of steps:  1.391947153192828 Episodes:  15895\n",
      "Q_Agent, Average reward: 0.4943889127368615 Number of steps:  1.3924081682712945 Episodes:  16307\n",
      "Q_Agent, Average reward: 0.49481445956477427 Number of steps:  1.3923625681913554 Episodes:  16681\n",
      "Q_Agent, Average reward: 0.49524368761009985 Number of steps:  1.39301233118027 Episodes:  17030\n",
      "Q_Agent, Average reward: 0.4953576341127923 Number of steps:  1.3928243924805135 Episodes:  17448\n",
      "Q_Agent, Average reward: 0.4959404221960916 Number of steps:  1.3923511954756704 Episodes:  17859\n",
      "Q_Agent, Average reward: 0.4964632340845534 Number of steps:  1.3928277677249548 Episodes:  18237\n",
      "Q_Agent, Average reward: 0.4966125389826863 Number of steps:  1.3925690934509087 Episodes:  18598\n",
      "Q_Agent, Average reward: 0.49665595871293905 Number of steps:  1.3933329822528833 Episodes:  18989\n",
      "Q_Agent, Average reward: 0.49709994821336095 Number of steps:  1.3926462972553082 Episodes:  19310\n",
      "Q_Agent, Average reward: 0.4972794304602085 Number of steps:  1.3926773455377575 Episodes:  19665\n",
      "Q_Agent, Average reward: 0.49743538668393006 Number of steps:  1.3926099297843733 Episodes:  20081\n",
      "Q_Agent, Average reward: 0.4984595823756663 Number of steps:  1.3928309452784977 Episodes:  20449\n",
      "Q_Agent, Average reward: 0.4983678955453149 Number of steps:  1.3924251152073732 Episodes:  20832\n",
      "Q_Agent, Average reward: 0.4993410524333992 Number of steps:  1.3916501929775016 Episodes:  21246\n",
      "Q_Agent, Average reward: 0.5 Number of steps:  1.3909635776855693 Episodes:  21690\n",
      "Q_Agent, Average reward: 0.5000226788225155 Number of steps:  1.3913457613280718 Episodes:  22047\n",
      "Q_Agent, Average reward: 0.5007153715460968 Number of steps:  1.3919788965393902 Episodes:  22366\n",
      "Q_Agent, Average reward: 0.5006378392645053 Number of steps:  1.391941230809836 Episodes:  22733\n",
      "Q_Agent, Average reward: 0.4999349438348441 Number of steps:  1.391854968122479 Episodes:  23057\n",
      "Q_Agent, Average reward: 0.5001917749840188 Number of steps:  1.3916897506925208 Episodes:  23465\n",
      "Q_Agent, Average reward: 0.5005458973712942 Number of steps:  1.3912824389014866 Episodes:  23814\n",
      "Q_Agent, Average reward: 0.5010157966748207 Number of steps:  1.3912268336166507 Episodes:  24119\n",
      "Q_Agent, Average reward: 0.5014074164728919 Number of steps:  1.3914657528658263 Episodes:  24513\n",
      "Q_Agent, Average reward: 0.5019519459089629 Number of steps:  1.3917978025516158 Episodes:  24847\n",
      "Q_Agent, Average reward: 0.5027144838517932 Number of steps:  1.391163067168615 Episodes:  25235\n",
      "Q_Agent, Average reward: 0.5039821972358867 Number of steps:  1.391934098539861 Episodes:  25614\n",
      "Q_Agent, Average reward: 0.5044268226961275 Number of steps:  1.3921779967664947 Episodes:  25978\n",
      "Q_Agent, Average reward: 0.5044980072119947 Number of steps:  1.392598215980262 Episodes:  26345\n",
      "Q_Agent, Average reward: 0.5051527075135844 Number of steps:  1.3931422147273749 Episodes:  26685\n",
      "Q_Agent, Average reward: 0.505567681550812 Number of steps:  1.3926232843771966 Episodes:  27031\n",
      "Q_Agent, Average reward: 0.5064016049607879 Number of steps:  1.3932518694145541 Episodes:  27415\n",
      "Q_Agent, Average reward: 0.5073603694616828 Number of steps:  1.3932385625631405 Episodes:  27716\n",
      "Q_Agent, Average reward: 0.5085777334851936 Number of steps:  1.3940418564920274 Episodes:  28096\n",
      "Q_Agent, Average reward: 0.5090332805071316 Number of steps:  1.3939425955273816 Episodes:  28395\n",
      "Q_Agent, Average reward: 0.5095523636870729 Number of steps:  1.3938083949239994 Episodes:  28684\n",
      "Q_Agent, Average reward: 0.5102258642060322 Number of steps:  1.3941950144608182 Episodes:  29044\n",
      "Q_Agent, Average reward: 0.5108254628524669 Number of steps:  1.3945582870196733 Episodes:  29329\n",
      "Q_Agent, Average reward: 0.5114758518418658 Number of steps:  1.3944255333490614 Episodes:  29671\n",
      "Q_Agent, Average reward: 0.5127606338615512 Number of steps:  1.3940950792326938 Episodes:  29975\n",
      "Q_Agent, Average reward: 0.5135661473461843 Number of steps:  1.3938803802482176 Episodes:  30296\n",
      "Q_Agent, Average reward: 0.5136785061373726 Number of steps:  1.394620005223296 Episodes:  30632\n",
      "Q_Agent, Average reward: 0.5138076935499499 Number of steps:  1.3947869900842995 Episodes:  30961\n",
      "Q_Agent, Average reward: 0.5142738403503724 Number of steps:  1.3949362232665197 Episodes:  31281\n",
      "Q_Agent, Average reward: 0.5143209798398582 Number of steps:  1.3951957464316234 Episodes:  31597\n",
      "Q_Agent, Average reward: 0.5145667564688929 Number of steps:  1.3957145542259257 Episodes:  31922\n",
      "Q_Agent, Average reward: 0.5149851079672375 Number of steps:  1.3957867957309507 Episodes:  32232\n",
      "Q_Agent, Average reward: 0.5152641277641278 Number of steps:  1.3959152334152334 Episodes:  32560\n",
      "Q_Agent, Average reward: 0.5153256704980843 Number of steps:  1.3959739706866143 Episodes:  32886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5153259591910546 Number of steps:  1.3959432170951505 Episodes:  33179\n",
      "Q_Agent, Average reward: 0.5155820895522388 Number of steps:  1.3958507462686567 Episodes:  33500\n",
      "Q_Agent, Average reward: 0.5161756892378535 Number of steps:  1.3955369266190447 Episodes:  33878\n",
      "Q_Agent, Average reward: 0.5158711566617863 Number of steps:  1.3953440702781845 Episodes:  34150\n",
      "Q_Agent, Average reward: 0.5161570786842486 Number of steps:  1.3955948413273438 Episodes:  34505\n",
      "Q_Agent, Average reward: 0.516754647693367 Number of steps:  1.3953695203121415 Episodes:  34856\n",
      "Q_Agent, Average reward: 0.5172178462763386 Number of steps:  1.3954844029914408 Episodes:  35167\n",
      "Q_Agent, Average reward: 0.5173529991274242 Number of steps:  1.3956146029780168 Episodes:  35527\n",
      "Q_Agent, Average reward: 0.517037532764486 Number of steps:  1.395822876582455 Episodes:  35862\n",
      "Q_Agent, Average reward: 0.5172642395447765 Number of steps:  1.3956135020164633 Episodes:  36202\n",
      "Q_Agent, Average reward: 0.5168708713647452 Number of steps:  1.395745963873585 Episodes:  36483\n",
      "Q_Agent, Average reward: 0.5167838050527801 Number of steps:  1.3961357900735394 Episodes:  36851\n",
      "Q_Agent, Average reward: 0.5163017162532954 Number of steps:  1.3962984881906708 Episodes:  37174\n",
      "Q_Agent, Average reward: 0.5164843958388904 Number of steps:  1.3966124299813283 Episodes:  37490\n",
      "Q_Agent, Average reward: 0.5165806536985577 Number of steps:  1.3969035331480746 Episodes:  37785\n",
      "Q_Agent, Average reward: 0.5170859538784067 Number of steps:  1.3964622641509434 Episodes:  38160\n",
      "Q_Agent, Average reward: 0.5166372049495684 Number of steps:  1.396277425392534 Episodes:  38468\n",
      "Q_Agent, Average reward: 0.5166683868304263 Number of steps:  1.3962225203839405 Episodes:  38756\n",
      "Q_Agent, Average reward: 0.5168245838668374 Number of steps:  1.3958514724711908 Episodes:  39050\n",
      "Q_Agent, Average reward: 0.5170977084497739 Number of steps:  1.3959656521518216 Episodes:  39362\n",
      "Q_Agent, Average reward: 0.5177285318559557 Number of steps:  1.3960967010828507 Episodes:  39710\n",
      "Q_Agent, Average reward: 0.5177760023967644 Number of steps:  1.3965147051480502 Episodes:  40054\n",
      "Q_Agent, Average reward: 0.517882795858721 Number of steps:  1.3964927923911428 Episodes:  40374\n",
      "Q_Agent, Average reward: 0.5179624533123649 Number of steps:  1.3968203263219972 Episodes:  40696\n",
      "Q_Agent, Average reward: 0.5177138955940799 Number of steps:  1.396605954209641 Episodes:  41013\n",
      "Q_Agent, Average reward: 0.5182070798598526 Number of steps:  1.3966171318110427 Episodes:  41385\n",
      "Q_Agent, Average reward: 0.5180743121686776 Number of steps:  1.3970591762815132 Episodes:  41689\n",
      "Q_Agent, Average reward: 0.5183093893693564 Number of steps:  1.3973030281371357 Episodes:  41973\n",
      "Q_Agent, Average reward: 0.5183783528076068 Number of steps:  1.3974170963621741 Episodes:  42278\n",
      "Q_Agent, Average reward: 0.5184559427431655 Number of steps:  1.39741874926669 Episodes:  42615\n",
      "Q_Agent, Average reward: 0.5188367327931452 Number of steps:  1.397434106361181 Episodes:  42948\n",
      "Q_Agent, Average reward: 0.5187358499283833 Number of steps:  1.3976805433627502 Episodes:  43286\n",
      "Q_Agent, Average reward: 0.5186738154156356 Number of steps:  1.3978553753093208 Episodes:  43644\n",
      "Q_Agent, Average reward: 0.5190964718727964 Number of steps:  1.3980801164668684 Episodes:  43961\n",
      "Q_Agent, Average reward: 0.5194547260088471 Number of steps:  1.3979191116728356 Episodes:  44308\n",
      "Q_Agent, Average reward: 0.5192940807596694 Number of steps:  1.397930617455376 Episodes:  44651\n",
      "Q_Agent, Average reward: 0.5192705437562548 Number of steps:  1.3976203713999777 Episodes:  44965\n",
      "Q_Agent, Average reward: 0.5195738955911868 Number of steps:  1.3975651176639245 Episodes:  45341\n",
      "Q_Agent, Average reward: 0.5200507558686474 Number of steps:  1.3975365901682382 Episodes:  45709\n",
      "Q_Agent, Average reward: 0.5200712873008628 Number of steps:  1.3975136380430766 Episodes:  46011\n",
      "Q_Agent, Average reward: 0.5204110269196728 Number of steps:  1.3975347019838957 Episodes:  46323\n",
      "Q_Agent, Average reward: 0.5203440362053064 Number of steps:  1.3977650515839821 Episodes:  46623\n",
      "Q_Agent, Average reward: 0.5204498977505112 Number of steps:  1.3977505112474438 Episodes:  46944\n",
      "Q_Agent, Average reward: 0.5204088110201232 Number of steps:  1.3977866649738675 Episodes:  47259\n",
      "Q_Agent, Average reward: 0.5204511025079953 Number of steps:  1.3979759299781183 Episodes:  47528\n",
      "Q_Agent, Average reward: 0.5206822314654181 Number of steps:  1.3978638463307067 Episodes:  47843\n",
      "Q_Agent, Average reward: 0.5205917799110668 Number of steps:  1.397851473216141 Episodes:  48126\n",
      "Q_Agent, Average reward: 0.5210526315789473 Number of steps:  1.3978328173374612 Episodes:  48450\n",
      "Q_Agent, Average reward: 0.5213806681843351 Number of steps:  1.397998318259193 Episodes:  48759\n",
      "Q_Agent, Average reward: 0.5212952396478644 Number of steps:  1.3983941962830126 Episodes:  49072\n",
      "Q_Agent, Average reward: 0.5212438797394084 Number of steps:  1.39829239671428 Episodes:  49426\n",
      "Q_Agent, Average reward: 0.5212907117008444 Number of steps:  1.3984921592279855 Episodes:  49740\n",
      "Q_Agent, Average reward: 0.5211874551113239 Number of steps:  1.3983520868246748 Episodes:  50124\n",
      "Q_Agent, Average reward: 0.5213067337599303 Number of steps:  1.3982209719278087 Episodes:  50477\n",
      "Q_Agent, Average reward: 0.5213744215811755 Number of steps:  1.3981884414689376 Episodes:  50785\n",
      "Q_Agent, Average reward: 0.5217884747089326 Number of steps:  1.3982976225418255 Episodes:  51105\n",
      "Q_Agent, Average reward: 0.5220942897152637 Number of steps:  1.3982612416368445 Episodes:  51416\n",
      "Q_Agent, Average reward: 0.5221300539474447 Number of steps:  1.3986890190846337 Episodes:  51717\n",
      "Q_Agent, Average reward: 0.5223929325907433 Number of steps:  1.398502016516228 Episodes:  52070\n",
      "Q_Agent, Average reward: 0.5224652618720416 Number of steps:  1.39834325851275 Episodes:  52392\n",
      "Q_Agent, Average reward: 0.5226310895185319 Number of steps:  1.398098419144858 Episodes:  52693\n",
      "Q_Agent, Average reward: 0.5227924528301887 Number of steps:  1.3982830188679245 Episodes:  53000\n",
      "Q_Agent, Average reward: 0.522958322391867 Number of steps:  1.398056795588401 Episodes:  53314\n",
      "Q_Agent, Average reward: 0.5230992952757374 Number of steps:  1.397964129907901 Episodes:  53638\n",
      "Q_Agent, Average reward: 0.5233984215791618 Number of steps:  1.3981066360369039 Episodes:  53978\n",
      "Q_Agent, Average reward: 0.5237305317482259 Number of steps:  1.3981015574601419 Episodes:  54255\n",
      "Q_Agent, Average reward: 0.5240930743862221 Number of steps:  1.3979479662880177 Episodes:  54580\n",
      "Q_Agent, Average reward: 0.5241820768136558 Number of steps:  1.3983295035926615 Episodes:  54834\n",
      "Q_Agent, Average reward: 0.5243519744599031 Number of steps:  1.398138910555243 Episodes:  55129\n",
      "Q_Agent, Average reward: 0.5240920402495762 Number of steps:  1.3984203123309409 Episodes:  55454\n",
      "Q_Agent, Average reward: 0.524304932735426 Number of steps:  1.3983677130044843 Episodes:  55750\n",
      "Q_Agent, Average reward: 0.5244831338411317 Number of steps:  1.3983303305446049 Episodes:  56059\n",
      "Q_Agent, Average reward: 0.5248762837226627 Number of steps:  1.3986236009861828 Episodes:  56379\n",
      "Q_Agent, Average reward: 0.5249762047449501 Number of steps:  1.3986850918320584 Episodes:  56734\n",
      "Q_Agent, Average reward: 0.525176074844949 Number of steps:  1.3986825046427696 Episodes:  57078\n",
      "Q_Agent, Average reward: 0.5249442586399108 Number of steps:  1.3988816889632107 Episodes:  57408\n",
      "Q_Agent, Average reward: 0.5249787875114721 Number of steps:  1.398985263814092 Episodes:  57749\n",
      "Q_Agent, Average reward: 0.5251412040225927 Number of steps:  1.398970243835239 Episodes:  58072\n",
      "Q_Agent, Average reward: 0.525117752847478 Number of steps:  1.3988353172904 Episodes:  58385\n",
      "Q_Agent, Average reward: 0.525250460028624 Number of steps:  1.3987937027192803 Episodes:  58692\n",
      "Q_Agent, Average reward: 0.5253608457003456 Number of steps:  1.3986921461001558 Episodes:  59028\n",
      "Q_Agent, Average reward: 0.525356029325019 Number of steps:  1.3987528440212353 Episodes:  59335\n",
      "Q_Agent, Average reward: 0.5252533713041293 Number of steps:  1.3985760951503476 Episodes:  59695\n",
      "Q_Agent, Average reward: 0.5249670937536447 Number of steps:  1.3986737533114513 Episodes:  60019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5248406588858539 Number of steps:  1.3988411555334823 Episodes:  60405\n",
      "Q_Agent, Average reward: 0.5250283759109079 Number of steps:  1.39890773305259 Episodes:  60791\n",
      "Q_Agent, Average reward: 0.5248433486576248 Number of steps:  1.3992114261407327 Episodes:  61123\n",
      "Q_Agent, Average reward: 0.5251912123677787 Number of steps:  1.3991700569568755 Episodes:  61450\n",
      "Q_Agent, Average reward: 0.5250958381184996 Number of steps:  1.3993012309334714 Episodes:  61823\n",
      "Q_Agent, Average reward: 0.5247683993823984 Number of steps:  1.3991089809572825 Episodes:  62176\n",
      "Q_Agent, Average reward: 0.5249016409173783 Number of steps:  1.3993058887502798 Episodes:  62526\n",
      "Q_Agent, Average reward: 0.5247877380990238 Number of steps:  1.3994180684961999 Episodes:  62894\n",
      "Q_Agent, Average reward: 0.5248292004048583 Number of steps:  1.3992914979757085 Episodes:  63232\n",
      "Q_Agent, Average reward: 0.5247191364823615 Number of steps:  1.399329703873871 Episodes:  63554\n",
      "Q_Agent, Average reward: 0.5245093436003381 Number of steps:  1.3993645725733246 Episodes:  63894\n",
      "Q_Agent, Average reward: 0.5244438212750047 Number of steps:  1.3994360316570076 Episodes:  64188\n",
      "Q_Agent, Average reward: 0.5243976136979933 Number of steps:  1.3994421631672735 Episodes:  64535\n",
      "Q_Agent, Average reward: 0.5243808407611881 Number of steps:  1.3995157758381396 Episodes:  64846\n",
      "Q_Agent, Average reward: 0.5245740598618572 Number of steps:  1.399493476592479 Episodes:  65150\n",
      "Q_Agent, Average reward: 0.5246372384298151 Number of steps:  1.3992821139453184 Episodes:  65470\n",
      "Q_Agent, Average reward: 0.5244436337103247 Number of steps:  1.3994436337103247 Episodes:  65784\n",
      "Q_Agent, Average reward: 0.5243420753946034 Number of steps:  1.3995671847334252 Episodes:  66079\n",
      "Q_Agent, Average reward: 0.5246343225185096 Number of steps:  1.3997471859387227 Episodes:  66452\n",
      "Q_Agent, Average reward: 0.5245147957349946 Number of steps:  1.3995896729363844 Episodes:  66776\n",
      "Q_Agent, Average reward: 0.5247083047357584 Number of steps:  1.3996448927217928 Episodes:  67022\n",
      "Q_Agent, Average reward: 0.5248488270165065 Number of steps:  1.3997801120240094 Episodes:  67307\n",
      "Q_Agent, Average reward: 0.5247182036034437 Number of steps:  1.3997662791041685 Episodes:  67602\n",
      "Q_Agent, Average reward: 0.5247655916510885 Number of steps:  1.399737992551923 Episodes:  67937\n",
      "Q_Agent, Average reward: 0.5248685925123354 Number of steps:  1.3997569510534562 Episodes:  68299\n",
      "Q_Agent, Average reward: 0.5248175288821549 Number of steps:  1.3997610757419034 Episodes:  68641\n",
      "Q_Agent, Average reward: 0.5248096308651824 Number of steps:  1.399782435274494 Episodes:  68945\n",
      "Q_Agent, Average reward: 0.5249902522852976 Number of steps:  1.3998007133883057 Episodes:  69247\n",
      "Q_Agent, Average reward: 0.525000359303813 Number of steps:  1.3997326779631785 Episodes:  69579\n",
      "Q_Agent, Average reward: 0.5250211073110002 Number of steps:  1.3997366952390493 Episodes:  69881\n",
      "Q_Agent, Average reward: 0.5251863146045 Number of steps:  1.399846103424199 Episodes:  70177\n",
      "Q_Agent, Average reward: 0.5250564141865713 Number of steps:  1.39988078511517 Episodes:  70461\n",
      "Q_Agent, Average reward: 0.5250197784810127 Number of steps:  1.399708973779385 Episodes:  70784\n",
      "Q_Agent, Average reward: 0.5254435205897663 Number of steps:  1.3997101816288917 Episodes:  71079\n",
      "Q_Agent, Average reward: 0.525668329316819 Number of steps:  1.3997786246707393 Episodes:  71372\n",
      "Q_Agent, Average reward: 0.5259419480881943 Number of steps:  1.3996650851241976 Episodes:  71660\n",
      "Q_Agent, Average reward: 0.5260136496948974 Number of steps:  1.3998721209846685 Episodes:  71943\n",
      "Q_Agent, Average reward: 0.526196215332613 Number of steps:  1.3996481312165794 Episodes:  72186\n",
      "Q_Agent, Average reward: 0.526248275862069 Number of steps:  1.3997793103448275 Episodes:  72500\n",
      "Q_Agent, Average reward: 0.5263960856000109 Number of steps:  1.3998103275286227 Episodes:  72757\n",
      "Q_Agent, Average reward: 0.5263705142763329 Number of steps:  1.3997373209472863 Episodes:  73093\n",
      "Q_Agent, Average reward: 0.5265940774859977 Number of steps:  1.3998037639170902 Episodes:  73381\n",
      "Q_Agent, Average reward: 0.5267685127398041 Number of steps:  1.3998860337014625 Episodes:  73706\n",
      "Q_Agent, Average reward: 0.5269479686001108 Number of steps:  1.3999567643522084 Episodes:  74013\n",
      "Q_Agent, Average reward: 0.5271762551174316 Number of steps:  1.3998734109028226 Episodes:  74256\n",
      "Q_Agent, Average reward: 0.5275746884348631 Number of steps:  1.3999570717572407 Episodes:  74543\n",
      "Q_Agent, Average reward: 0.5276003100858082 Number of steps:  1.4000775214520569 Episodes:  74818\n",
      "Q_Agent, Average reward: 0.5278509998136166 Number of steps:  1.4001118300183721 Episodes:  75114\n",
      "Q_Agent, Average reward: 0.5283238986623536 Number of steps:  1.400140525778526 Episodes:  75431\n",
      "Q_Agent, Average reward: 0.5285178632726889 Number of steps:  1.399923424256027 Episodes:  75742\n",
      "Q_Agent, Average reward: 0.5289198606271777 Number of steps:  1.3997764775491421 Episodes:  76055\n",
      "Q_Agent, Average reward: 0.5290572761096264 Number of steps:  1.3998585128124508 Episodes:  76332\n",
      "Q_Agent, Average reward: 0.5292137030995107 Number of steps:  1.399973898858075 Episodes:  76625\n",
      "Q_Agent, Average reward: 0.5294446321370098 Number of steps:  1.3998804542737597 Episodes:  76958\n",
      "Q_Agent, Average reward: 0.5298145247925862 Number of steps:  1.3998783344766441 Episodes:  77261\n",
      "Q_Agent, Average reward: 0.5298713353789031 Number of steps:  1.3998917051285358 Episodes:  77566\n",
      "Q_Agent, Average reward: 0.5298296549420621 Number of steps:  1.3999640297011895 Episodes:  77842\n",
      "Q_Agent, Average reward: 0.5299686560481034 Number of steps:  1.4000255868995075 Episodes:  78165\n",
      "Q_Agent, Average reward: 0.5300662758093296 Number of steps:  1.399910782564364 Episodes:  78460\n",
      "Q_Agent, Average reward: 0.5300112962798431 Number of steps:  1.4000406158376382 Episodes:  78787\n",
      "Q_Agent, Average reward: 0.5299123683312047 Number of steps:  1.3998179082206852 Episodes:  79081\n",
      "Q_Agent, Average reward: 0.529997607745867 Number of steps:  1.3998338012918172 Episodes:  79423\n",
      "Q_Agent, Average reward: 0.530163387628685 Number of steps:  1.3998169256040829 Episodes:  79749\n",
      "Q_Agent, Average reward: 0.5301714985198416 Number of steps:  1.3997801621304289 Episodes:  80059\n",
      "Q_Agent, Average reward: 0.5302575721737398 Number of steps:  1.3997535075379386 Episodes:  80327\n",
      "Q_Agent, Average reward: 0.5303757738161698 Number of steps:  1.3997543637649337 Episodes:  80607\n",
      "Q_Agent, Average reward: 0.530409204948525 Number of steps:  1.3997009133266596 Episodes:  80913\n",
      "Q_Agent, Average reward: 0.5303895975964144 Number of steps:  1.3996946264098902 Episodes:  81212\n",
      "Q_Agent, Average reward: 0.5305739284092722 Number of steps:  1.3996392239633824 Episodes:  81491\n",
      "Q_Agent, Average reward: 0.5307020761499524 Number of steps:  1.3997872496515296 Episodes:  81786\n",
      "Q_Agent, Average reward: 0.5308082837211001 Number of steps:  1.3997467645519073 Episodes:  82137\n",
      "Q_Agent, Average reward: 0.530908517579712 Number of steps:  1.3997550119461997 Episodes:  82453\n",
      "Q_Agent, Average reward: 0.5310426511644771 Number of steps:  1.3998259629446104 Episodes:  82741\n",
      "Q_Agent, Average reward: 0.5312492473688013 Number of steps:  1.3998338190313335 Episodes:  83042\n",
      "Q_Agent, Average reward: 0.5314371437143715 Number of steps:  1.3999399939994 Episodes:  83325\n",
      "Q_Agent, Average reward: 0.5313916631780395 Number of steps:  1.4001674540996352 Episodes:  83605\n",
      "Q_Agent, Average reward: 0.5315807035942416 Number of steps:  1.4003122318619505 Episodes:  83912\n",
      "Q_Agent, Average reward: 0.5315997483888579 Number of steps:  1.4002872164923983 Episodes:  84257\n",
      "Q_Agent, Average reward: 0.5317041420118344 Number of steps:  1.4003313609467456 Episodes:  84500\n",
      "Q_Agent, Average reward: 0.5318268130727588 Number of steps:  1.4004623350277754 Episodes:  84787\n",
      "Q_Agent, Average reward: 0.5319354004560521 Number of steps:  1.4004207903335761 Episodes:  85078\n",
      "Q_Agent, Average reward: 0.5318740264455454 Number of steps:  1.4004544230116065 Episodes:  85383\n",
      "Q_Agent, Average reward: 0.5318910593012672 Number of steps:  1.4005110971084507 Episodes:  85698\n",
      "Q_Agent, Average reward: 0.5317401219341927 Number of steps:  1.400404895983618 Episodes:  85948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5317691246536754 Number of steps:  1.4005888967459976 Episodes:  86263\n",
      "Q_Agent, Average reward: 0.5316509837467921 Number of steps:  1.4005733706332508 Episodes:  86506\n",
      "Q_Agent, Average reward: 0.5315787654264084 Number of steps:  1.4006314600785867 Episodes:  86783\n",
      "Q_Agent, Average reward: 0.5312733415304 Number of steps:  1.4005607712903485 Episodes:  87023\n",
      "Q_Agent, Average reward: 0.5313216020529741 Number of steps:  1.4007309137567592 Episodes:  87288\n",
      "Q_Agent, Average reward: 0.5313413408841797 Number of steps:  1.4005982827913774 Episodes:  87584\n",
      "Q_Agent, Average reward: 0.5314875506395376 Number of steps:  1.4004392553143066 Episodes:  87876\n",
      "Q_Agent, Average reward: 0.5313911011276745 Number of steps:  1.4005400131599846 Episodes:  88146\n",
      "Q_Agent, Average reward: 0.5315219602613079 Number of steps:  1.400664571983996 Episodes:  88478\n",
      "Q_Agent, Average reward: 0.5315905121415291 Number of steps:  1.4007549721111048 Episodes:  88745\n",
      "Q_Agent, Average reward: 0.531672861618623 Number of steps:  1.4006580498815286 Episodes:  89051\n",
      "Q_Agent, Average reward: 0.5317098828295489 Number of steps:  1.400684893181284 Episodes:  89357\n",
      "Q_Agent, Average reward: 0.5316865265318873 Number of steps:  1.4007118311242022 Episodes:  89628\n",
      "Q_Agent, Average reward: 0.5315916497058267 Number of steps:  1.400720696673451 Episodes:  89913\n",
      "Q_Agent, Average reward: 0.5316024709705325 Number of steps:  1.4007009216232102 Episodes:  90167\n",
      "Q_Agent, Average reward: 0.5317106616386699 Number of steps:  1.4006214957921859 Episodes:  90427\n",
      "Q_Agent, Average reward: 0.5319721587963423 Number of steps:  1.4007302249136857 Episodes:  90657\n",
      "Q_Agent, Average reward: 0.5321590459006293 Number of steps:  1.4006733265853981 Episodes:  90892\n",
      "Q_Agent, Average reward: 0.5323502000986788 Number of steps:  1.4007784660928677 Episodes:  91205\n",
      "Q_Agent, Average reward: 0.5325673430120693 Number of steps:  1.4007674479622179 Episodes:  91472\n",
      "Q_Agent, Average reward: 0.5325170483017059 Number of steps:  1.4008039390836402 Episodes:  91798\n",
      "Q_Agent, Average reward: 0.5325342837893638 Number of steps:  1.4007454415056615 Episodes:  92026\n",
      "Q_Agent, Average reward: 0.532499187520312 Number of steps:  1.4008341458130213 Episodes:  92310\n",
      "Q_Agent, Average reward: 0.5325275199654651 Number of steps:  1.4007230736024174 Episodes:  92660\n",
      "Q_Agent, Average reward: 0.5326082279025733 Number of steps:  1.4006046131336605 Episodes:  92952\n",
      "Q_Agent, Average reward: 0.5328214312524799 Number of steps:  1.4005919761493668 Episodes:  93247\n",
      "Q_Agent, Average reward: 0.5329177404005517 Number of steps:  1.4006372900204231 Episodes:  93521\n",
      "Q_Agent, Average reward: 0.5330164549407451 Number of steps:  1.4006522295165829 Episodes:  93832\n",
      "Q_Agent, Average reward: 0.533111703540058 Number of steps:  1.4005799194910304 Episodes:  94151\n",
      "Q_Agent, Average reward: 0.5331518053907442 Number of steps:  1.4006505339888116 Episodes:  94384\n",
      "Q_Agent, Average reward: 0.5330573712499604 Number of steps:  1.4006906091933389 Episodes:  94699\n",
      "Q_Agent, Average reward: 0.5330813849441538 Number of steps:  1.4006821555272493 Episodes:  94993\n",
      "Q_Agent, Average reward: 0.5330876563041356 Number of steps:  1.4007475301059351 Episodes:  95247\n",
      "Q_Agent, Average reward: 0.533116427966146 Number of steps:  1.4006611777752205 Episodes:  95587\n",
      "Q_Agent, Average reward: 0.532987776897084 Number of steps:  1.4007342205164575 Episodes:  95884\n",
      "Q_Agent, Average reward: 0.5331856796747461 Number of steps:  1.4008068960497446 Episodes:  96171\n",
      "Q_Agent, Average reward: 0.5333222811671088 Number of steps:  1.4007377320954908 Episodes:  96512\n",
      "Q_Agent, Average reward: 0.533214145464316 Number of steps:  1.400729595105719 Episodes:  96766\n",
      "Q_Agent, Average reward: 0.5331595594523032 Number of steps:  1.4007067720299606 Episodes:  97061\n",
      "Q_Agent, Average reward: 0.5331902923784494 Number of steps:  1.4006447109067017 Episodes:  97408\n",
      "Q_Agent, Average reward: 0.5331334854359993 Number of steps:  1.4006711615391698 Episodes:  97741\n",
      "Q_Agent, Average reward: 0.5331885033555678 Number of steps:  1.4006588744058912 Episodes:  98046\n",
      "Q_Agent, Average reward: 0.5332330735385272 Number of steps:  1.4006361077521823 Episodes:  98411\n",
      "Q_Agent, Average reward: 0.5332104442238742 Number of steps:  1.4005307189012903 Episodes:  98734\n",
      "Q_Agent, Average reward: 0.5333636088404481 Number of steps:  1.4004440407710161 Episodes:  99090\n",
      "Q_Agent, Average reward: 0.5332274345002312 Number of steps:  1.4003378038726801 Episodes:  99466\n",
      "Q_Agent, Average reward: 0.5331596091205212 Number of steps:  1.400501127536958 Episodes:  99775\n",
      "Q_Agent, Average reward: 0.53316 Number of steps:  1.40045\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "# Create a q model\n",
    "q_model = define_q_model(N_in, N_h, N_a)\n",
    "# And a frozen copy\n",
    "frozen_model = define_q_model(N_in, N_h, N_a)\n",
    "frozen_model.set_weights(q_model.get_weights())\n",
    "\n",
    "# Create an Adam optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=eta, clipnorm=1.0)\n",
    "loss_function = keras.losses.Huber()\n",
    "\n",
    "#accumulate history for batch \n",
    "state_history      = []\n",
    "state_next_history = []\n",
    "action_history     = []\n",
    "rewards_history    = []\n",
    "done_history       = []\n",
    "\n",
    "R_save_q = []\n",
    "N_moves_save_q = []\n",
    "N_actions = 0\n",
    "\n",
    "for n in range(N_episodes):\n",
    "\n",
    "    epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "    Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "    i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "    \n",
    "    while Done==0:                           ## START THE EPISODE\n",
    "        ## THIS IS A RANDOM AGENT, CHANGE IT...\n",
    "        #a,_=np.where(allowed_a==1)\n",
    "        #a_agent=np.random.permutation(a)[0]\n",
    "        \n",
    "        #applying my model to the state\n",
    "        Qvalues = q_model(tf.expand_dims(X, 0), training=False)\n",
    "        \n",
    "        a_agent = EpsilonGreedy_Policy(Qvalues, epsilon_f, allowed_a)\n",
    "        S_next,X_next,allowed_a_next,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        # Add new values to history\n",
    "        if (len(state_history) < H_size):\n",
    "            state_history.append(np.copy(X))\n",
    "            state_next_history.append(np.copy(X_next))\n",
    "            action_history.append(a_agent)\n",
    "            rewards_history.append(R)\n",
    "            done_history.append(Done)\n",
    "        # Reuse old history once buffers are full.\n",
    "        else:\n",
    "            state_history[N_actions % H_size]      = np.copy(X)\n",
    "            state_next_history[N_actions % H_size] = np.copy(X_next)\n",
    "            action_history[N_actions % H_size]     = a_agent\n",
    "            rewards_history[N_actions % H_size]    = R\n",
    "            done_history[N_actions % H_size]       = Done\n",
    "        N_actions += 1\n",
    "        # Update model's variables.\n",
    "        if N_actions % update_after_actions == 0 and len(state_history) > batch_size:\n",
    "            for i in range(batches_per_training):\n",
    "                update_q_model(\n",
    "                    q_model,\n",
    "                    frozen_model,\n",
    "                    optimizer, \n",
    "                    gamma, \n",
    "                    state_history, \n",
    "                    state_next_history, \n",
    "                    action_history, \n",
    "                    rewards_history, \n",
    "                    done_history)\n",
    "\n",
    "        # Update frozen model with current model\n",
    "        if N_actions % update_frozen_model_actions == 0:\n",
    "            frozen_model.set_weights(q_model.get_weights())\n",
    "            print('Q_Agent, Average reward:',np.mean(R_save_q),'Number of steps: ',np.mean(N_moves_save_q), 'Episodes: ', n)\n",
    "        ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "        if Done==1:\n",
    "            # Keep a reward and moves history to make pretty graphs.\n",
    "            R_save_q.append(R)\n",
    "            N_moves_save_q.append(i)\n",
    "            break\n",
    "        # IF THE EPISODE IS NOT OVER...\n",
    "        else:\n",
    "            ## ONLY TO PUT SUMETHING0.53\n",
    "            PIPPO=1            \n",
    "        # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "        S=np.copy(S_next)\n",
    "        X=np.copy(X_next)\n",
    "        allowed_a=np.copy(allowed_a_next)\n",
    "        \n",
    "        i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "print('Q_Agent, Average reward:',np.mean(R_save_q),'Number of steps: ',np.mean(N_moves_save_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b288ad57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "R_ma_q = pd.DataFrame({'R': R_save_q}).ewm(com=400).mean()\n",
    "\n",
    "plt.plot(R_ma_q, label=\"Q-Learning - gamma=0.6\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward per game\")\n",
    "plt.savefig(f\"q_rewards_{N_episodes}_gamma_06.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01027921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee820dc7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4181f2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6HElEQVR4nO3dd3gUVfcH8O9JCIQWWiiBACEQgYSEAIl0pIN0AUX0pYjSBAvva0GpYgPlJ3YRUREELCBFYkHpHQKEFkoEAgaRhFBCC6Tc3x87s5nZnd2d3exkk+z5PE+e7M7Mzt5JdufMvffcOySEAGOMMSbz8XQBGGOMFS4cGBhjjKlwYGCMMabCgYExxpgKBwbGGGMqJTxdAGcFBgaKkJAQTxeDMcaKlP37918WQlTVs22RCwwhISGIj4/3dDEYY6xIIaJzerflpiTGGGMqHBgYY4ypcGBgjDGmUuT6GBizJysrCykpKcjMzPR0URjzCH9/fwQHB8PPz8/lfXBgYMVKSkoKypcvj5CQEBCRp4vDWIESQiA9PR0pKSmoV6+ey/vhpiRWrGRmZqJKlSocFJhXIiJUqVIl3zVmDgys2OGgwLyZOz7/XhUYVh+8gFt3sz1dDMYYK9S8JjDsP3cVz3+fgOlrjnm6KKyYS0lJQf/+/REWFobQ0FBMnDgRd+/e1dx20aJFmDhxYoGVbe3atZg9e7Zb9rV79260bNkS0dHRaNy4MWbOnAkA2Lx5M3bu3OmW9/AmZ8+eRcuWLREWFoYhQ4bg3r17mtudP38e3bt3R+PGjREeHo7k5GS3l8VrAsONzCwAQNpN7S8oY+4ghMDAgQMxYMAAJCUlISkpCXfu3MFLL71UYGXIycmxua5fv36YPHmyW95nxIgRWLBgARISEnD06FE88sgjADgwuOrll1/GpEmTkJSUhEqVKuHLL7/U3G748OF48cUXcfz4cezduxfVqlVze1m8JjDIN6rj1mdmpI0bN8Lf3x9PPPEEAMDX1xfz5s3D4sWLcfPmTd37+fbbb3H//fcjOjoaY8eONZ/sx48fj5iYGERERGDGjBnm7UNCQjBr1iy0a9cOP/74I0JCQjBjxgw0b94ckZGROHHiBAB1DWXkyJF49tln0aZNG4SGhmLFihUAgNzcXDz99NOIiIhAnz590KtXL/M6pdTUVAQFBZmPU756nT9/PubNm4fo6Ghs27YNaWlpGDRoEGJjYxEbG4sdO3YAAGbOnIlhw4ahc+fOCAsLwxdffAEAuHjxIjp06IDo6Gg0adIE27Ztc+p/8Prrr6NRo0bo1q0bhg4dirlz5wIAvvjiC8TGxqJp06YYNGgQbt++bf47jB8/Hp06dUJoaCi2bNmCUaNGoXHjxhg5cqR5v+XKlcPLL7+MFi1aoGvXrti7dy86duyI0NBQrF27FgCQnJyM9u3bo3nz5mjevLnuACmEwMaNGzF48GAApqC7evVqq+0SExORnZ2Nbt26mctUpkwZp/4+enhNumquFBl8ODJ4jdd+PobEfzLcus/wmgGY0TfC5vpjx46hRYsWqmUBAQEICQnBX3/9hejoaIfvcfz4cXz//ffYsWMH/Pz88PTTT2Pp0qUYPnw43nzzTVSuXBk5OTno0qULDh8+jKioKACm/PXt27cDACZPnozAwEAcOHAAn376KebOnYuFCxdavdfFixexfft2nDhxAv369cPgwYPx008/ITk5GUeOHEFqaioaN26MUaNGWb120qRJaNiwITp27IiePXtixIgRCAkJwbhx41CuXDm88MILAIDHHnsMkyZNQrt27XD+/Hn06NEDx48fBwAcPnwYu3fvxq1bt9CsWTP07t0by5cvR48ePTBlyhTk5OSYT+B6xMfHY+XKlTh48CCys7PRvHlz8/9j4MCBGD16NABg6tSp+PLLL/HMM88AAK5evYqNGzdi7dq16Nu3L3bs2IGFCxciNjYWCQkJiI6Oxq1bt9CxY0fMmTMHDz30EKZOnYo//vgDiYmJGDFiBPr164dq1arhjz/+gL+/P5KSkjB06FDEx8fjxo0baN++vWaZly1bhmrVqqFixYooUcJ0Sg4ODsaFCxestj116hQqVqyIgQMH4uzZs+jatStmz54NX19f3X8jPbwoMJh++3JkYAYSQmhmhThzb/UNGzZg//79iI2NBQDcuXPH3Fzwww8/YMGCBcjOzsbFixeRmJhoDgxDhgxR7WfgwIEAgBYtWuCnn37SfK8BAwbAx8cH4eHhuHTpEgBg+/btePjhh+Hj44MaNWqgU6dOmq+dPn06Hn/8caxfvx7Lli3D8uXLsXnzZqvt/vzzTyQmJpqfZ2Rk4MaNGwCA/v37o3Tp0ihdujQ6deqEvXv3IjY2FqNGjUJWVhYGDBigK5jKtm/fbt4nAPTt29e87ujRo5g6dSquXbuGmzdvokePHuZ1ffv2BREhMjIS1atXR2RkJAAgIiICycnJiI6ORsmSJdGzZ08AQGRkJEqVKgU/Pz9ERkaa2/mzsrIwceJEJCQkwNfXF6dOnQIAlC9fHgkJCTbLnZaWZrVM63OUnZ2Nbdu24eDBg6hTpw6GDBmCRYsW4cknn9T9N9LDsMBARF8B6AMgVQjRRGN9RwBrAJyVFv0khJhlVHnkGgOnMnoPe1f2RomIiMDKlStVyzIyMnDp0iU0bNgQn3zyibnJ5JdfftHchxACI0aMwNtvv61afvbsWcydOxf79u1DpUqVMHLkSFW+etmyZVXblypVCoCpmSc7WzsbT95Gfl/lbz3q16+P8ePHY/To0ahatSrS09OttsnNzcWuXbvMJ2sly+8jEaFDhw7YunUr4uLiMGzYMLz44osYPny4eZs9e/Zg7NixAIBZs2ahX79+VsegZeTIkVi9ejWaNm2KRYsWqYKY/Hfw8fFR/U18fHzMfzs/Pz9zeZXbKbeZN28eqlevjkOHDiE3Nxf+/v4A4LDG0LhxY1y7dg3Z2dkoUaIEUlJSULNmTattg4OD0axZM4SGhgIwBfbdu3e7PTAY2cewCEBPB9tsE0JESz+GBQUA2J50GQDwR+IlI9+GebkuXbrg9u3bWLx4MQBTR/D//vc/TJw4EaVLl8aECROQkJCAhIQEzS++vI8VK1YgNTUVAHDlyhWcO3cOGRkZKFu2LCpUqIBLly7h119/NeQY2rVrh5UrVyI3NxeXLl3SrAUAQFxcnPlEnJSUBF9fX1SsWBHly5c31wgAoHv37vj444/Nz5VXzmvWrEFmZibS09OxefNmxMbG4ty5c6hWrRpGjx6NJ598EgcOHFC9b8uWLc1/Q2VQkMv+888/IzMzEzdv3kRcXJx53Y0bNxAUFISsrCwsXbrU1T+PXdevX0dQUBB8fHywZMkSc9+QXGPQ+gkPDwcRoVOnTua+nG+++Qb9+/e32n9sbCyuXr1qrmFs3LgR4eHhbj8OwwKDEGIrgCtG7d9Zhy9c93QRmBcgIqxatQorVqxAWFgYqlSpAh8fH0yZMsXmaxYtWoTg4GDzT0BAAN544w10794dUVFR6NatGy5evIimTZuiWbNmiIiIwKhRo9C2bVtDjmHQoEEIDg5GkyZNMHbsWLRs2RIVKlSw2m7JkiVo2LAhoqOjMWzYMCxduhS+vr7o27cvVq1aZe58/vDDDxEfH4+oqCiEh4dj/vz55n3cf//96N27N1q1aoVp06ahZs2a2Lx5M6Kjo9GsWTOsXLkSzz33nO6yx8bGol+/fmjatCkGDhyImJgYc9lff/11tGzZEt26dUOjRo3y/4fS8PTTT+Obb75Bq1atcOrUKatanD1z5szBe++9hwYNGiA9Pd1cC4iPj8dTTz0FwFT7mzt3Lrp06YLIyEgIIcz9Jm4lhDDsB0AIgKM21nUEkA7gEIBfAUTY2c8YAPEA4uvUqSNc0e+jbaLuy+tE3ZfXufR6VjQkJiZ6uggqO3bsEHXq1BHx8fGeLopTbty4IYQQ4vLlyyI0NFRcvHjR7e8xY8YM8e6777p9v3LZb926JVq0aCH279/v9vco7LS+BwDihc5ztyc7nw8AqCuEuElEvQCsBhCmtaEQYgGABQAQExOjvwFUIdelVzGWP23atMG5c7pvnFVo9OnTB9euXcO9e/cwbdo01KhRw9NF0m3MmDFITExEZmYmRowYgebNm3u6SEWOxwKDECJD8fgXIvqUiAKFEJcNeT9wZGBML1v9Cu4kj5R2t2XLlhmyX2/isQFuRFSDpC5+IrpfKot1SoObhFUrb9SuWSEjnMiqYay4ccfn38h01eUw9SMEElEKgBkA/ABACDEfwGAA44koG8AdAI8KA7/Rl3kqDK/g7++P9PR0nnqbeSUh3Y9BTpN1lWGBQQgx1MH6jwF8bG8bd8rKyS2ot2IeFBwcjJSUFM0BQ4x5A/kObvnhNSOfS/h4zbRQXs3Pzy9fd65ijHnRJHolfLlZgTHG9PCawODn6zWHyhhj+eI1Z0s/rjEwxpguXhMYuI+BMcb08ZqzJc+2zRhj+nhNYOCcdsYY08d7AoOnC8AYY0WE9wQGrjEw5rVOXbrBU6U4wWsGuBW2Poazl28huFJpTqNlzGAhk0036+kdGYRPHueZVvXwmrNSYaowxB2+iE5zNyNsijF34GJq2Tm5ePCDbdh4gu/e583ijlz0dBGKDO8JDIWol+GDDac8XQSvcuXWPRy/mIGXVhzxdFEYKxK8JjAUpmEMIVX03+6P5Z98kyYjmhP3nElH4j8ZjjdkHpHLd+hySSE6XRrL38/X00Uwu3Yny9NF8Cq5UqejrwGRYciC3ej14Ta37zc/tp5Kw99Xbnu6GIVCVi7PquwKrwkMhakp6XTqTZdeN3/LafT/eLubS+O6v6/cRsjkOPzl4vG4atSifWj99gbd28uBofB8AoyTfvMuhn+1F+3f2eTpohQKOVxjcInXBIbCdGvPWf2buPS62b+ewKGU64WmeiyffMYside1/YHzVzF2SXy+0wY3nkjFxeuZyNZ5j43sHCkwWGQgLNtzHiGT47DhuHGd0vuSryDtRsHdJGr2rycK7L2Kgp8OXPB0EYok7wkMheNcCiD/QaqwVY/PpN2yue7L7Wfx7/VMAMDAT3fi92OX8Ofx1IIqGgDgyIXrAIAL1+6ogtKrq0yd0Z9tPm3Yez88f5fDWt6RlOtYe+gft7zfj/tT3LIfI8z+9YQ5dbSgTF19NF+vv3k3G48u2IWzl21/xosjLwoMhScyzFx7LF+vX7bnvJtK4pxrt+8haubvur8kZ9Ju4vV1iejwziZkZOb1q4xerK+GoeXm3Wzz4xuZ2Xa2zPPM8oPmx5O+T7BaH3/uqsN9yM1myYpjd/SZktf/IwVGW/p+vB3PKsqoZf2xf3H7nr7j1SpH3OGLumtYRpm/5bS5PEXFxhOp2H3mCp77zv7/p7jxnsDg6QIoXL55L1+vn/ObqbmgIG9XejrtJl77OREZmdnoNHezrtdcvW0KBvdychE1c71byvHRxiTz4/0aJ/Q1CRc0T/6y1QnaV+aOmue6vrcFANBRcezKlwghrE54+Wnf/vvKbdy5lwMA+O3ovxizZL/dq9/cXIEf9v2tuW704v2YsOwAXvs50Wrdl9vP4r4CHk/jqZbQ9mGBGPDJDjz2xW7V8j8SL+FnGzW2b3YmAwAOp1w3uniFivcEBg98GIUQhpy8M7NykXz5FsKm/Iolu5Jd2sf1O1lOXYF2+b8tWHUwr732081/OXzNxet3bK5z9WT0+ZYz5sdXb1sH2Oe+S8Cqgxew5VQafjv6r+79Zjs4W5UqYf1VUf5v673yC+YrygYAt+7m6H5/pet3stD+nU1oPP03AMC4b/cDAI5dsJ0Wu/bQP3hp5WHNdX9KfSg7/rpste71dYm4l5MLIQRSMzIxY81RhEyOw9c7zrpUdj3kgHkpIxMLt50psBrEtqTLSPj7GnaeTlddVIxeHK+qVSppXXy4S1ZOLjafLNhmVb28JzAUUJ1h6Z5z5oyZz7eeQdiUX3H9tvvTUx/+fBcAYNoa15qlmr62HuHTf9e1rdYX953fTloty8zKwZVbeSdre1fM93QEzLWH/kGPeVshhMDd7Byr9um37XS0jvhqL8Z9ux+Xb+rr+HV0dV+2lPXsMU9+s0/1XK7JyT7RETyVQibHWXWGK8t/8tINm6+dtsa6NmH5f5P73lNvZCJkchxOp+Vlk2XnCry44jC+2XUOADRrF67IzTX975RO/ms6jpZvbcAbccdVTZPTVh/FZCnA5eYKzFx7TNV8p9flm3excNsZm+u/0hn46lQuY368bM953LrrWnOelhd/PISRX+/DTo2A7WneExgKqMYwZdVRXLyeiZt3s80ZInvOprv9fQoy08XR1bTskc93ofnrf5if382yf/J31Hzz7PKDOHnpBrJzBRpO/c1qfVa24+Dy9LcHrJZpBWpbHfrPLD+IIZ/vQpmS1uNgdvxl///q6tVgjQr+5sdv/XLc4fYfb0zS7G/5/Zg620rOypqyyhRElP0a97Jz8fdV7bEPQgjsPH3ZpSv7575PsPrfHftH3Syj3OuS3efwndQktvtMOhbtTFY13+k1cdkBvBFn+28nByclOTArL0DOK8aDvLrqCN608/8QQjisYTw8f6d5/3Kz5pLd5+y+xhO8JzAoHqdm2O8MdMWpSzdwT3GiekpxNZnfjJNHPt+lK5sjNcN0JfjBn0kOt5WdsnMVKuvx/laH2yT8fc3cDrsmwdTkdMtBU9XSvfo60RP+vqa5PKx6OYev3Zt8xWpZ01nr8bxFZ+L121nmNv2D569i12nTSf/nQ/9gz9krKKdRYyjhYMBceX8/h+XTojz/WqZbnkmzHjMyd732FCtyE5RMvnL/I9EUMI4pRmyfvXzLZnZZizf+xGNf7MEKFzKetNruP918GplZebUIPxvTEtx1ohn2+p0svPDjIYRMjkPSpRsO+/H+Sr2JhdvO2E2EuKlRO7gmNV/evJuNU5du4IUfD2GKlN22aGcyBn22E1tOpVm97l52Lv5v/UnsSzYFDuVF0aZC2JzkNYEhsGxJ8+PX44671DH4wZ9JGPDJDqvlF67dQfd5WzFrXV6zzu4zeSekR2PrOPU+lh2Ze89an9y0yAPN5v2pfy6m4xcdT+dgLx1Vpvy7PPddAgDgTpb9NvZpdjpTlYHwn2vafRX56dy17IRWtuk/9OlODLXooCxTUh0YcnKFw5qUsnyZDv4WSvauOjv/3xbd+7H09xXbfT5alQH56lluHjxz+RaW7TlvdcWvNHZJPL7ecdaqVnZV0cR4/sptNJqWV4tYLV1IvBmnbr564mt1U509neduNgeubvO24kam4+bbN+KOm4OkFq0+OLnW1WTG7+g+bytW7E/B0j3nkZ2Ta25+O6Dx//s+/m98tDGvaVE5Wj7Tomb9Y/zfmGHRNJiZlWO+cCkIXhMY2jQIND/++dA/LlXz5/15SvPqVf4gfLtb+wp44fa8tk5HzSdZObmo98ovdtvPbXElh10+iduy+4zrzWCufpAtmyxsBaa2iv+pLX2b1nSpDJblSL2RV8t8ddUR1H/1F4evV35Wbjvxt/j9mONO89xcgVGL9jlMHdabourv5/hU8Nnm03h11RH0/nA7rt/Owpfbz2Ln6cs4Ko0TOXD+Kn4/dgmv/ZyIprPWmzN6AKCZoonR0nt/mC5kvthmu93/4Pmr+GKr7T6D9FvqGsKlDDc0tTpx3dFAkUxx5ZZ1beWuxYXBCY2mLJmyr0fWaNpv5guXguA1gcGSo9xye+QOqO/2nsc/1+7gu332m0Q2n8yrWoYqTiglfX0QOeN3VXrlVqkausDOl8DSvexcvBmXqJpWODdX4PMtp3VdOVlKvZGJOb+dQG6uwP+tt+5k1svVtFzLmkCH+7QDQGhVdVOS3ISlpHX1pleGot2+c6Nq5seujCNxptPymI5J+f48fgkbT6Q6TB3WmsepU8OqVsvu6uivUWo6az1eX5eIx77Ygz4fbcek7xMw8NOdqm1mKMbrVCjtXLOaMqgAplqcvfZ9IyRpTPVy0UbtVcnP1wdCCLz2c17Hub1AAJgytPRw5fvsCq8NDOfyMZLxyq17SL95F5N/OoKe72/FWR1NLVru5eTixt1sVRro94pcdD0nk8da1sHyvefxxbazqj6OLUlpePvXExizeL/VayyryCf+VZ+IXlpxGJ9tPo29yVfMbaKuWHnAcQ1GK2vIMqCc/Fd7LibLbBet2s8FHV9kW5buybtq03Oyll3KyMT/fjikWmbZXp2RmYVPNv3l8qCzizovbE5dUv/tsnJysemkdRv4gfP5S8tUfoa1XHdy4sgZDgaBvvDjIez86zL+vZ7p1kwh2YKtp/H4wj1Wyw+cv+bwtV/tOIvTaTfx9Q5Tx/nuM+kO+2davrXBapZerTnICqo5yWsDw8Lt2tXW7JxcnEu3PtEr/yHT1hw1fzEzMrMRoPNqyNYAJACInPk7QibH4Vx6XhZEdq4wd3bZkpMjNL9EckbQrjPpWLwrGUcUA3Qy7qi/SD3fV19VyjWcRxeo29mddU/HVWjcYeubpyRb/P3lqSssydk1Rtmj6CfaeVpfk9qMNUcxZdURq6B4zaLNffLKw3j395OqJgi9jv1z3Soo2lJZ0bcGwObkg0VlKvjcXIHb97KxYn8KHlu4B63e3oCIGfbTrtvUr+L0+7z1i+2mXD39RYsUNZ4PN+hLBtlyKk01K0JPjaSPgrpFsdcGBlve/zMJD7y7GefT1al76bfyrmw3n0xTXenquT1n0qUbNgcgAXnTO5RWpEX2+3g7omfZbpsFgBwbKYTvKzqgp685hr6K+XoK4rOlN7VRK6j94sKdtjLcVMVWnnC1BtA58s2uc5pzQQ39Yjf+vW7KGuvwzibz/FGu6PPRdlWfRffw6ja3tWzvttW85yhRoLA4lHJN9/gbma2sNlcpO85tualohtR7UTHntxOqgCInNyhrlXJ/jtEMCwxE9BURpRKR3cs6IoolohwiGmxUWZwhV6ktr1qHf7VX9VxZlR/UvJbD/ertfFSmQJ5Ldzynfk6uwND7rbOe7LVp5hbAoI56rzjunJXJmVGLdyUjZHIcFu+yndf93iNNsWZCW6vljgYJ/aeVvsywhYoOUHdPg5B40bS/81du62qSsEUI0wWMrLTGGAtnvfKTZ+9up/dC4rwL95lwpuPfXdz5DVM2hz6xSH+mVn4YWWNYBKCnvQ2IyBfAHADOXQK4QO+5UL6hzy9HLppT2e7cy7HKjImpW8n8OLB8KYf71XuVrpU7bc+qgxewXOd4APlqWCvNs/eH27Box1m7KaDJs3s7VTbZmw/Zn2ZcHuAzXcco7oHNg9GwRnmr5Y6a6gPLOf4fAdbZI+7ka9BtBNdLA9kea+lcWrSSViZNQVpk0dlsi70UZ3t2vdIZU3s3xp5Xu7j0emf5uLFa7ombjBkWGIQQWwE4SsB/BsBKAB4b4ZGTKxAx/Tdz+7884Ou7fX9j9OJ4HL+YodmksC0p7wpVnu/flqa1K+r+oDjKXsgPuT3fsr0bMHWuzvw5Ecv2uH8U5pCY2g7beZ25x4T8RWmhCM4TllmPcFbSmxWT4mRn9crxbXRvu1Vj4JM7yM1A7uiEfeXBRvnehyuq6ri4AoBMJ7OnAKBa+VIIqlAaT7UPtXmB0CuyhtP7tcdRZ7wzPHGzIY/1MRBRLQAPAZivY9sxRBRPRPFpae79ct26l41b93Iwa51pcErKVfWJ4cEPtmk2vcjbA45nOT309zU8vdT+iUuP6gH6vjy2yCmJfT6yfX+Afw0YFV7C1wfzhkSrmrya16lofrxsz3lMceFKcP+5q5rTW3zyWHOrZc3qVLJapmWtjdlXbWlRtxKOvdZD17YHFZk/geVK2tnSNamK3P0tL3Z0aR91q5RxvJGb1K5c2vz4pRW2+9+U9CQ0WFowPMb82NeHED+1K75+Ila1Tev6jsfEeELI5DjNBA2jebLz+X0ALwshHNbdhRALhBAxQoiYqlWtc7DzI+/uXvbe3/4+XtTxobZsG/32yZYOX6MUWasC9rza1anXWNKTTfHJJv03rVkxrjW2vthJ17bVA/zx9sBI7H21C94dHIVJ3e5TrdfbHGbpsYW7rdqne0cF4eC0bqplVcrqOxHrnRdKSWuCPS3KfoUsB7VMS+8MinK4TcUyebWiui5mGe3S2VHqDivG5dW2jOwHiK5dUfU8sFwp1eR4ANDPzkBIZQDzBD1p3+7mycAQA+A7IkoGMBjAp0Q0wOg3XTCsheq5fLWv96Yv7tLayRS6I27IRnB3vndMSGWnvzTVAvzxcExtt5Xh2D8Zmvc3rqQRCGJD9NUaCsJDzRwnLPj5mq5WDk3vjkdia2ORxVWuUlAFfzwSa/q7hmhc9f/53wd0laukxvTi7wx2HJScFVO3EqoH+DveMJ9qVtB+D8v5mbQmSZTZm0okP7rZySZTMrJ52RaPBQYhRD0hRIgQIgTACgBPCyFWG/2+lh05yur9xhPa86bonaLXGb4OJmAzgpzdYJnbrse2l7RrBkSEpDcfBADUqlgaz3cN07U/dyZGWTb/yZSd3hXK+GHZ6FboHl4dOyd3dul99NaO9NDT2Zr0Zi8kz+6NClJNwHK+JqXmdSqhkdQp/0KPhlbra9g4QVpOGdIjwrqt/RE3BnLZoBbBurZranG17yxbr69dubSqs97P10ezCRIAmgZXsPsecgB31heKJi69HonR93fLLyPTVZcD2AWgIRGlENGTRDSOiMYZ9Z56WM6IueVUXieyrakOUt0x74pCrYqmq+wPHo3Gphc6OvXa0EDXByIt32vqYHclA6V2Zdttz36+Pvjg0Wj8MK41Buv8wlcq4/42dkvVy+edDAP8/eDn64MFw2NQs2JeLadN/SpYMa613f2Me6A+zrzVC3UKsP1dizITzhIREFShNJJn90afKNPJPrhS3nFqzQ4LANP6NFY9rx7gj8+lWnV07YqY0su0Pnl2bzzXRV/Q10P+Gjrqa9FKTXbk7Nu98M2o+/HdmFZ49+GmmtsQEV7org6gvaOC8GznBqplvz3fHv2i82p38VPVzbkv9WyIHS93Rv2qBTNAcGa/iAJ5HyOzkoYKIYKEEH5CiGAhxJdCiPlCCKvOZiHESCHECqPKoqQcOfj3lduqgVG2blIf58SAK3vVfdn7j0YDAPpH10I9J0/0tj7ontY/uhZqVSyN4Er6Tp6RwRWweNT9hpbJXqVkVNt6eLJdPXw+rAWia1dE+zDtzsd5Q5pi8oON4ONiDa9UCR80qRXgcLuo4Ar4cVxrBPjbrhXYK8M6jQ7KL0dofxYTpuf1v1S1yNKpXbkMekTUQPLs3lg9oS1Gdwg1rxvVrh6qli+F3lFB5mUfSJ9lWwZajPHZ+mIntKhbCb0iTfv48NFmqvVlFU06vzzb3u6+bSEiPHBfVbQKrWIzINoy5oH6queNagSoJhgMLFdKNdfU2A71US3AHxv+19HhvrVqFqWdSEWd/58WdmuN7uQ1I5+17uDW/p1Nbu/x79iwmsNt7F35yR6N1a6+hwflnWRe6mndZOAuy0Zrd45/+2RLLBvdEqfeeDDf79HhPvuJBJte6IglT+YFj69HOg66SvZuXTq9bzim9QlHeX8/lPD1wRIbyQA9I4JUz5/uaDpxRAVXwAFFB3elMtrpsFXKlsSI1iEOy7pyfBvEhlTGrP6m5q8DFp3nrpA7oxtZjPtQBhhnplioUNoP+6Z0xXjFybN/dC27WVmj24eqntepUgYrx7cx36vCcgyQ8vuT3yw8R7T+Z1qBpJ00i6/cnzZRqlV8P6aVqkl43TPtrF6bPLs3ht5fBx8ObYanOzawWq814tzW33PLqYLL6veawCAroKlGHJTBcSHefChSc7nyg6j1QfuvRbaPPXJTw0dDm1mtax2q3TneLiwQbeoHanZSyiwzPuwZaKcTtl5gWbQPq4ogqX28UyPHQVdJ76A2eyyv8uSTRETNAFVfzWf/yUtqCCxXEhM6mU6ey0a3sltu+UQkT6syoFktJM/u7VI/kKXqAf6Y0Tcci55Q18wy7+XommbbFssprsuWKoE29atgWKu6KGkxPYzyo35kZnerfVmmggcp+kIs38fd9AbFOpXL4PmuYVj6ZCsAQIu6lXHmrV5oafEdaVJLuy/i7YGR6Ne0JiZ1uw/Js3ubf2yxleX2YJMgzeVGKJh6iRcb1qquS7fu8/UhtA6tgtIlfbHxRKr5BFqyhA/eGNAED2hcbcc92w6NawSY57fXMvizvKmRl49uhZIlfDTvRJafybraNgjEeZ3pp+8NicZPGoOB/vxvB/PjXa900TVlwuj29fDfbnm1KHlQW5SDzkN7LJMEWtevgncGRaFPU/WXtGW9ypgzKBJ9omqav9iTut6HEg7m0TqqcwyE7M2Hmjg1eeATbetZLQso7YcD07oh3cVp0aODK1otWzbadNJsFxaIsUvyZvQN8PfD+0OiEVEzQPOOdiXsjAZ3NrAvG93SqYsSvYgIz3dVX3DZatZ7NLa2+daknz6u3Zmt9NHQZnhGcYvVZU/ZTmMvZ6eZ0d28rsZgpEHNTR2vfRRtsCGBZTH2gVBbL7Fr+ZhW5vbMMqXy2iL/06quZmdwRM0Kqg+sVpphvOL+BNUD/FE9wB9VypVCM8WAs/ya2Nm6JuOsBtXUzR+WgUqrxvLFtrOqeYMiagbglQcbYeEI57M/bL0vEeGR2NpWbb1EhCGxdVRXe46Cgiseb1nX5de+MzgKIVXKwN/PF2VKlrCbUGBPhTJ+WD2hLRJnWQe1HhE18P6QaPPznFyBAc1qIay69TQmANCgmvqeGq1Cq+BZqZNbTiG1dYW9d0oXvNijISJqBoAIaFM/UHcfl2zh8BiXBwNq6do4LwVVz6VV36Y1se6ZdtjzahdM7d1YdUMxS64M7nMVBwYnKT/0lv7vEVPHsHK8QLXypfDKg41VbdNGmN4n3Pw4fmpXPNE2xGGuvPLk+tnjeU0hb1k0Y73QXX/zFKBuu7XX5JQfEzSa0SwREcY+UB/VyhufL+9pevqtHompjc1uSrmNrl3RZkfoAMXnztl5frqGV8ekrmE4/VYvh6+tVt4fEzo1QNyz7XH2bdfm8eoaXt3lwYBalBlvUTpTbZvUqoDqAf54qr39C0hllpnRODA4qbyO6pxy9KwcCF7q2QjJs3tj7UTrDqq9U7qoRme6Mm/LqHZ5TQaB5UphRt8IXdOBy5Sd819uV989ztnBeMrmgQ42sn2UlJkZ7wyO0uzEs/Rc1zCrq0hnM1AKktYcRK6OZektZfQMiM4bg+CO/hR3OvF6T6x7pp3uOZCUiMjh30bveBlX6Pn82dI4KK9mVKuie0/kztaG8oMDgxPOvNVLNXEbYKqKWlKeoPTMsFCtvD9WT2iLtRPb4n/d7sMHihS+WtJVQr3AcrZebteWFztih44BXcoyW55k6ld17r2VHbaW0xFoOahIn+zauLrNTjwtM/rm1ZSUX0pXvN4/L0d8fMf6Dgc2OWOARu1tx8uuDbSTJ1XrrhiMNkfHlBmOvKgxMM5V/n6+Tv0f9ZA79N96KBLPdjYuMGjN3qsXEWHTCx3x3iOFM61cLw4MsJ4nZfnoVqqrMZmPD6FimZKqK9UHGlZF46AA1fiFeYrmJmfufRAVXBHPdAlTXel3blQdy0e3whNtQjRf8/UTsZrBSVa3SlldVy7KjkHLFMOKTg5GU7bLD9ORqqlsMtB7ZzKZnA8PAD3zmbWhLOvLPRthjUbtzlVa0z/YGo3siJzme1/1cnh3cBRWjGttHh3titUT2iK0allM6JT/viEj/bdbQ+x+pQsea1nH5XElesjJGC/3dG2m2XqBZTGwef5GKK+d2Baz+hfMYDYt3hMYFOdnZW48YH3rv1ahlXWnRvr5+uDX59qr8q/dPX966/pVbH4ROjWshq4651zRq00D098jv9MRAM7fBN7ZJhHlCddW8CxM2tnpXNRr6P21cWh6dzSoVh4Px9RGTEjlfO0vunZFbNQxQMvTfH3I5WDqDCJC8uzeGN+xvuONDRIVXBHDdVxUGcV7AoOEAFQpqz75bDqpHjhCROgfXQuHZuTlXesZvaokn1TzM4WFO709UHtchBa5U3HNhLYu35xn8oONsHai/ukMpvcJR8+IGk71i1hyx1XkvildseF/+iacc9bOyZ3zlSElI6J81RBY0SHP91XQM7wW3t46A4XXVJ/km9ephN+PWU+gp7zaPXohQ7Vu7cS2dq9ufxrfBtm5uQV2825Hht5fR3X7RmUWk6xdg0Bsd3CLTL3GPeDc1daodvVUHeieUrV8KZc6TPVQZqxEurn9vTgY28G1tO7iTJ6ypKGNdF+jeGVgsLQvOS+3X+9FZ5TGIB8lXx+Cr0/B35JPL62BQN/aGVzD3OfUGw/q/px5gx/GtsaUVUc0Z4X1dnLyRkE3K3FggCmb5c/jphqDrSwio8YfeIrlwCJWcIwa21FU3V+vMv7Qeb8Ib1MtwN/l5tz88NpP6JGZ3TG1t2lKYT03zDickv8b5RQWI9uEIKSQ9H0wxgofr60xlPf3w1PtQzGsdV2UKuG4yadtA+cGeRVmaTfde38JTzv7di9PF4GxYsVrAoOt0QR6ggIAvNqrseONioibBXwbU6MVlg5+xooLrwkMMlsnkS6NqmHDiVSr2+1N7d0YmVk5iKhZfPoY0m8VrxoDY8y9vC4w2FJCmsYhO0c9g6Gjia2KIsvUW8YYU/LazmdLj0nTGeudEZExxoorrjFIHrivqkfSwhhjrLDhGoMX+b+HTTM+umO+HsZY8cWBwYvIN4cvzPctYIx5Hp8hvMgD91XFqLb1PDprJGOs8POawODEbRGKrRK+Ppje13ryPMYYU/K6piQeC8UYY/Z5XWBgjDFmHwcGxhhjKhwYGGOMqXBgYIwxpmJYYCCir4golYiO2ljfn4gOE1ECEcUTUTujysIYY0w/I2sMiwD0tLN+A4CmQohoAKMALDSwLIwxxnQyLDAIIbYCuGJn/U0hzKMLysL2LRPcUx5jd88YY8WGR/sYiOghIjoBIA6mWoOt7cZIzU3xaWlp+XvPfL2aMcaKP48GBiHEKiFEIwADALxuZ7sFQogYIURM1apVC6x8jDHmjQpFVpLU7FSfiHjaT8YY8zCPBQYiakDSfTaJqDmAkgDSPVUexhhjJk5PokdElQDUFkIcdrDdcgAdAQQSUQqAGQD8AEAIMR/AIADDiSgLwB0AQxSd0YwxxjxEV2Agos0A+knbJwBII6ItQoj/2nqNEGKovX0KIeYAmKO7pIwxxgqE3qakCkKIDAADAXwthGgBoKtxxXI/roswxpg+egNDCSIKAvAIgHUGlsdwPO02Y4zZpzcwzALwO4DTQoh9RBQKIMm4YjHGGPMUXX0MQogfAfyoeH4Gps5jxhhjxYyuGgMRhRLRz0SUJk2Mt4aI6hldOMYYYwVPb1PSMgA/AAgCUBOm2sN3RhWKMcaY5+gNDCSEWCKEyJZ+voXBk94xxhjzDL0D3DYR0WSYagkCwBAAcURUGQCEEDZnUWWMMVa06A0MQ6TfYy2Wj4IpUIS6rUQG4eoNY4zpozcrqRh1NPNABsYYs0dvVlIZIppKRAuk52FE1MfYojHGGPMEvZ3PXwO4B6CN9DwFwBuGlIgxxphH6Q0M9YUQ7wDIAgAhxB1wmwxjjBVLegPDPSIqDakPl4jqA7hrWKkYY4x5jN6spJkAfgNQm4iWAmgL4AmjCsUYY8xz9GYlrSei/QBawdSE9JwQ4rKhJWOMMeYRerOSNggh0oUQcUKIdUKIy0S0wejCuRPfHI4xxvSxW2MgIn8AZWC6PWcl5HU4B8A0Z1KRw/djYIwx+xw1JY0F8DxMQWC/YvkNAJ8YVCbGGGMe5KgpaSdMYxdeEEKEAngNwFEAW2CacZUxxlgx4ygwfA7grhDiIyLqAOBtAN8AuA5ggdGFY4wxVvAcNSX5KmZOHQJggRBiJYCVRJRgaMkYY4x5hKMagy8RycGjC4CNinV6x0AwxhgrQhyd3JcD2EJElwHcAbANAIioAUzNSUUGJ6syxpg+dgODEOJNabxCEID1Im8wgA+AZ4wunBE4W5Uxxuxz2BwkhNitseyUMcVhjDHmaXon0WOMMeYlODAwxhhT4cDAGGNMxbDAQERfEVEqER21sf5xIjos/ewkoqZGlYUxxph+RtYYFgHoaWf9WQAPCCGiALwOHknNGGOFgmGD1IQQW4koxM76nYqnuwEEG1UW0xsaunfGGCs2Cksfw5MAfrW1kojGEFE8EcWnpaXl642I591mjDG7PB4YiKgTTIHhZVvbCCEWCCFihBAxVatWLbjCMcaYF/LofEdEFAVgIYAHhRDpniwLY4wxE4/VGIioDoCfAAzjkdSMMVZ4GFZjIKLlADrCdFvQFAAzAPgBgBBiPoDpAKoA+FRq988WQsQYVR7GGGP6GJmVNNTB+qcAPGXU+zPGGHONxzufGWOMFS5eExgED2RgjDFdvCYwyHgUA2OM2ed1gYExxph9HBgYY4ypcGBgjDGmwoGBMcaYCgcGxhhjKl4TGARnqzLGmC5eExhkPOs2Y4zZ53WBgTHGmH0cGBhjjKlwYGCMMabCgYExxpgKBwbGGGMqHBgYY4ypeE1g4HEMjDGmj9cEBhnxxNuMMWaX1wUGxhhj9nFgYIwxpsKBgTHGmAoHBsYYYyocGBhjjKl4TWDgbFXGGNPHawKDjKfdZowx+7wuMDDGGLOPAwNjjDEVDgyMMcZUODAwxhhTMSwwENFXRJRKREdtrG9ERLuI6C4RvWBUORhjjDnHyBrDIgA97ay/AuBZAHMNLANjjDEnGRYYhBBbYTr521qfKoTYByDLqDJYvF9BvA1jjBV5RaKPgYjGEFE8EcWnpaV5ujiMMVasFYnAIIRYIISIEULEVK1a1dPFYYyxYq1IBAbGGGMFhwMDY4wxlRJG7ZiIlgPoCCCQiFIAzADgBwBCiPlEVANAPIAAALlE9DyAcCFEhlFlYowx5phhgUEIMdTB+n8BBBv1/owxxlzDTUmMMcZUvCYw8CgGxhjTx2sCg4zvx8AYY/Z5XWBgjDFmHwcGxhhjKhwYGGOMqXBgYIwxpsKBgTHGmIrXBAaedZsxxvTxmsAgI3C+KmOM2eN1gYExxph9HBgYY4ypcGBgjDGmwoGBMcaYCgcGxhhjKhwYGGOMqXhRYOCBDIwxpocXBQYTnnabMcbs87rAwBhjzD4ODIwxxlQ4MDDGGFPhwMAYY0yFAwNjjDEVDgyMMcZUvCYw8P0YGGNMH68JDDIex8AYY/Z5XWBgjDFmHwcGxhhjKhwYGGOMqRgWGIjoKyJKJaKjNtYTEX1IRH8R0WEiam5UWRhjjOlnZI1hEYCedtY/CCBM+hkD4DMDy8IYY0wnwwKDEGIrgCt2NukPYLEw2Q2gIhEFGVWeIxeuG7VrxhgrVkp48L1rAfhb8TxFWnbRckMiGgNTrQJ16tRx6c26NK6Oq7ezEBpYzqXXM8aYt/BkYNAaUaA5DE0IsQDAAgCIiYlxaahai7qV0KJuJVdeyhhjXsWTWUkpAGorngcD+MdDZWGMMSbxZGBYC2C4lJ3UCsB1IYRVMxJjjLGCZVhTEhEtB9ARQCARpQCYAcAPAIQQ8wH8AqAXgL8A3AbwhFFlYYwxpp9hgUEIMdTBegFgglHvzxhjzDU88pkxxpgKBwbGGGMqHBgYY4ypcGBgjDGmQqKI3dqMiNIAnHPx5YEALruxOEUBH7N34GP2Dvk55rpCiKp6NixygSE/iCheCBHj6XIUJD5m78DH7B0K6pi5KYkxxpgKBwbGGGMq3hYYFni6AB7Ax+wd+Ji9Q4Ecs1f1MTDGGHPM22oMjDHGHODAwBhjTMVrAgMR9SSik0T0FxFN9nR5nEFEtYloExEdJ6JjRPSctLwyEf1BREnS70qK17wiHetJIuqhWN6CiI5I6z4kIpKWlyKi76Xle4gopMAPVAMR+RLRQSJaJz0v1sdMRBWJaAURnZD+36294JgnSZ/ro0S0nIj8i9sxE9FXRJRKREcVywrkGIlohPQeSUQ0QleBhRDF/geAL4DTAEIBlARwCEC4p8vlRPmDADSXHpcHcApAOIB3AEyWlk8GMEd6HC4dYykA9aRj95XW7QXQGqY76P0K4EFp+dMA5kuPHwXwvaePWyrLfwEsA7BOel6sjxnANwCekh6XBFCxOB8zTLfzPQugtPT8BwAji9sxA+gAoDmAo4plhh8jgMoAzki/K0mPKzksr6e/CAX0T2kN4HfF81cAvOLpcuXjeNYA6AbgJIAgaVkQgJNaxwfgd+lvEATghGL5UACfK7eRHpeAaXQlefg4gwFsANAZeYGh2B4zgACYTpJksbw4H7N87/fKUnnWAeheHI8ZQAjUgcHwY1RuI637HMBQR2X1lqYk+cMnS5GWFTlSFbEZgD0AqgvprnfS72rSZraOt5b02HK56jVCiGwA1wFUMeQg9HsfwEsAchXLivMxhwJIA/C11Hy2kIjKohgfsxDiAoC5AM4DuAjTnRzXoxgfs0JBHKNL5z5vCQyksazI5ekSUTkAKwE8L4TIsLepxjJhZ7m913gEEfUBkCqE2K/3JRrLitQxw3Sl1xzAZ0KIZgBuwdTEYEuRP2apXb0/TE0mNQGUJaL/2HuJxrIidcw6uPMYXTp2bwkMKQBqK54HA/jHQ2VxCRH5wRQUlgohfpIWXyKiIGl9EIBUabmt402RHlsuV72GiEoAqADgivuPRLe2APoRUTKA7wB0JqJvUbyPOQVAihBij/R8BUyBojgfc1cAZ4UQaUKILAA/AWiD4n3MsoI4RpfOfd4SGPYBCCOiekRUEqbOmbUeLpNuUubBlwCOCyHeU6xaC0DOMhgBU9+DvPxRKVOhHoAwAHul6uoNImol7XO4xWvkfQ0GsFFIjZKeIIR4RQgRLIQIgen/tVEI8R8U72P+F8DfRNRQWtQFQCKK8THD1ITUiojKSGXtAuA4ivcxywriGH8H0J2IKkm1s+7SMvsKugPGUz8AesGUzXMawBRPl8fJsreDqfp3GECC9NMLpjbEDQCSpN+VFa+ZIh3rSUiZC9LyGABHpXUfI2/0uz+AHwH8BVPmQ6inj1tR5o7I63wu1scMIBpAvPS/Xg1TJklxP+bXAJyQyrsEpmycYnXMAJbD1IeSBdNV/JMFdYwARknL/wLwhJ7y8pQYjDHGVLylKYkxxphOHBgYY4ypcGBgjDGmwoGBMcaYCgcGxhhjKhwYmFciohwiSlD82J1xl4jGEdFwN7xvMhEF5nc/jBmJ01WZVyKim0KIch5432QAMUKIywX93ozpxTUGxhSkK/o5RLRX+mkgLZ9JRC9Ij58lokQiOkxE30nLKhPRamnZbiKKkpZXIaL10qR4n0Mxdw0R/Ud6jwQi+pxM957wJaJFZLo3wREimuSBPwPzchwYmLcqbdGUNESxLkMIcT9MI0vf13jtZADNhBBRAMZJy14DcFBa9iqAxdLyGQC2C9OkeGsB1AEAImoMYAiAtkKIaAA5AB6HaeRzLSFEEyFEJICv3XXAjOlVwtMFYMxD7kgnZC3LFb/naaw/DGApEa2GadoKwDRtySAAEEJslGoKFWC6QctAaXkcEV2Vtu8CoAWAfdJNuErDNInazwBCiegjAHEA1rt4fIy5jGsMjFkTNh7LegP4BKYT+35pNkt70xtr7YMAfCOEiJZ+GgohZgohrgJoCmAzgAkAFrp4DIy5jAMDY9aGKH7vUq4gIh8AtYUQm2C6iVBFAOUAbIWpKQhE1BHAZWG6Z4Zy+YMwTYoHmCZNG0xE1aR1lYmorpSx5COEWAlgGkzTbjNWoLgpiXmr0kSUoHj+mxBCTlktRUR7YLpwGmrxOl8A30rNRARgnhDiGhHNhOnOa4cB3EbeFMivAVhORAcAbIFpmmkIIRKJaCqA9VKwyYKphnBH2o980faK246YMZ04XZUxBU4nZYybkhhjjFngGgNjjDEVrjEwxhhT4cDAGGNMhQMDY4wxFQ4MjDHGVDgwMMYYU/l/nTUtx4UGzLgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "N_ma_q = pd.DataFrame({'N': N_moves_save_q}).ewm(com=400).mean()\n",
    "plt.plot(N_ma_q, label=\"Q-Learning Steps - gamma=0.6\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"q_steps_{N_episodes}_gamma_06.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
