{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02944396",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9652bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from degree_freedom_queen import *\n",
    "from degree_freedom_king1 import *\n",
    "from degree_freedom_king2 import *\n",
    "from generate_game import *\n",
    "from Chess_env import *\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "\n",
    "size_board = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bceca7c",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You can find the environment in the file Chess_env, which contains the class Chess_env. To define an object, you need to provide the board size considered as input. In our example, size_board=4. \n",
    "Chess_env is composed by the following methods:\n",
    "\n",
    "1. Initialise_game. The method initialises an episode by placing the three pieces considered (Agent's king and queen, enemy's king) in the chess board. The outputs of the method are described below in order.\n",
    "\n",
    "     S $\\;$ A matrix representing the board locations filled with 4 numbers: 0, no piece in that position; 1, location of the \n",
    "     agent's king; 2 location of the queen; 3 location of the enemy king.\n",
    "     \n",
    "     X $\\;$ The features, that is the input to the neural network. See the assignment for more information regarding the            definition of the features adopted. To personalise this, go into the Features method of the class Chess_env() and change        accordingly.\n",
    "     \n",
    "     allowed_a $\\;$ The allowed actions that the agent can make. The agent is moving a king, with a total number of 8                possible actions, and a queen, with a total number of $(board_{size}-1)\\times 8$ actions. The total number of possible actions correspond      to the sum of the two, but not all actions are allowed in a given position (movements to locations outside the borders or      against chess rules). Thus, the variable allowed_a is a vector that is one (zero) for an action that the agent can (can't)      make. Be careful, apply the policy considered on the actions that are allowed only.\n",
    "     \n",
    "\n",
    "2. OneStep. The method performs a one step update of the system. Given as input the action selected by the agent, it updates the chess board by performing that action and the response of the enemy king (which is a random allowed action in the settings considered). The first three outputs are the same as for the Initialise_game method, but the variables are computed for the position reached after the update of the system. The fourth and fifth outputs are:\n",
    "\n",
    "     R $\\;$ The reward. To change this, look at the OneStep method of the class where the rewards are set.\n",
    "     \n",
    "     Done $\\;$ A variable that is 1 if the episode has ended (checkmate or draw).\n",
    "     \n",
    "     \n",
    "3. Features. Given the chessboard position, the method computes the features.\n",
    "\n",
    "This information and a quick analysis of the class should be all you need to get going. The other functions that the class exploits are uncommented and constitute an example on how not to write a python code. You can take a look at them if you want, but it is not necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9593a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE THE ENVIRONMENT\n",
    "\n",
    "env=Chess_Env(size_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc05bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 2 0 0]]\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[3 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 0]\n",
      " [3 0 0 0]\n",
      " [0 0 1 2]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  2\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 2]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  3\n",
      "\n",
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [2 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n"
     ]
    }
   ],
   "source": [
    "## PRINT 5 STEPS OF AN EPISODE CONSIDERING A RANDOM AGENT\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()                       # INTIALISE GAME\n",
    "\n",
    "print(S)                                                  # PRINT CHESS BOARD (SEE THE DESCRIPTION ABOVE)\n",
    "\n",
    "print('check? ',env.check)                                # PRINT VARIABLE THAT TELLS IF ENEMY KING IS IN CHECK (1) OR NOT (0)\n",
    "print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))    # PRINT THE NUMBER OF LOCATIONS THAT THE ENEMY KING CAN MOVE TO\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    a,_=np.where(allowed_a==1)                  # FIND WHAT THE ALLOWED ACTIONS ARE\n",
    "    a_agent=np.random.permutation(a)[0]         # MAKE A RANDOM ACTION\n",
    "\n",
    "    S,X,allowed_a,R,Done=env.OneStep(a_agent)   # UPDATE THE ENVIRONMENT\n",
    "    \n",
    "    \n",
    "    ## PRINT CHESS BOARD AND VARIABLES\n",
    "    print('')\n",
    "    print(S)\n",
    "    print(R,'', Done)\n",
    "    print('check? ',env.check)\n",
    "    print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))\n",
    "    \n",
    "    \n",
    "    # TERMINATE THE EPISODE IF Done=True (DRAW OR CHECKMATE)\n",
    "    if Done:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc16cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Agent, Average reward: 0.198 Number of steps:  6.981\n"
     ]
    }
   ],
   "source": [
    "# PERFORM N_episodes=1000 EPISODES MAKING RANDOM ACTIONS AND COMPUTE THE AVERAGE REWARD AND NUMBER OF MOVES \n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_episodes=1000\n",
    "\n",
    "# VARIABLES WHERE TO SAVE THE FINAL REWARD IN AN EPISODE AND THE NUMBER OF MOVES \n",
    "R_save_random = np.zeros([N_episodes, 1])\n",
    "N_moves_save_random = np.zeros([N_episodes, 1])\n",
    "\n",
    "for n in range(N_episodes):\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()     # INITIALISE GAME\n",
    "    Done=0                                  # SET Done=0 AT THE BEGINNING\n",
    "    i=1                                     # COUNTER FOR THE NUMBER OF ACTIONS (MOVES) IN AN EPISODE\n",
    "    \n",
    "    # UNTIL THE EPISODE IS NOT OVER...(Done=0)\n",
    "    while Done==0:\n",
    "        \n",
    "        # SAME AS THE CELL BEFORE, BUT SAVING THE RESULTS WHEN THE EPISODE TERMINATES \n",
    "        \n",
    "        a,_=np.where(allowed_a==1)\n",
    "        a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "        S,X,allowed_a,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        \n",
    "        if Done:\n",
    "            \n",
    "            R_save_random[n]=np.copy(R)\n",
    "            N_moves_save_random[n]=np.copy(i)\n",
    "\n",
    "            break\n",
    "\n",
    "        i=i+1                               # UPDATE THE COUNTER\n",
    "\n",
    "\n",
    "\n",
    "# AS YOU SEE, THE PERFORMANCE OF A RANDOM AGENT ARE NOT GREAT, SINCE THE MAJORITY OF THE POSITIONS END WITH A DRAW \n",
    "# (THE ENEMY KING IS NOT IN CHECK AND CAN'T MOVE)\n",
    "\n",
    "print('Random_Agent, Average reward:',np.mean(R_save_random),'Number of steps: ',np.mean(N_moves_save_random))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece20429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE THE PARAMETERS OF YOUR NEURAL NETWORK AND...\n",
    "# PLEASE CONSIDER TO USE A MASK OF ONE FOR THE ACTION MADE AND ZERO OTHERWISE IF YOU ARE NOT USING VANILLA GRADIENT DESCENT...\n",
    "# WE SUGGEST A NETWORK WITH ONE HIDDEN LAYER WITH SIZE 200. \n",
    "\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_a=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in=np.shape(X)[0]    ## INPUT SIZE\n",
    "N_h=200                ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "################## INITALISE YOUR NEURAL NETWORK.########################################\n",
    "#Epsilon_Greedy Policy. Filter for the valid ones.\n",
    "#https://keras.io/examples/rl/deep_q_network_breakout/\n",
    "\n",
    "def EpsilonGreedy_Policy(Qvalues, epsilon, allowed_a):\n",
    "    rand_value=np.random.uniform(0,1)\n",
    "    rand_a=rand_value<epsilon\n",
    "    if rand_a==True:\n",
    "        a,_=np.where(allowed_a==1)\n",
    "        return np.random.permutation(a)[0]\n",
    "    else:#\n",
    "        Qvalues = Qvalues.numpy()\n",
    "        #set the qvalues for not allowed actions to negative infinity, so that they won't be picked.\n",
    "        Qvalues[np.transpose(allowed_a)==0] = np.NINF\n",
    "        result = np.argmax(Qvalues)\n",
    "        return result\n",
    "\n",
    "    \n",
    "#Network    \n",
    "def define_q_model(N_in, N_h, N_a):\n",
    "    #input layer\n",
    "    inputs =layers.Input(shape=(N_in,))\n",
    "    #hidden layer 1\n",
    "    # Initializing weights at 0s made it start from a much better state (compared to random one).\n",
    "    layer1 = layers.Dense(N_h, activation=\"relu\", bias_initializer='zeros', kernel_initializer='zeros')(inputs)\n",
    "    #output layer\n",
    "    action = layers.Dense(N_a, activation=\"linear\", bias_initializer='zeros', kernel_initializer='zeros')(layer1)\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "#update our model\n",
    "def update_q_model(model, frozen_model, optimizer, gamma, state_history, state_next_history, action_history, rewards_history, done_history):\n",
    "    # Pick batch_size random states from history to build a training batch.\n",
    "    # \n",
    "    indices = np.random.choice(range(len(state_history)), size = batch_size)\n",
    "    sample_state_history = [state_history[i] for i in indices]\n",
    "    sample_action_history = [action_history[i] for i in indices]\n",
    "    sample_state_next_history = [state_next_history[i] for i in indices]\n",
    "    sample_rewards_history = [rewards_history[i] for i in indices]\n",
    "    # done= 0 or 1 depending on the game's state(finished or not)\n",
    "    sample_done_history = [done_history[i] for i in indices]\n",
    "    \n",
    "    #masks for actions taken\n",
    "    masks = tf.one_hot(np.array(sample_action_history), N_a)\n",
    "    #q values for every action taken in S' from the frozen (target) network!!! *not* model.\n",
    "    future_q_values = frozen_model(np.array(sample_state_next_history))\n",
    "    # Q-learning, pick the max q value\n",
    "    max_future_q_values = tf.reduce_max(future_q_values, axis=1)\n",
    "    \n",
    "    \n",
    "    # Only consider stuff inside tape when computing gradients for the model!\n",
    "    with tf.GradientTape() as tape:\n",
    "        #q values for every action taken\n",
    "        q_values = model(np.array(sample_state_history))\n",
    "        q_values_masked = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "        updated_q_values = np.arr\n",
    "        loss = loss_function(updated_q_values, q_values_masked)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    #Pass the gradients and variables to optimizer so it can do it's thing.\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2     # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.00005      # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.85        # THE DISCOUNT FACTOR\n",
    "eta = 0.0035        # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 100000 # THE NUMBER OF GAMES TO BE PLAYED \n",
    "\n",
    "# SAVING VARIABLES\n",
    "R_save = np.zeros([N_episodes, 1])\n",
    "N_moves_save = np.zeros([N_episodes, 1])\n",
    "\n",
    "# History buffer(how far I should know betwen past and present) size.\n",
    "H_size = 100000\n",
    "batch_size = 64\n",
    "# How many batches to train when updating model.\n",
    "batches_per_training = 2\n",
    "update_after_actions = 2\n",
    "update_frozen_model_actions = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ba1f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.28293736501079914 Number of steps:  1.4168466522678185 Episodes:  463\n",
      "Q_Agent, Average reward: 0.3373493975903614 Number of steps:  1.3975903614457832 Episodes:  913\n",
      "Q_Agent, Average reward: 0.3860805860805861 Number of steps:  1.3868131868131868 Episodes:  1365\n",
      "Q_Agent, Average reward: 0.40852272727272726 Number of steps:  1.3909090909090909 Episodes:  1760\n",
      "Q_Agent, Average reward: 0.43324125230202576 Number of steps:  1.3802946593001841 Episodes:  2172\n",
      "Q_Agent, Average reward: 0.44431464174454827 Number of steps:  1.382398753894081 Episodes:  2568\n",
      "Q_Agent, Average reward: 0.450490030415681 Number of steps:  1.3825616762419737 Episodes:  2959\n",
      "Q_Agent, Average reward: 0.45819793205317577 Number of steps:  1.3855243722304285 Episodes:  3385\n",
      "Q_Agent, Average reward: 0.4604183214191157 Number of steps:  1.3910510987556262 Episodes:  3777\n",
      "Q_Agent, Average reward: 0.4681107099879663 Number of steps:  1.3884476534296029 Episodes:  4155\n",
      "Q_Agent, Average reward: 0.472715173025732 Number of steps:  1.3910825199645076 Episodes:  4508\n",
      "Q_Agent, Average reward: 0.4733292458614347 Number of steps:  1.3901491927243 Episodes:  4893\n",
      "Q_Agent, Average reward: 0.4779577995478523 Number of steps:  1.3897889977392615 Episodes:  5308\n",
      "Q_Agent, Average reward: 0.4833656046470692 Number of steps:  1.391304347826087 Episodes:  5681\n",
      "Q_Agent, Average reward: 0.48500329597890574 Number of steps:  1.3922214897824654 Episodes:  6068\n",
      "Q_Agent, Average reward: 0.49029954989911534 Number of steps:  1.3929846344870402 Episodes:  6443\n",
      "Q_Agent, Average reward: 0.4949970570924073 Number of steps:  1.3937610359034727 Episodes:  6796\n",
      "Q_Agent, Average reward: 0.4973441431367067 Number of steps:  1.3954431087503494 Episodes:  7154\n",
      "Q_Agent, Average reward: 0.5010621348911312 Number of steps:  1.3963090812533192 Episodes:  7532\n",
      "Q_Agent, Average reward: 0.5026697177726926 Number of steps:  1.3965166539537248 Episodes:  7866\n",
      "Q_Agent, Average reward: 0.5039706780696396 Number of steps:  1.3974343310934636 Episodes:  8185\n",
      "Q_Agent, Average reward: 0.5060396387944177 Number of steps:  1.3984988858918728 Episodes:  8527\n",
      "Q_Agent, Average reward: 0.5095505617977528 Number of steps:  1.3985393258426966 Episodes:  8900\n",
      "Q_Agent, Average reward: 0.5101623830519411 Number of steps:  1.3993977847080332 Episodes:  9299\n",
      "Q_Agent, Average reward: 0.5109844559585492 Number of steps:  1.398860103626943 Episodes:  9650\n",
      "Q_Agent, Average reward: 0.5118809904153354 Number of steps:  1.400858626198083 Episodes:  10016\n",
      "Q_Agent, Average reward: 0.51478093403948 Number of steps:  1.4027924891670678 Episodes:  10385\n",
      "Q_Agent, Average reward: 0.517511177347243 Number of steps:  1.4041542473919524 Episodes:  10736\n",
      "Q_Agent, Average reward: 0.5201471776002872 Number of steps:  1.4041999461545365 Episodes:  11143\n",
      "Q_Agent, Average reward: 0.5229246266064606 Number of steps:  1.4041333796457103 Episodes:  11516\n",
      "Q_Agent, Average reward: 0.5253909534218933 Number of steps:  1.4012947704725072 Episodes:  11894\n",
      "Q_Agent, Average reward: 0.5267419038272817 Number of steps:  1.4015374550212627 Episodes:  12228\n",
      "Q_Agent, Average reward: 0.5276161632262693 Number of steps:  1.401370845620467 Episodes:  12547\n",
      "Q_Agent, Average reward: 0.5280574416608133 Number of steps:  1.4020135799578552 Episodes:  12813\n",
      "Q_Agent, Average reward: 0.5287103144463011 Number of steps:  1.4017165426097524 Episodes:  13166\n",
      "Q_Agent, Average reward: 0.5291846130996584 Number of steps:  1.4019010842120898 Episodes:  13466\n",
      "Q_Agent, Average reward: 0.5305351826301649 Number of steps:  1.4026577590588918 Episodes:  13771\n",
      "Q_Agent, Average reward: 0.5302051536877973 Number of steps:  1.4033506069425712 Episodes:  14087\n",
      "Q_Agent, Average reward: 0.5320979943091123 Number of steps:  1.40356721493511 Episodes:  14409\n",
      "Q_Agent, Average reward: 0.533315202610824 Number of steps:  1.4038618438944792 Episodes:  14708\n",
      "Q_Agent, Average reward: 0.5346851654215582 Number of steps:  1.4050160085378869 Episodes:  14992\n",
      "Q_Agent, Average reward: 0.5362792521898287 Number of steps:  1.4050856321087724 Episodes:  15298\n",
      "Q_Agent, Average reward: 0.5361519214730224 Number of steps:  1.4055302495669468 Episodes:  15587\n",
      "Q_Agent, Average reward: 0.5373893388585421 Number of steps:  1.4052238337414453 Episodes:  15927\n",
      "Q_Agent, Average reward: 0.5378970089423374 Number of steps:  1.405858772741289 Episodes:  16215\n",
      "Q_Agent, Average reward: 0.5386805597625249 Number of steps:  1.4056460895377718 Episodes:  16507\n",
      "Q_Agent, Average reward: 0.539385292194281 Number of steps:  1.4049105285060342 Episodes:  16821\n",
      "Q_Agent, Average reward: 0.54111975839238 Number of steps:  1.404925078406319 Episodes:  17218\n",
      "Q_Agent, Average reward: 0.5410600545950864 Number of steps:  1.405539126478617 Episodes:  17584\n",
      "Q_Agent, Average reward: 0.5422546996151058 Number of steps:  1.4055335527416746 Episodes:  17927\n",
      "Q_Agent, Average reward: 0.5429945880938064 Number of steps:  1.404635652982015 Episodes:  18293\n",
      "Q_Agent, Average reward: 0.5437721274541358 Number of steps:  1.4048921789507565 Episodes:  18642\n",
      "Q_Agent, Average reward: 0.5447843715444157 Number of steps:  1.4043494286767415 Episodes:  18991\n",
      "Q_Agent, Average reward: 0.545228086563911 Number of steps:  1.4044319892054595 Episodes:  19269\n",
      "Q_Agent, Average reward: 0.5466972711043101 Number of steps:  1.4048457026268808 Episodes:  19605\n",
      "Q_Agent, Average reward: 0.5470582339380575 Number of steps:  1.40488122682169 Episodes:  19954\n",
      "Q_Agent, Average reward: 0.5474918373404571 Number of steps:  1.405214207974671 Episodes:  20214\n",
      "Q_Agent, Average reward: 0.547812545622658 Number of steps:  1.405226531704706 Episodes:  20549\n",
      "Q_Agent, Average reward: 0.5476647166011317 Number of steps:  1.4055816629903135 Episodes:  20854\n",
      "Q_Agent, Average reward: 0.5484206053165872 Number of steps:  1.405684876528637 Episodes:  21179\n",
      "Q_Agent, Average reward: 0.5495746757774369 Number of steps:  1.4054292753218984 Episodes:  21513\n",
      "Q_Agent, Average reward: 0.5495586150116636 Number of steps:  1.405662534876275 Episodes:  21863\n",
      "Q_Agent, Average reward: 0.549563802377616 Number of steps:  1.4053699769470687 Episodes:  22123\n",
      "Q_Agent, Average reward: 0.5502603123748498 Number of steps:  1.4050193565612068 Episodes:  22473\n",
      "Q_Agent, Average reward: 0.5510625219529329 Number of steps:  1.4044169301018616 Episodes:  22776\n",
      "Q_Agent, Average reward: 0.5512648066993535 Number of steps:  1.4043476374365427 Episodes:  23047\n",
      "Q_Agent, Average reward: 0.5514693319665129 Number of steps:  1.4035537331283103 Episodes:  23412\n",
      "Q_Agent, Average reward: 0.5516469594594594 Number of steps:  1.403758445945946 Episodes:  23680\n",
      "Q_Agent, Average reward: 0.5519976620882562 Number of steps:  1.403957750594915 Episodes:  23953\n",
      "Q_Agent, Average reward: 0.5520983782445426 Number of steps:  1.4045722774728675 Episodes:  24233\n",
      "Q_Agent, Average reward: 0.5524466955314108 Number of steps:  1.404705497916837 Episodes:  24482\n",
      "Q_Agent, Average reward: 0.5528970303421562 Number of steps:  1.4046158812136862 Episodes:  24784\n",
      "Q_Agent, Average reward: 0.5530055081024986 Number of steps:  1.4051648439370958 Episodes:  25054\n",
      "Q_Agent, Average reward: 0.5532510547691337 Number of steps:  1.4051496392098104 Episodes:  25361\n",
      "Q_Agent, Average reward: 0.5529324540523667 Number of steps:  1.405236664455457 Episodes:  25627\n",
      "Q_Agent, Average reward: 0.5529161838547701 Number of steps:  1.4052529934337583 Episodes:  25890\n",
      "Q_Agent, Average reward: 0.5531516379343298 Number of steps:  1.405374412293108 Episodes:  26161\n",
      "Q_Agent, Average reward: 0.5538444074466475 Number of steps:  1.405441198728621 Episodes:  26428\n",
      "Q_Agent, Average reward: 0.5538968084708348 Number of steps:  1.4057320312792307 Episodes:  26727\n",
      "Q_Agent, Average reward: 0.5544081723295581 Number of steps:  1.4056184765711748 Episodes:  27018\n",
      "Q_Agent, Average reward: 0.5546178402377719 Number of steps:  1.4055700289876343 Episodes:  27253\n",
      "Q_Agent, Average reward: 0.5552932631196659 Number of steps:  1.4054839295442165 Episodes:  27535\n",
      "Q_Agent, Average reward: 0.5558705325104062 Number of steps:  1.4052318070905698 Episodes:  27868\n",
      "Q_Agent, Average reward: 0.5562229014144573 Number of steps:  1.4051460658184662 Episodes:  28138\n",
      "Q_Agent, Average reward: 0.5567013937772772 Number of steps:  1.4052864986625369 Episodes:  28412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5569699499165276 Number of steps:  1.4053631051752922 Episodes:  28752\n",
      "Q_Agent, Average reward: 0.5573103448275862 Number of steps:  1.4055172413793104 Episodes:  29000\n",
      "Q_Agent, Average reward: 0.5571804421361943 Number of steps:  1.4053712372296443 Episodes:  29267\n",
      "Q_Agent, Average reward: 0.557579656655267 Number of steps:  1.4056479192767413 Episodes:  29533\n",
      "Q_Agent, Average reward: 0.5574165885032829 Number of steps:  1.4053999732011255 Episodes:  29852\n",
      "Q_Agent, Average reward: 0.5578095995757094 Number of steps:  1.4056616282153276 Episodes:  30168\n",
      "Q_Agent, Average reward: 0.5582669159368953 Number of steps:  1.405654498343665 Episodes:  30489\n",
      "Q_Agent, Average reward: 0.5585254952906787 Number of steps:  1.4055212731406301 Episodes:  30790\n",
      "Q_Agent, Average reward: 0.5586920875799762 Number of steps:  1.4058129440889946 Episodes:  31103\n",
      "Q_Agent, Average reward: 0.5591202775390687 Number of steps:  1.4057735764982973 Episodes:  31419\n",
      "Q_Agent, Average reward: 0.5595850020497619 Number of steps:  1.4061051370187 Episodes:  31711\n",
      "Q_Agent, Average reward: 0.5601509622282524 Number of steps:  1.405882536414959 Episodes:  32061\n",
      "Q_Agent, Average reward: 0.5602115289460663 Number of steps:  1.405801583374567 Episodes:  32336\n",
      "Q_Agent, Average reward: 0.5603987730061349 Number of steps:  1.4057361963190185 Episodes:  32600\n",
      "Q_Agent, Average reward: 0.560711570624905 Number of steps:  1.4058385282043484 Episodes:  32885\n",
      "Q_Agent, Average reward: 0.5606425944903249 Number of steps:  1.4062933269033697 Episodes:  33178\n",
      "Q_Agent, Average reward: 0.560711939317924 Number of steps:  1.406647554201756 Episodes:  33486\n",
      "Q_Agent, Average reward: 0.5610974780474824 Number of steps:  1.4065281021789906 Episodes:  33823\n",
      "Q_Agent, Average reward: 0.5615098538756625 Number of steps:  1.4062783683270375 Episodes:  34149\n",
      "Q_Agent, Average reward: 0.5618163354127376 Number of steps:  1.4059480632525752 Episodes:  34465\n",
      "Q_Agent, Average reward: 0.5620015547174158 Number of steps:  1.4058964097544122 Episodes:  34733\n",
      "Q_Agent, Average reward: 0.5625838878259132 Number of steps:  1.4056601079475683 Episodes:  35017\n",
      "Q_Agent, Average reward: 0.5628152093840313 Number of steps:  1.4063013543378478 Episodes:  35294\n",
      "Q_Agent, Average reward: 0.562726531988424 Number of steps:  1.406507263072125 Episodes:  35591\n",
      "Q_Agent, Average reward: 0.5635336043209532 Number of steps:  1.4060916532100896 Episodes:  35918\n",
      "Q_Agent, Average reward: 0.5636519384343309 Number of steps:  1.4061178811240984 Episodes:  36189\n",
      "Q_Agent, Average reward: 0.563452613077747 Number of steps:  1.4063658583472936 Episodes:  36413\n",
      "Q_Agent, Average reward: 0.5639349620066999 Number of steps:  1.4066781055097095 Episodes:  36717\n",
      "Q_Agent, Average reward: 0.564 Number of steps:  1.4065675675675675 Episodes:  37000\n",
      "Q_Agent, Average reward: 0.5642676970965491 Number of steps:  1.4068587989051682 Episodes:  37266\n",
      "Q_Agent, Average reward: 0.564543614868463 Number of steps:  1.406752582809671 Episodes:  37556\n",
      "Q_Agent, Average reward: 0.5645886209813875 Number of steps:  1.4066994500846024 Episodes:  37824\n",
      "Q_Agent, Average reward: 0.565258462345841 Number of steps:  1.4073471529782209 Episodes:  38110\n",
      "Q_Agent, Average reward: 0.5654155705467142 Number of steps:  1.407470111739119 Episodes:  38393\n",
      "Q_Agent, Average reward: 0.5661167709572322 Number of steps:  1.407870921032218 Episodes:  38674\n",
      "Q_Agent, Average reward: 0.566568237257671 Number of steps:  1.4078572345615612 Episodes:  38945\n",
      "Q_Agent, Average reward: 0.5668562393205988 Number of steps:  1.4080742648746525 Episodes:  39211\n",
      "Q_Agent, Average reward: 0.5670753330969147 Number of steps:  1.408126044885759 Episodes:  39478\n",
      "Q_Agent, Average reward: 0.5674662102640256 Number of steps:  1.4079685887594071 Episodes:  39731\n",
      "Q_Agent, Average reward: 0.5679536486688976 Number of steps:  1.408571000449528 Episodes:  40042\n",
      "Q_Agent, Average reward: 0.5681987208091626 Number of steps:  1.408448609251822 Episodes:  40338\n",
      "Q_Agent, Average reward: 0.5686274509803921 Number of steps:  1.4083407232239629 Episodes:  40596\n",
      "Q_Agent, Average reward: 0.5684916419883013 Number of steps:  1.4083310898455665 Episodes:  40859\n",
      "Q_Agent, Average reward: 0.5686551187232386 Number of steps:  1.4083057609964966 Episodes:  41104\n",
      "Q_Agent, Average reward: 0.5689430501930502 Number of steps:  1.4078909266409267 Episodes:  41440\n",
      "Q_Agent, Average reward: 0.5688165850849409 Number of steps:  1.4079086284672233 Episodes:  41676\n",
      "Q_Agent, Average reward: 0.5688471440831505 Number of steps:  1.4077905978830934 Episodes:  41948\n",
      "Q_Agent, Average reward: 0.569491124260355 Number of steps:  1.4075739644970415 Episodes:  42250\n",
      "Q_Agent, Average reward: 0.5700194922618069 Number of steps:  1.4070360019727108 Episodes:  42581\n",
      "Q_Agent, Average reward: 0.5704192510376347 Number of steps:  1.4071725038474094 Episodes:  42886\n",
      "Q_Agent, Average reward: 0.5711243808730269 Number of steps:  1.407188816368097 Episodes:  43206\n",
      "Q_Agent, Average reward: 0.5715008160356757 Number of steps:  1.4072132956347838 Episodes:  43503\n",
      "Q_Agent, Average reward: 0.5714775532595776 Number of steps:  1.4069214592667094 Episodes:  43748\n",
      "Q_Agent, Average reward: 0.5718861452488585 Number of steps:  1.4071693055587107 Episodes:  44021\n",
      "Q_Agent, Average reward: 0.5722321368061988 Number of steps:  1.4072785596494002 Episodes:  44267\n",
      "Q_Agent, Average reward: 0.572658216468896 Number of steps:  1.4070253505933117 Episodes:  44496\n",
      "Q_Agent, Average reward: 0.5730229021291823 Number of steps:  1.4070495616389336 Episodes:  44712\n",
      "Q_Agent, Average reward: 0.5737104012085129 Number of steps:  1.4068956324698982 Episodes:  45014\n",
      "Q_Agent, Average reward: 0.5739672435514886 Number of steps:  1.4071127025175165 Episodes:  45243\n",
      "Q_Agent, Average reward: 0.5745850280312191 Number of steps:  1.4073210948664394 Episodes:  45485\n",
      "Q_Agent, Average reward: 0.5748187931185049 Number of steps:  1.4072133438127674 Episodes:  45804\n",
      "Q_Agent, Average reward: 0.5752554063726872 Number of steps:  1.4069366418671236 Episodes:  46103\n",
      "Q_Agent, Average reward: 0.5754399585921325 Number of steps:  1.4071342305037957 Episodes:  46368\n",
      "Q_Agent, Average reward: 0.5754215110043331 Number of steps:  1.406817109271097 Episodes:  46618\n",
      "Q_Agent, Average reward: 0.5756650582860071 Number of steps:  1.406763738844528 Episodes:  46838\n",
      "Q_Agent, Average reward: 0.576011542297002 Number of steps:  1.4067174471154866 Episodes:  47131\n",
      "Q_Agent, Average reward: 0.5760261686187612 Number of steps:  1.4068165031127995 Episodes:  47385\n",
      "Q_Agent, Average reward: 0.5763380399890901 Number of steps:  1.4069194133814489 Episodes:  47663\n",
      "Q_Agent, Average reward: 0.5764136578854056 Number of steps:  1.4069832926600339 Episodes:  47943\n",
      "Q_Agent, Average reward: 0.5769724846676612 Number of steps:  1.4068871208354052 Episodes:  48264\n",
      "Q_Agent, Average reward: 0.5772423025435074 Number of steps:  1.406631654824426 Episodes:  48555\n",
      "Q_Agent, Average reward: 0.5773732652768382 Number of steps:  1.4067810507758851 Episodes:  48783\n",
      "Q_Agent, Average reward: 0.5774745558750943 Number of steps:  1.4066980766485142 Episodes:  49029\n",
      "Q_Agent, Average reward: 0.5775839334618116 Number of steps:  1.4066538188457247 Episodes:  49295\n",
      "Q_Agent, Average reward: 0.5776504066681467 Number of steps:  1.4066277825990434 Episodes:  49549\n",
      "Q_Agent, Average reward: 0.577763057529407 Number of steps:  1.40676060861536 Episodes:  49818\n",
      "Q_Agent, Average reward: 0.5778269890671136 Number of steps:  1.4067512568829303 Episodes:  50124\n",
      "Q_Agent, Average reward: 0.578011157213476 Number of steps:  1.407019912251097 Episodes:  50371\n",
      "Q_Agent, Average reward: 0.57824781767192 Number of steps:  1.4069005016392147 Episodes:  50634\n",
      "Q_Agent, Average reward: 0.5781237713297162 Number of steps:  1.4068766218447748 Episodes:  50868\n",
      "Q_Agent, Average reward: 0.5781992374621175 Number of steps:  1.4070388112229935 Episodes:  51145\n",
      "Q_Agent, Average reward: 0.578213812972047 Number of steps:  1.4069532040800437 Episodes:  51372\n",
      "Q_Agent, Average reward: 0.5780454272602289 Number of steps:  1.40710260829154 Episodes:  51643\n",
      "Q_Agent, Average reward: 0.5785540962138428 Number of steps:  1.4069444979393753 Episodes:  51926\n",
      "Q_Agent, Average reward: 0.5785040108743514 Number of steps:  1.4069840905174889 Episodes:  52233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5789533842607586 Number of steps:  1.4067208961194826 Episodes:  52493\n",
      "Q_Agent, Average reward: 0.5788147474517829 Number of steps:  1.4067674586033116 Episodes:  52782\n",
      "Q_Agent, Average reward: 0.5790089002866194 Number of steps:  1.4066224166540957 Episodes:  53032\n",
      "Q_Agent, Average reward: 0.5789493433395873 Number of steps:  1.4065853658536585 Episodes:  53300\n",
      "Q_Agent, Average reward: 0.578858966463244 Number of steps:  1.4066401657242036 Episodes:  53583\n",
      "Q_Agent, Average reward: 0.578697346446465 Number of steps:  1.4065689367229541 Episodes:  53890\n",
      "Q_Agent, Average reward: 0.5788774248324997 Number of steps:  1.4063751638088557 Episodes:  54179\n",
      "Q_Agent, Average reward: 0.5789589604287497 Number of steps:  1.4065046619190955 Episodes:  54484\n",
      "Q_Agent, Average reward: 0.5791866771360225 Number of steps:  1.4064605664408452 Episodes:  54763\n",
      "Q_Agent, Average reward: 0.5793750340840923 Number of steps:  1.4064823398956572 Episodes:  55011\n",
      "Q_Agent, Average reward: 0.579445338929392 Number of steps:  1.4066790889520053 Episodes:  55277\n",
      "Q_Agent, Average reward: 0.5793169256251913 Number of steps:  1.4068199413067353 Episodes:  55543\n",
      "Q_Agent, Average reward: 0.5792020647381438 Number of steps:  1.406871706635122 Episodes:  55794\n",
      "Q_Agent, Average reward: 0.5792318532921847 Number of steps:  1.4068002212034179 Episodes:  56057\n",
      "Q_Agent, Average reward: 0.5793437905245767 Number of steps:  1.4069067201961167 Episodes:  56293\n",
      "Q_Agent, Average reward: 0.5796291053227633 Number of steps:  1.4071347678369195 Episodes:  56512\n",
      "Q_Agent, Average reward: 0.579813445969729 Number of steps:  1.4070749736008448 Episodes:  56820\n",
      "Q_Agent, Average reward: 0.5799992987131386 Number of steps:  1.407061958694204 Episodes:  57038\n",
      "Q_Agent, Average reward: 0.5802104969193445 Number of steps:  1.4068036234793082 Episodes:  57293\n",
      "Q_Agent, Average reward: 0.5805515491685057 Number of steps:  1.4069369385024415 Episodes:  57547\n",
      "Q_Agent, Average reward: 0.5807232666332302 Number of steps:  1.4069628681620865 Episodes:  57821\n",
      "Q_Agent, Average reward: 0.5809838548659162 Number of steps:  1.406915900719474 Episodes:  58098\n",
      "Q_Agent, Average reward: 0.581295728311715 Number of steps:  1.406915577183393 Episodes:  58361\n",
      "Q_Agent, Average reward: 0.5814524796560725 Number of steps:  1.406980909974922 Episodes:  58617\n",
      "Q_Agent, Average reward: 0.5816541506677088 Number of steps:  1.4069285398756328 Episodes:  58858\n",
      "Q_Agent, Average reward: 0.581650258804425 Number of steps:  1.4068134916607462 Episodes:  59118\n",
      "Q_Agent, Average reward: 0.5819883198411229 Number of steps:  1.4068532574852315 Episodes:  59417\n",
      "Q_Agent, Average reward: 0.582186044953606 Number of steps:  1.4070110206679396 Episodes:  59706\n",
      "Q_Agent, Average reward: 0.5826694223140771 Number of steps:  1.4069968998966633 Episodes:  59998\n",
      "Q_Agent, Average reward: 0.5832420591456736 Number of steps:  1.4068339473596867 Episodes:  60258\n",
      "Q_Agent, Average reward: 0.5836942506694879 Number of steps:  1.4067841438820379 Episodes:  60494\n",
      "Q_Agent, Average reward: 0.5838941635265661 Number of steps:  1.406776035410462 Episodes:  60773\n",
      "Q_Agent, Average reward: 0.5838605001802747 Number of steps:  1.4068963256743912 Episodes:  61018\n",
      "Q_Agent, Average reward: 0.5838491059034866 Number of steps:  1.4070547889279008 Episodes:  61235\n",
      "Q_Agent, Average reward: 0.584005857468272 Number of steps:  1.4071591278880573 Episodes:  61460\n",
      "Q_Agent, Average reward: 0.5842789521462846 Number of steps:  1.4070483724549345 Episodes:  61688\n",
      "Q_Agent, Average reward: 0.5846188601303814 Number of steps:  1.4069257083844318 Episodes:  61972\n",
      "Q_Agent, Average reward: 0.5850029724127959 Number of steps:  1.4068831440093832 Episodes:  62239\n",
      "Q_Agent, Average reward: 0.5853728764756695 Number of steps:  1.4068848577918547 Episodes:  62514\n",
      "Q_Agent, Average reward: 0.5857643312101911 Number of steps:  1.4067675159235669 Episodes:  62800\n",
      "Q_Agent, Average reward: 0.5859415898599235 Number of steps:  1.406808699652585 Episodes:  63037\n",
      "Q_Agent, Average reward: 0.5861234942615954 Number of steps:  1.4066995478832718 Episodes:  63258\n",
      "Q_Agent, Average reward: 0.5862036395692967 Number of steps:  1.4066179711605062 Episodes:  63524\n",
      "Q_Agent, Average reward: 0.5862761086370194 Number of steps:  1.4064322900332433 Episodes:  63772\n",
      "Q_Agent, Average reward: 0.5865871181358155 Number of steps:  1.4064003248578747 Episodes:  64028\n",
      "Q_Agent, Average reward: 0.5867404861510708 Number of steps:  1.4064633520474021 Episodes:  64301\n",
      "Q_Agent, Average reward: 0.5869794412229836 Number of steps:  1.4066327638066296 Episodes:  64498\n",
      "Q_Agent, Average reward: 0.5870367795850905 Number of steps:  1.4066607967622844 Episodes:  64737\n",
      "Q_Agent, Average reward: 0.5872993891273908 Number of steps:  1.4066842080967548 Episodes:  64989\n",
      "Q_Agent, Average reward: 0.5873898720600628 Number of steps:  1.4067723894890063 Episodes:  65265\n",
      "Q_Agent, Average reward: 0.5873975362916152 Number of steps:  1.4068477049655783 Episodes:  65511\n",
      "Q_Agent, Average reward: 0.5877214342241431 Number of steps:  1.4067845620015829 Episodes:  65708\n",
      "Q_Agent, Average reward: 0.5879293350519372 Number of steps:  1.4069451815907195 Episodes:  65945\n",
      "Q_Agent, Average reward: 0.5881775185481799 Number of steps:  1.4069115580471145 Episodes:  66179\n",
      "Q_Agent, Average reward: 0.5884221619993978 Number of steps:  1.4069256248118036 Episodes:  66420\n",
      "Q_Agent, Average reward: 0.5884911291411089 Number of steps:  1.4070097032049071 Episodes:  66679\n",
      "Q_Agent, Average reward: 0.5885850888988495 Number of steps:  1.407067085014194 Episodes:  66930\n",
      "Q_Agent, Average reward: 0.5886291606529082 Number of steps:  1.4071450890532236 Episodes:  67207\n",
      "Q_Agent, Average reward: 0.5888093013599086 Number of steps:  1.4072755854132373 Episodes:  67431\n",
      "Q_Agent, Average reward: 0.589036441792103 Number of steps:  1.4073149474865947 Episodes:  67697\n",
      "Q_Agent, Average reward: 0.5892518068210254 Number of steps:  1.4073038256031323 Episodes:  67937\n",
      "Q_Agent, Average reward: 0.5893050792813388 Number of steps:  1.407236437175767 Episodes:  68238\n",
      "Q_Agent, Average reward: 0.5893496136825039 Number of steps:  1.4073787372018636 Episodes:  68467\n",
      "Q_Agent, Average reward: 0.5895000218204035 Number of steps:  1.407401480878053 Episodes:  68743\n",
      "Q_Agent, Average reward: 0.5897755430293722 Number of steps:  1.4078045528973642 Episodes:  69011\n",
      "Q_Agent, Average reward: 0.589727678120445 Number of steps:  1.4078334030854487 Episodes:  69293\n",
      "Q_Agent, Average reward: 0.5897015462064006 Number of steps:  1.4077957569219706 Episodes:  69525\n",
      "Q_Agent, Average reward: 0.5899137263894064 Number of steps:  1.4077216314597725 Episodes:  69778\n",
      "Q_Agent, Average reward: 0.5898135191478425 Number of steps:  1.4076591369906046 Episodes:  70034\n",
      "Q_Agent, Average reward: 0.5897939156035329 Number of steps:  1.407688697358877 Episodes:  70311\n",
      "Q_Agent, Average reward: 0.5899852599353704 Number of steps:  1.4077612109530018 Episodes:  70556\n",
      "Q_Agent, Average reward: 0.5901306036004236 Number of steps:  1.4077373808683376 Episodes:  70825\n",
      "Q_Agent, Average reward: 0.5902321722377691 Number of steps:  1.4078271997299996 Episodes:  71111\n",
      "Q_Agent, Average reward: 0.5903479394083769 Number of steps:  1.4079845297983549 Episodes:  71363\n",
      "Q_Agent, Average reward: 0.5904748603351956 Number of steps:  1.4079189944134078 Episodes:  71600\n",
      "Q_Agent, Average reward: 0.5905248645712933 Number of steps:  1.4079154423540226 Episodes:  71809\n",
      "Q_Agent, Average reward: 0.5904928404928405 Number of steps:  1.4076756576756577 Episodes:  72072\n",
      "Q_Agent, Average reward: 0.5904320774282752 Number of steps:  1.4077290010369858 Episodes:  72325\n",
      "Q_Agent, Average reward: 0.5905250244662228 Number of steps:  1.4078484886076996 Episodes:  72549\n",
      "Q_Agent, Average reward: 0.5904981727255242 Number of steps:  1.4076882917044486 Episodes:  72786\n",
      "Q_Agent, Average reward: 0.5904205063603127 Number of steps:  1.4078268132710767 Episodes:  73031\n",
      "Q_Agent, Average reward: 0.5905170060599443 Number of steps:  1.4082136812796855 Episodes:  73268\n",
      "Q_Agent, Average reward: 0.5905967204191331 Number of steps:  1.4082057562767911 Episodes:  73485\n",
      "Q_Agent, Average reward: 0.5906600113935382 Number of steps:  1.4083905270867807 Episodes:  73726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.590751132445406 Number of steps:  1.4084781285917112 Episodes:  73955\n",
      "Q_Agent, Average reward: 0.5908919428725411 Number of steps:  1.408340070061978 Episodes:  74220\n",
      "Q_Agent, Average reward: 0.5910769189457714 Number of steps:  1.4084934412803265 Episodes:  74481\n",
      "Q_Agent, Average reward: 0.5911463910901692 Number of steps:  1.4086394302848575 Episodes:  74704\n",
      "Q_Agent, Average reward: 0.5912791628850569 Number of steps:  1.4084939405264 Episodes:  74924\n",
      "Q_Agent, Average reward: 0.5914467818982608 Number of steps:  1.4084201562146554 Episodes:  75153\n",
      "Q_Agent, Average reward: 0.5914439212044836 Number of steps:  1.4084499568879751 Episodes:  75385\n",
      "Q_Agent, Average reward: 0.591481148537888 Number of steps:  1.4085056316429592 Episodes:  75644\n",
      "Q_Agent, Average reward: 0.5915158862986439 Number of steps:  1.4082469064217282 Episodes:  75883\n",
      "Q_Agent, Average reward: 0.5917719026490588 Number of steps:  1.408333114547507 Episodes:  76178\n",
      "Q_Agent, Average reward: 0.5919165750771969 Number of steps:  1.4083189407023604 Episodes:  76428\n",
      "Q_Agent, Average reward: 0.5920699100039128 Number of steps:  1.4084257206208426 Episodes:  76670\n",
      "Q_Agent, Average reward: 0.5920771991884721 Number of steps:  1.4085730635176612 Episodes:  76892\n",
      "Q_Agent, Average reward: 0.592168916903363 Number of steps:  1.4086481719258654 Episodes:  77103\n",
      "Q_Agent, Average reward: 0.5922837231552952 Number of steps:  1.4088411362372806 Episodes:  77343\n",
      "Q_Agent, Average reward: 0.5924126018356193 Number of steps:  1.4089409095596577 Episodes:  77576\n",
      "Q_Agent, Average reward: 0.592436974789916 Number of steps:  1.408873641199599 Episodes:  77826\n",
      "Q_Agent, Average reward: 0.5924426277821201 Number of steps:  1.4090949860974078 Episodes:  78043\n",
      "Q_Agent, Average reward: 0.5924355798452384 Number of steps:  1.409237173430038 Episodes:  78314\n",
      "Q_Agent, Average reward: 0.5926166380243142 Number of steps:  1.4092292024696074 Episodes:  78555\n",
      "Q_Agent, Average reward: 0.5926081051923492 Number of steps:  1.4090926398355101 Episodes:  78789\n",
      "Q_Agent, Average reward: 0.5926755785103043 Number of steps:  1.4090207099093626 Episodes:  78996\n",
      "Q_Agent, Average reward: 0.5925103462198446 Number of steps:  1.4090163520742909 Episodes:  79256\n",
      "Q_Agent, Average reward: 0.5926904115102123 Number of steps:  1.4090954824429016 Episodes:  79512\n",
      "Q_Agent, Average reward: 0.5928381630402085 Number of steps:  1.4091547177378922 Episodes:  79784\n",
      "Q_Agent, Average reward: 0.5929478772436018 Number of steps:  1.409138032250409 Episodes:  80061\n",
      "Q_Agent, Average reward: 0.5928470951438424 Number of steps:  1.409082421481122 Episodes:  80331\n",
      "Q_Agent, Average reward: 0.5927350321316031 Number of steps:  1.4091134654988462 Episodes:  80606\n",
      "Q_Agent, Average reward: 0.5926544446918528 Number of steps:  1.4091516366065464 Episodes:  80838\n",
      "Q_Agent, Average reward: 0.5928164393023657 Number of steps:  1.409021387867874 Episodes:  81074\n",
      "Q_Agent, Average reward: 0.5929226382162787 Number of steps:  1.409007104402763 Episodes:  81358\n",
      "Q_Agent, Average reward: 0.5929270773340523 Number of steps:  1.4091560772972906 Episodes:  81607\n",
      "Q_Agent, Average reward: 0.5929529832615039 Number of steps:  1.4091957952311769 Episodes:  81907\n",
      "Q_Agent, Average reward: 0.5929839082698347 Number of steps:  1.4092436156486599 Episodes:  82154\n",
      "Q_Agent, Average reward: 0.5929219644763661 Number of steps:  1.4092861302533242 Episodes:  82424\n",
      "Q_Agent, Average reward: 0.5929259205496685 Number of steps:  1.4092998500024194 Episodes:  82668\n",
      "Q_Agent, Average reward: 0.5929126740191647 Number of steps:  1.4091845959139395 Episodes:  82965\n",
      "Q_Agent, Average reward: 0.5929500276422374 Number of steps:  1.4092373146167343 Episodes:  83206\n",
      "Q_Agent, Average reward: 0.5931218009421863 Number of steps:  1.409323567841003 Episodes:  83423\n",
      "Q_Agent, Average reward: 0.5932104149987453 Number of steps:  1.409107746722908 Episodes:  83687\n",
      "Q_Agent, Average reward: 0.5931979272142475 Number of steps:  1.4091845851450355 Episodes:  83945\n",
      "Q_Agent, Average reward: 0.593103366355451 Number of steps:  1.4091891763476112 Episodes:  84186\n",
      "Q_Agent, Average reward: 0.5931072884086817 Number of steps:  1.4091436830632167 Episodes:  84408\n",
      "Q_Agent, Average reward: 0.5932189378461684 Number of steps:  1.4093319319295676 Episodes:  84677\n",
      "Q_Agent, Average reward: 0.5933195186850967 Number of steps:  1.4094355617302847 Episodes:  84934\n",
      "Q_Agent, Average reward: 0.593402594353466 Number of steps:  1.4097200211304808 Episodes:  85185\n",
      "Q_Agent, Average reward: 0.5933775144603424 Number of steps:  1.4097487295974522 Episodes:  85406\n",
      "Q_Agent, Average reward: 0.593358476466261 Number of steps:  1.4097124108216668 Episodes:  85643\n",
      "Q_Agent, Average reward: 0.5934526163940529 Number of steps:  1.409618650969078 Episodes:  85958\n",
      "Q_Agent, Average reward: 0.5933634992458522 Number of steps:  1.4095718760877132 Episodes:  86190\n",
      "Q_Agent, Average reward: 0.5932442593556597 Number of steps:  1.4096014807102781 Episodes:  86445\n",
      "Q_Agent, Average reward: 0.5932895191975095 Number of steps:  1.4094430992736078 Episodes:  86730\n",
      "Q_Agent, Average reward: 0.5933559399965516 Number of steps:  1.4094833036381402 Episodes:  86995\n",
      "Q_Agent, Average reward: 0.5933820241466686 Number of steps:  1.4095531834390085 Episodes:  87217\n",
      "Q_Agent, Average reward: 0.593329747175901 Number of steps:  1.4094628775479838 Episodes:  87373\n",
      "Q_Agent, Average reward: 0.5933487782888055 Number of steps:  1.4094358787076453 Episodes:  87623\n",
      "Q_Agent, Average reward: 0.5933787044202667 Number of steps:  1.4094095688988026 Episodes:  87868\n",
      "Q_Agent, Average reward: 0.5934899351718343 Number of steps:  1.4095073740619217 Episodes:  88079\n",
      "Q_Agent, Average reward: 0.5933895523232781 Number of steps:  1.4094629011262663 Episodes:  88345\n",
      "Q_Agent, Average reward: 0.5934151546286992 Number of steps:  1.4094978942495513 Episodes:  88567\n",
      "Q_Agent, Average reward: 0.5935017074077831 Number of steps:  1.409620087680743 Episodes:  88731\n",
      "Q_Agent, Average reward: 0.5935357712795847 Number of steps:  1.4096334090040683 Episodes:  88982\n",
      "Q_Agent, Average reward: 0.5937545518717297 Number of steps:  1.4096180349359657 Episodes:  89249\n",
      "Q_Agent, Average reward: 0.593882021592865 Number of steps:  1.4095714956300154 Episodes:  89474\n",
      "Q_Agent, Average reward: 0.5939091952869835 Number of steps:  1.4095129808603373 Episodes:  89709\n",
      "Q_Agent, Average reward: 0.5938813171176379 Number of steps:  1.409509304755764 Episodes:  89954\n",
      "Q_Agent, Average reward: 0.5939268200678989 Number of steps:  1.409556881975725 Episodes:  90134\n",
      "Q_Agent, Average reward: 0.5940651045413794 Number of steps:  1.4096206846934596 Episodes:  90347\n",
      "Q_Agent, Average reward: 0.5942273917221725 Number of steps:  1.409627641360418 Episodes:  90531\n",
      "Q_Agent, Average reward: 0.5944019739595955 Number of steps:  1.4097288008636073 Episodes:  90782\n",
      "Q_Agent, Average reward: 0.5945657789160136 Number of steps:  1.409676958418976 Episodes:  90979\n",
      "Q_Agent, Average reward: 0.5947628599300692 Number of steps:  1.409566713798735 Episodes:  91233\n",
      "Q_Agent, Average reward: 0.5948277747402952 Number of steps:  1.4095899398578458 Episodes:  91450\n",
      "Q_Agent, Average reward: 0.5950690786962827 Number of steps:  1.409488915786145 Episodes:  91707\n",
      "Q_Agent, Average reward: 0.5952290304685035 Number of steps:  1.4095027792583568 Episodes:  91931\n",
      "Q_Agent, Average reward: 0.5952910540877774 Number of steps:  1.4094612922475993 Episodes:  92165\n",
      "Q_Agent, Average reward: 0.5953045850110404 Number of steps:  1.4094038186777504 Episodes:  92388\n",
      "Q_Agent, Average reward: 0.5953928895416649 Number of steps:  1.4094021340014689 Episodes:  92596\n",
      "Q_Agent, Average reward: 0.5954701618722469 Number of steps:  1.409354772700348 Episodes:  92851\n",
      "Q_Agent, Average reward: 0.5956086923828859 Number of steps:  1.4093540867734415 Episodes:  93093\n",
      "Q_Agent, Average reward: 0.5958600295712173 Number of steps:  1.4093363618831294 Episodes:  93334\n",
      "Q_Agent, Average reward: 0.5960278350846062 Number of steps:  1.4093275325758143 Episodes:  93551\n",
      "Q_Agent, Average reward: 0.5961727078891258 Number of steps:  1.4092004264392324 Episodes:  93800\n",
      "Q_Agent, Average reward: 0.596336225227524 Number of steps:  1.4092136599472656 Episodes:  94056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_Agent, Average reward: 0.5964255409418753 Number of steps:  1.4093126856173102 Episodes:  94280\n",
      "Q_Agent, Average reward: 0.5967220048641219 Number of steps:  1.409368721581897 Episodes:  94570\n",
      "Q_Agent, Average reward: 0.5968277738523354 Number of steps:  1.409383799289202 Episodes:  94823\n",
      "Q_Agent, Average reward: 0.596858363318814 Number of steps:  1.4094438482419038 Episodes:  95046\n",
      "Q_Agent, Average reward: 0.5968095712861415 Number of steps:  1.4094873274912105 Episodes:  95285\n",
      "Q_Agent, Average reward: 0.5968822630289579 Number of steps:  1.4095667832241043 Episodes:  95518\n",
      "Q_Agent, Average reward: 0.5969924812030075 Number of steps:  1.4096386800334169 Episodes:  95760\n",
      "Q_Agent, Average reward: 0.5970175694545757 Number of steps:  1.4097142618953336 Episodes:  95962\n",
      "Q_Agent, Average reward: 0.597062247910516 Number of steps:  1.4096220217056843 Episodes:  96196\n",
      "Q_Agent, Average reward: 0.5972445393570592 Number of steps:  1.4095041622176379 Episodes:  96463\n",
      "Q_Agent, Average reward: 0.5973894336187994 Number of steps:  1.409467957469695 Episodes:  96684\n",
      "Q_Agent, Average reward: 0.597503481714551 Number of steps:  1.4095734254913086 Episodes:  96935\n",
      "Q_Agent, Average reward: 0.5976954732510288 Number of steps:  1.4094341563786008 Episodes:  97200\n",
      "Q_Agent, Average reward: 0.5978303261695096 Number of steps:  1.4094053410513783 Episodes:  97434\n",
      "Q_Agent, Average reward: 0.5979216790376248 Number of steps:  1.4096544663424622 Episodes:  97675\n",
      "Q_Agent, Average reward: 0.5980306032809659 Number of steps:  1.409701934666694 Episodes:  97898\n",
      "Q_Agent, Average reward: 0.5981574146734201 Number of steps:  1.4097306441914739 Episodes:  98123\n",
      "Q_Agent, Average reward: 0.5982673065972505 Number of steps:  1.409643699666477 Episodes:  98344\n",
      "Q_Agent, Average reward: 0.5983829407348794 Number of steps:  1.409611053624688 Episodes:  98574\n",
      "Q_Agent, Average reward: 0.5985830676585193 Number of steps:  1.4096553818126614 Episodes:  98805\n",
      "Q_Agent, Average reward: 0.5988773006754369 Number of steps:  1.4096136177774188 Episodes:  99047\n",
      "Q_Agent, Average reward: 0.5990047646389249 Number of steps:  1.4096279955274849 Episodes:  99273\n",
      "Q_Agent, Average reward: 0.5991696906947055 Number of steps:  1.4096762195796182 Episodes:  99481\n",
      "Q_Agent, Average reward: 0.5993783214679635 Number of steps:  1.4097763962699288 Episodes:  99730\n",
      "Q_Agent, Average reward: 0.5994659946599467 Number of steps:  1.4095940959409594 Episodes:  99999\n",
      "Q_Agent, Average reward: 0.59946 Number of steps:  1.40959\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "# Create a q model\n",
    "q_model = define_q_model(N_in, N_h, N_a)\n",
    "# And a frozen copy\n",
    "frozen_model = define_q_model(N_in, N_h, N_a)\n",
    "frozen_model.set_weights(q_model.get_weights())\n",
    "\n",
    "# Create an Adam optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=eta, clipnorm=1.0)\n",
    "loss_function = keras.losses.Huber()\n",
    "\n",
    "#accumulate history for batch \n",
    "state_history      = []\n",
    "state_next_history = []\n",
    "action_history     = []\n",
    "rewards_history    = []\n",
    "done_history       = []\n",
    "\n",
    "R_save_q = []\n",
    "N_moves_save_q = []\n",
    "N_actions = 0\n",
    "\n",
    "for n in range(N_episodes):\n",
    "\n",
    "    epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "    Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "    i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "    \n",
    "    while Done==0:                           ## START THE EPISODE\n",
    "        ## THIS IS A RANDOM AGENT, CHANGE IT...\n",
    "        #a,_=np.where(allowed_a==1)\n",
    "        #a_agent=np.random.permutation(a)[0]\n",
    "        \n",
    "        #applying my model to the state\n",
    "        Qvalues = q_model(tf.expand_dims(X, 0), training=False)\n",
    "        \n",
    "        a_agent = EpsilonGreedy_Policy(Qvalues, epsilon_f, allowed_a)\n",
    "        S_next,X_next,allowed_a_next,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        # Add new values to history\n",
    "        if (len(state_history) < H_size):\n",
    "            state_history.append(np.copy(X))\n",
    "            state_next_history.append(np.copy(X_next))\n",
    "            action_history.append(a_agent)\n",
    "            rewards_history.append(R)\n",
    "            done_history.append(Done)\n",
    "        # Reuse old history once buffers are full.\n",
    "        else:\n",
    "            state_history[N_actions % H_size]      = np.copy(X)\n",
    "            state_next_history[N_actions % H_size] = np.copy(X_next)\n",
    "            action_history[N_actions % H_size]     = a_agent\n",
    "            rewards_history[N_actions % H_size]    = R\n",
    "            done_history[N_actions % H_size]       = Done\n",
    "        N_actions += 1\n",
    "        # Update model's variables.\n",
    "        if N_actions % update_after_actions == 0 and len(state_history) > batch_size:\n",
    "            for i in range(batches_per_training):\n",
    "                update_q_model(\n",
    "                    q_model,\n",
    "                    frozen_model,\n",
    "                    optimizer, \n",
    "                    gamma, \n",
    "                    state_history, \n",
    "                    state_next_history, \n",
    "                    action_history, \n",
    "                    rewards_history, \n",
    "                    done_history)\n",
    "\n",
    "        # Update frozen model with current model\n",
    "        if N_actions % update_frozen_model_actions == 0:\n",
    "            frozen_model.set_weights(q_model.get_weights())\n",
    "            print('Q_Agent, Average reward:',np.mean(R_save_q),'Number of steps: ',np.mean(N_moves_save_q), 'Episodes: ', n)\n",
    "        ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "        if Done==1:\n",
    "            # Keep a reward and moves history to make pretty graphs.\n",
    "            R_save_q.append(R)\n",
    "            N_moves_save_q.append(i)\n",
    "            break\n",
    "        # IF THE EPISODE IS NOT OVER...\n",
    "        else:\n",
    "            ## ONLY TO PUT SUMETHING\n",
    "            PIPPO=1            \n",
    "        # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "        S=np.copy(S_next)\n",
    "        X=np.copy(X_next)\n",
    "        allowed_a=np.copy(allowed_a_next)\n",
    "        \n",
    "        i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "print('Q_Agent, Average reward:',np.mean(R_save_q),'Number of steps: ',np.mean(N_moves_save_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b288ad57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "R_ma_q = pd.DataFrame({'R': R_save_q}).ewm(com=400).mean()\n",
    "\n",
    "plt.plot(R_ma_q, label=\"Q-Learning\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward per game\")\n",
    "plt.savefig(f\"q_rewards_{N_episodes}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfaac16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "N_ma_q = pd.DataFrame({'N': N_moves_save_q}).ewm(com=400).mean()\n",
    "plt.plot(N_ma_q, label=\"Q-Learning Steps\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"q_steps_{N_episodes}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
