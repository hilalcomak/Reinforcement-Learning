{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02944396",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9652bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from degree_freedom_queen import *\n",
    "from degree_freedom_king1 import *\n",
    "from degree_freedom_king2 import *\n",
    "from generate_game import *\n",
    "from Chess_env import *\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "\n",
    "size_board = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bceca7c",
   "metadata": {},
   "source": [
    "## The Environment\n",
    "\n",
    "You can find the environment in the file Chess_env, which contains the class Chess_env. To define an object, you need to provide the board size considered as input. In our example, size_board=4. \n",
    "Chess_env is composed by the following methods:\n",
    "\n",
    "1. Initialise_game. The method initialises an episode by placing the three pieces considered (Agent's king and queen, enemy's king) in the chess board. The outputs of the method are described below in order.\n",
    "\n",
    "     S $\\;$ A matrix representing the board locations filled with 4 numbers: 0, no piece in that position; 1, location of the \n",
    "     agent's king; 2 location of the queen; 3 location of the enemy king.\n",
    "     \n",
    "     X $\\;$ The features, that is the input to the neural network. See the assignment for more information regarding the            definition of the features adopted. To personalise this, go into the Features method of the class Chess_env() and change        accordingly.\n",
    "     \n",
    "     allowed_a $\\;$ The allowed actions that the agent can make. The agent is moving a king, with a total number of 8                possible actions, and a queen, with a total number of $(board_{size}-1)\\times 8$ actions. The total number of possible actions correspond      to the sum of the two, but not all actions are allowed in a given position (movements to locations outside the borders or      against chess rules). Thus, the variable allowed_a is a vector that is one (zero) for an action that the agent can (can't)      make. Be careful, apply the policy considered on the actions that are allowed only.\n",
    "     \n",
    "\n",
    "2. OneStep. The method performs a one step update of the system. Given as input the action selected by the agent, it updates the chess board by performing that action and the response of the enemy king (which is a random allowed action in the settings considered). The first three outputs are the same as for the Initialise_game method, but the variables are computed for the position reached after the update of the system. The fourth and fifth outputs are:\n",
    "\n",
    "     R $\\;$ The reward. To change this, look at the OneStep method of the class where the rewards are set.\n",
    "     \n",
    "     Done $\\;$ A variable that is 1 if the episode has ended (checkmate or draw).\n",
    "     \n",
    "     \n",
    "3. Features. Given the chessboard position, the method computes the features.\n",
    "\n",
    "This information and a quick analysis of the class should be all you need to get going. The other functions that the class exploits are uncommented and constitute an example on how not to write a python code. You can take a look at them if you want, but it is not necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9593a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INITIALISE THE ENVIRONMENT\n",
    "\n",
    "env=Chess_Env(size_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc05bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]\n",
      " [0 2 0 0]]\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 0 1]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[3 0 0 0]\n",
      " [0 0 0 2]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n",
      "\n",
      "[[0 0 0 0]\n",
      " [3 0 0 0]\n",
      " [0 0 1 2]\n",
      " [0 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  2\n",
      "\n",
      "[[0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 2]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  3\n",
      "\n",
      "[[0 0 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [2 0 0 0]]\n",
      "0  0\n",
      "check?  0\n",
      "dofk2  1\n"
     ]
    }
   ],
   "source": [
    "## PRINT 5 STEPS OF AN EPISODE CONSIDERING A RANDOM AGENT\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()                       # INTIALISE GAME\n",
    "\n",
    "print(S)                                                  # PRINT CHESS BOARD (SEE THE DESCRIPTION ABOVE)\n",
    "\n",
    "print('check? ',env.check)                                # PRINT VARIABLE THAT TELLS IF ENEMY KING IS IN CHECK (1) OR NOT (0)\n",
    "print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))    # PRINT THE NUMBER OF LOCATIONS THAT THE ENEMY KING CAN MOVE TO\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    a,_=np.where(allowed_a==1)                  # FIND WHAT THE ALLOWED ACTIONS ARE\n",
    "    a_agent=np.random.permutation(a)[0]         # MAKE A RANDOM ACTION\n",
    "\n",
    "    S,X,allowed_a,R,Done=env.OneStep(a_agent)   # UPDATE THE ENVIRONMENT\n",
    "    \n",
    "    \n",
    "    ## PRINT CHESS BOARD AND VARIABLES\n",
    "    print('')\n",
    "    print(S)\n",
    "    print(R,'', Done)\n",
    "    print('check? ',env.check)\n",
    "    print('dofk2 ',np.sum(env.dfk2_constrain).astype(int))\n",
    "    \n",
    "    \n",
    "    # TERMINATE THE EPISODE IF Done=True (DRAW OR CHECKMATE)\n",
    "    if Done:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc16cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Agent, Average reward: 0.20253 Number of steps:  7.00923\n"
     ]
    }
   ],
   "source": [
    "# PERFORM N_episodes=1000 EPISODES MAKING RANDOM ACTIONS AND COMPUTE THE AVERAGE REWARD AND NUMBER OF MOVES \n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_episodes=100000\n",
    "\n",
    "# VARIABLES WHERE TO SAVE THE FINAL REWARD IN AN EPISODE AND THE NUMBER OF MOVES \n",
    "R_save_random = np.zeros([N_episodes, 1])\n",
    "N_moves_save_random = np.zeros([N_episodes, 1])\n",
    "\n",
    "for n in range(N_episodes):\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()     # INITIALISE GAME\n",
    "    Done=0                                  # SET Done=0 AT THE BEGINNING\n",
    "    i=1                                     # COUNTER FOR THE NUMBER OF ACTIONS (MOVES) IN AN EPISODE\n",
    "    \n",
    "    # UNTIL THE EPISODE IS NOT OVER...(Done=0)\n",
    "    while Done==0:\n",
    "        \n",
    "        # SAME AS THE CELL BEFORE, BUT SAVING THE RESULTS WHEN THE EPISODE TERMINATES \n",
    "        \n",
    "        a,_=np.where(allowed_a==1)\n",
    "        a_agent=np.random.permutation(a)[0]\n",
    "\n",
    "        S,X,allowed_a,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        \n",
    "        if Done:\n",
    "            \n",
    "            R_save_random[n]=np.copy(R)\n",
    "            N_moves_save_random[n]=np.copy(i)\n",
    "\n",
    "            break\n",
    "\n",
    "        i=i+1                               # UPDATE THE COUNTER\n",
    "\n",
    "\n",
    "\n",
    "# AS YOU SEE, THE PERFORMANCE OF A RANDOM AGENT ARE NOT GREAT, SINCE THE MAJORITY OF THE POSITIONS END WITH A DRAW \n",
    "# (THE ENEMY KING IS NOT IN CHECK AND CAN'T MOVE)\n",
    "\n",
    "print('Random_Agent, Average reward:',np.mean(R_save_random),'Number of steps: ',np.mean(N_moves_save_random))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece20429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISE THE PARAMETERS OF YOUR NEURAL NETWORK AND...\n",
    "# PLEASE CONSIDER TO USE A MASK OF ONE FOR THE ACTION MADE AND ZERO OTHERWISE IF YOU ARE NOT USING VANILLA GRADIENT DESCENT...\n",
    "# WE SUGGEST A NETWORK WITH ONE HIDDEN LAYER WITH SIZE 200. \n",
    "\n",
    "\n",
    "S,X,allowed_a=env.Initialise_game()\n",
    "N_a=np.shape(allowed_a)[0]   # TOTAL NUMBER OF POSSIBLE ACTIONS\n",
    "\n",
    "N_in=np.shape(X)[0]    ## INPUT SIZE\n",
    "N_h=200                ## NUMBER OF HIDDEN NODES\n",
    "\n",
    "################## INITALISE YOUR NEURAL NETWORK.########################################\n",
    "#Epsilon_Greedy Policy. Filter for the valid ones.\n",
    "#https://keras.io/examples/rl/deep_q_network_breakout/\n",
    "\n",
    "def EpsilonGreedy_Policy(Qvalues, epsilon, allowed_a):\n",
    "    rand_value=np.random.uniform(0,1)\n",
    "    rand_a=rand_value<epsilon\n",
    "    if rand_a==True:\n",
    "        a,_=np.where(allowed_a==1)\n",
    "        return np.random.permutation(a)[0]\n",
    "    else:#\n",
    "        Qvalues = Qvalues.numpy()\n",
    "        #set the qvalues for not allowed actions to negative infinity, so that they won't be picked.\n",
    "        Qvalues[np.transpose(allowed_a)==0] = np.NINF\n",
    "        result = np.argmax(Qvalues)\n",
    "        return result\n",
    "\n",
    "    \n",
    "#Network    \n",
    "def define_q_model(N_in, N_h, N_a):\n",
    "    #input layer\n",
    "    inputs =layers.Input(shape=(N_in,))\n",
    "    #hidden layer 1\n",
    "    # Initializing weights at 0s made it start from a much better state (compared to random one).\n",
    "    layer1 = layers.Dense(N_h, activation=\"relu\", bias_initializer='zeros', kernel_initializer='zeros')(inputs)\n",
    "    #output layer\n",
    "    action = layers.Dense(N_a, activation=\"linear\", bias_initializer='zeros', kernel_initializer='zeros')(layer1)\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "#update our model\n",
    "def update_sarsa_model(model, frozen_model, optimizer, gamma, state_history, state_next_history, action_next_allowed_history, action_history, rewards_history, done_history, epsilon_f):\n",
    "    # Pick batch_size random states from history to build a training batch.\n",
    "    # \n",
    "    indices = np.random.choice(range(len(state_history)), size = batch_size)\n",
    "    sample_state_history = [state_history[i] for i in indices]\n",
    "    sample_action_next_allowed_history = [action_next_allowed_history[i] for i in indices]\n",
    "    sample_action_history = [action_history[i] for i in indices]\n",
    "    sample_state_next_history = [state_next_history[i] for i in indices]\n",
    "    sample_rewards_history = [rewards_history[i] for i in indices]\n",
    "    # done= 0 or 1 depending on the game's state(finished or not)\n",
    "    sample_done_history = [done_history[i] for i in indices]\n",
    "    \n",
    "    #masks for actions taken\n",
    "    masks = tf.one_hot(np.array(sample_action_history), N_a)\n",
    "    #q values for every action taken in S' from the frozen (target) network!!! *not* model.\n",
    "    greedy_future_q = frozen_model(np.array(sample_state_next_history)).numpy()\n",
    "    # SARSA, pick the future action according to policy\n",
    "    \n",
    "    # Get random values for epsilon greedy\n",
    "    rand_values  = np.random.rand(batch_size) < epsilon_f\n",
    "    \n",
    "    allowed_next = np.squeeze(np.array(sample_action_next_allowed_history))\n",
    "    # Some states have no allowed actions. WE multiply their q value by 0 but we cant use -inf * 0 so\n",
    "    # we use -1000000 instead of -inf.\n",
    "    greedy_future_q[allowed_next == 0] = -100000\n",
    "    \n",
    "    \n",
    "    random_future_q = np.full(greedy_future_q.shape, -100000)\n",
    "    for i, allowed_a in enumerate(sample_action_next_allowed_history):\n",
    "        if (len(allowed_a) == 0):\n",
    "            continue\n",
    "        a,_=np.where(allowed_a==1)\n",
    "        j = np.random.permutation(a)[0]\n",
    "        random_future_q[i, j] = greedy_future_q[i,j]\n",
    "    \n",
    "    \n",
    "    #print(allowed_next.shape)\n",
    "    #print(allowed_next)\n",
    "    #print(rand_values.shape)\n",
    "    #print(rand_values)\n",
    "    #print(future_q_values.shape)\n",
    "    #print(future_q_values)\n",
    "    \n",
    "    # Build matrix with Epsilon-greedy q values. Everything else should be -10000.\n",
    "    future_q_values = np.zeros(greedy_future_q.shape)\n",
    "    future_q_values[rand_values == False, :] = greedy_future_q[rand_values == False, :]\n",
    "    future_q_values[rand_values == True, :] = random_future_q[rand_values == True, :]\n",
    "    max_future_q_values = tf.reduce_max(future_q_values, axis=1)\n",
    "    \n",
    "    # Only consider stuff inside tape when computing gradients for the model!\n",
    "    with tf.GradientTape() as tape:\n",
    "        #q values for every action taken\n",
    "        q_values = model(np.array(sample_state_history))\n",
    "        q_values_masked = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "        updated_q_values = np.array(sample_rewards_history) + gamma * max_future_q_values * (1 - np.array(sample_done_history))\n",
    "        loss = loss_function(updated_q_values, q_values_masked)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    #Pass the gradients and variables to optimizer so it can do it's thing.\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS SUGGESTED (FOR A GRID SIZE OF 4)\n",
    "\n",
    "epsilon_0 = 0.2     # STARTING VALUE OF EPSILON FOR THE EPSILON-GREEDY POLICY\n",
    "beta = 0.00005      # THE PARAMETER SETS HOW QUICKLY THE VALUE OF EPSILON IS DECAYING (SEE epsilon_f BELOW)\n",
    "gamma = 0.85        # THE DISCOUNT FACTOR\n",
    "eta = 0.0035        # THE LEARNING RATE\n",
    "\n",
    "N_episodes = 100000 # THE NUMBER OF GAMES TO BE PLAYED \n",
    "\n",
    "# SAVING VARIABLES\n",
    "R_save = np.zeros([N_episodes, 1])\n",
    "N_moves_save = np.zeros([N_episodes, 1])\n",
    "\n",
    "# History buffer(how far I should know betwen past and present) size.\n",
    "H_size = 100000\n",
    "batch_size = 64\n",
    "# How many batches to train when updating model.\n",
    "batches_per_training = 2\n",
    "update_after_actions = 2\n",
    "update_frozen_model_actions = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ba1f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA_Agent, Average reward: 0.3101851851851852 Number of steps:  1.5555555555555556 Episodes:  432\n",
      "SARSA_Agent, Average reward: 0.40540540540540543 Number of steps:  1.4932432432432432 Episodes:  888\n",
      "SARSA_Agent, Average reward: 0.4158878504672897 Number of steps:  1.4587227414330217 Episodes:  1284\n",
      "SARSA_Agent, Average reward: 0.4178486997635934 Number of steps:  1.4414893617021276 Episodes:  1692\n",
      "SARSA_Agent, Average reward: 0.4200934579439252 Number of steps:  1.435981308411215 Episodes:  2140\n",
      "SARSA_Agent, Average reward: 0.43087298613713 Number of steps:  1.420756837766954 Episodes:  2669\n",
      "SARSA_Agent, Average reward: 0.4377806286080821 Number of steps:  1.4146889031430405 Episodes:  3118\n",
      "SARSA_Agent, Average reward: 0.44847438111686816 Number of steps:  1.409902130109384 Episodes:  3474\n",
      "SARSA_Agent, Average reward: 0.45307612095933264 Number of steps:  1.4053701772679874 Episodes:  3836\n",
      "SARSA_Agent, Average reward: 0.45415676959619955 Number of steps:  1.402850356294537 Episodes:  4210\n",
      "SARSA_Agent, Average reward: 0.45777682033606204 Number of steps:  1.3950883239982765 Episodes:  4642\n",
      "SARSA_Agent, Average reward: 0.46320174568537986 Number of steps:  1.3969450505852012 Episodes:  5041\n",
      "SARSA_Agent, Average reward: 0.46341017197219175 Number of steps:  1.394072447859495 Episodes:  5466\n",
      "SARSA_Agent, Average reward: 0.4648154536046913 Number of steps:  1.3939289410141429 Episodes:  5798\n",
      "SARSA_Agent, Average reward: 0.466307717409039 Number of steps:  1.3920704845814977 Episodes:  6129\n",
      "SARSA_Agent, Average reward: 0.46406130268199236 Number of steps:  1.3935632183908047 Episodes:  6525\n",
      "SARSA_Agent, Average reward: 0.46580514011906493 Number of steps:  1.391171772905474 Episodes:  6887\n",
      "SARSA_Agent, Average reward: 0.4670980176211454 Number of steps:  1.3922081497797356 Episodes:  7264\n",
      "SARSA_Agent, Average reward: 0.4674424686192469 Number of steps:  1.3916056485355648 Episodes:  7648\n",
      "SARSA_Agent, Average reward: 0.46828474915551105 Number of steps:  1.391217315150757 Episodes:  7993\n",
      "SARSA_Agent, Average reward: 0.46915351506456243 Number of steps:  1.390961262553802 Episodes:  8364\n",
      "SARSA_Agent, Average reward: 0.4718036529680365 Number of steps:  1.391095890410959 Episodes:  8760\n",
      "SARSA_Agent, Average reward: 0.46923833460823955 Number of steps:  1.3924161293847668 Episodes:  9151\n",
      "SARSA_Agent, Average reward: 0.4705142976851367 Number of steps:  1.3918508431968157 Episodes:  9547\n",
      "SARSA_Agent, Average reward: 0.47216619604679305 Number of steps:  1.3931020572811617 Episodes:  9916\n",
      "SARSA_Agent, Average reward: 0.4736128594945289 Number of steps:  1.3936283528614313 Episodes:  10327\n",
      "SARSA_Agent, Average reward: 0.472389181066867 Number of steps:  1.392092411720511 Episodes:  10648\n",
      "SARSA_Agent, Average reward: 0.47384671267707956 Number of steps:  1.3913912095895387 Episodes:  11012\n",
      "SARSA_Agent, Average reward: 0.4763786441868634 Number of steps:  1.3906743940990516 Episodes:  11388\n",
      "SARSA_Agent, Average reward: 0.47709630640621004 Number of steps:  1.391196792629873 Episodes:  11723\n",
      "SARSA_Agent, Average reward: 0.47781371817201623 Number of steps:  1.3918885294849466 Episodes:  12057\n",
      "SARSA_Agent, Average reward: 0.47867107491331345 Number of steps:  1.3923070720103217 Episodes:  12401\n",
      "SARSA_Agent, Average reward: 0.4800282508043632 Number of steps:  1.3919014360825552 Episodes:  12743\n",
      "SARSA_Agent, Average reward: 0.48155206586369875 Number of steps:  1.389998475377344 Episodes:  13118\n",
      "SARSA_Agent, Average reward: 0.481951871657754 Number of steps:  1.3885918003565063 Episodes:  13464\n",
      "SARSA_Agent, Average reward: 0.48230184581976115 Number of steps:  1.3892870068765835 Episodes:  13815\n",
      "SARSA_Agent, Average reward: 0.4839414001972109 Number of steps:  1.389561910128187 Episodes:  14198\n",
      "SARSA_Agent, Average reward: 0.4849572177753243 Number of steps:  1.388766215843224 Episodes:  14492\n",
      "SARSA_Agent, Average reward: 0.4849922081441832 Number of steps:  1.3892540144996273 Episodes:  14759\n",
      "SARSA_Agent, Average reward: 0.4862160371106693 Number of steps:  1.3889993373094764 Episodes:  15090\n",
      "SARSA_Agent, Average reward: 0.48705638097709725 Number of steps:  1.3887627327580614 Episodes:  15413\n",
      "SARSA_Agent, Average reward: 0.4873703633008844 Number of steps:  1.3891327861551186 Episodes:  15717\n",
      "SARSA_Agent, Average reward: 0.48783379086598455 Number of steps:  1.3890067382081357 Episodes:  16028\n",
      "SARSA_Agent, Average reward: 0.48792744208849126 Number of steps:  1.3896310822404707 Episodes:  16318\n",
      "SARSA_Agent, Average reward: 0.48822681403171553 Number of steps:  1.390377222489188 Episodes:  16648\n",
      "SARSA_Agent, Average reward: 0.48890462700661 Number of steps:  1.3902856468366382 Episodes:  16944\n",
      "SARSA_Agent, Average reward: 0.49082064052817514 Number of steps:  1.390339954827127 Episodes:  17267\n",
      "SARSA_Agent, Average reward: 0.49183220445102166 Number of steps:  1.3912004098127384 Episodes:  17569\n",
      "SARSA_Agent, Average reward: 0.4919305299603507 Number of steps:  1.3912994918188417 Episodes:  17907\n",
      "SARSA_Agent, Average reward: 0.4921488964532777 Number of steps:  1.3910178983199737 Episodes:  18214\n",
      "SARSA_Agent, Average reward: 0.49183948289792623 Number of steps:  1.3909507137085915 Episodes:  18565\n",
      "SARSA_Agent, Average reward: 0.4925649574006456 Number of steps:  1.390008996136953 Episodes:  18897\n",
      "SARSA_Agent, Average reward: 0.49296581909128806 Number of steps:  1.3900583576490204 Episodes:  19192\n",
      "SARSA_Agent, Average reward: 0.49357036733439213 Number of steps:  1.390235155489523 Episodes:  19519\n",
      "SARSA_Agent, Average reward: 0.4941093189057997 Number of steps:  1.3903018658037114 Episodes:  19777\n",
      "SARSA_Agent, Average reward: 0.4946070878274268 Number of steps:  1.3902281425518166 Episodes:  20119\n",
      "SARSA_Agent, Average reward: 0.4949946020217882 Number of steps:  1.3900775345961331 Episodes:  20378\n",
      "SARSA_Agent, Average reward: 0.4955059437518121 Number of steps:  1.389388228472021 Episodes:  20694\n",
      "SARSA_Agent, Average reward: 0.4966865315852205 Number of steps:  1.3905601907032181 Episodes:  20975\n",
      "SARSA_Agent, Average reward: 0.497439030120765 Number of steps:  1.3903481979230299 Episodes:  21281\n",
      "SARSA_Agent, Average reward: 0.49914450867052024 Number of steps:  1.390150289017341 Episodes:  21625\n",
      "SARSA_Agent, Average reward: 0.499863363089816 Number of steps:  1.3901439242120606 Episodes:  21956\n",
      "SARSA_Agent, Average reward: 0.5004494786048184 Number of steps:  1.3903721682847896 Episodes:  22248\n",
      "SARSA_Agent, Average reward: 0.5006439007060705 Number of steps:  1.3907811181668812 Episodes:  22519\n",
      "SARSA_Agent, Average reward: 0.5004165387819529 Number of steps:  1.3910203007848467 Episodes:  22807\n",
      "SARSA_Agent, Average reward: 0.5015585765001299 Number of steps:  1.3909862325742488 Episodes:  23098\n",
      "SARSA_Agent, Average reward: 0.5024336094270344 Number of steps:  1.3914268636324822 Episodes:  23422\n",
      "SARSA_Agent, Average reward: 0.5027163613392293 Number of steps:  1.391619288271215 Episodes:  23745\n",
      "SARSA_Agent, Average reward: 0.5033487249885602 Number of steps:  1.3917384250592786 Episodes:  24039\n",
      "SARSA_Agent, Average reward: 0.5040993686972206 Number of steps:  1.3918176600803476 Episodes:  24394\n",
      "SARSA_Agent, Average reward: 0.5048260199529564 Number of steps:  1.391921485927488 Episodes:  24658\n",
      "SARSA_Agent, Average reward: 0.5048259842204333 Number of steps:  1.3917257399174976 Episodes:  24969\n",
      "SARSA_Agent, Average reward: 0.5043161479369604 Number of steps:  1.3914627385760672 Episodes:  25254\n",
      "SARSA_Agent, Average reward: 0.504883575558681 Number of steps:  1.3915455539928114 Episodes:  25596\n",
      "SARSA_Agent, Average reward: 0.505090236001851 Number of steps:  1.3917553601727595 Episodes:  25932\n",
      "SARSA_Agent, Average reward: 0.5056668574699484 Number of steps:  1.3919099408509827 Episodes:  26205\n",
      "SARSA_Agent, Average reward: 0.5058978707367627 Number of steps:  1.391935179951008 Episodes:  26535\n",
      "SARSA_Agent, Average reward: 0.506066696441864 Number of steps:  1.3917299389608455 Episodes:  26868\n",
      "SARSA_Agent, Average reward: 0.5064241799506682 Number of steps:  1.3917461252438978 Episodes:  27163\n",
      "SARSA_Agent, Average reward: 0.5064812117681329 Number of steps:  1.3913122633265365 Episodes:  27464\n",
      "SARSA_Agent, Average reward: 0.5067533405561575 Number of steps:  1.391152040447815 Episodes:  27690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA_Agent, Average reward: 0.5070588235294118 Number of steps:  1.3908021390374332 Episodes:  28050\n",
      "SARSA_Agent, Average reward: 0.5075901998164231 Number of steps:  1.3905246063687071 Episodes:  28326\n",
      "SARSA_Agent, Average reward: 0.5079952517282312 Number of steps:  1.390266042874101 Episodes:  28642\n",
      "SARSA_Agent, Average reward: 0.5079567813869998 Number of steps:  1.390589940971383 Episodes:  28969\n",
      "SARSA_Agent, Average reward: 0.5086705202312138 Number of steps:  1.390806170263707 Episodes:  29237\n",
      "SARSA_Agent, Average reward: 0.5088116902885363 Number of steps:  1.3912661096641072 Episodes:  29563\n",
      "SARSA_Agent, Average reward: 0.5095458199356914 Number of steps:  1.3914790996784565 Episodes:  29856\n",
      "SARSA_Agent, Average reward: 0.5095902209560407 Number of steps:  1.3912942657435319 Episodes:  30187\n",
      "SARSA_Agent, Average reward: 0.5101445475105707 Number of steps:  1.3916876987118556 Episodes:  30509\n",
      "SARSA_Agent, Average reward: 0.5106555779351569 Number of steps:  1.3917549217074914 Episodes:  30782\n",
      "SARSA_Agent, Average reward: 0.5107663587498793 Number of steps:  1.3915800315426954 Episodes:  31069\n",
      "SARSA_Agent, Average reward: 0.5114764565043894 Number of steps:  1.391827613727055 Episodes:  31325\n",
      "SARSA_Agent, Average reward: 0.5117206035873588 Number of steps:  1.391699092088197 Episodes:  31611\n",
      "SARSA_Agent, Average reward: 0.5123596210552732 Number of steps:  1.3918690005646528 Episodes:  31878\n",
      "SARSA_Agent, Average reward: 0.5125323037643615 Number of steps:  1.391910826042283 Episodes:  32117\n",
      "SARSA_Agent, Average reward: 0.5127286208601087 Number of steps:  1.3920847750865053 Episodes:  32368\n",
      "SARSA_Agent, Average reward: 0.5127764655357526 Number of steps:  1.3918525108132151 Episodes:  32599\n",
      "SARSA_Agent, Average reward: 0.5128633478115603 Number of steps:  1.3919144670898764 Episodes:  32923\n",
      "SARSA_Agent, Average reward: 0.5130968868549407 Number of steps:  1.391792617570904 Episodes:  33214\n",
      "SARSA_Agent, Average reward: 0.5136419328810925 Number of steps:  1.3915668051280519 Episodes:  33463\n",
      "SARSA_Agent, Average reward: 0.5135447540011855 Number of steps:  1.3918494368701837 Episodes:  33740\n",
      "SARSA_Agent, Average reward: 0.5132358983389095 Number of steps:  1.3911486764101662 Episodes:  34074\n",
      "SARSA_Agent, Average reward: 0.5134002618943693 Number of steps:  1.3911246908191475 Episodes:  34365\n",
      "SARSA_Agent, Average reward: 0.5140602872749342 Number of steps:  1.391318169995087 Episodes:  34601\n",
      "SARSA_Agent, Average reward: 0.5142734430923407 Number of steps:  1.3910952040085898 Episodes:  34925\n",
      "SARSA_Agent, Average reward: 0.5147389067341311 Number of steps:  1.3906023479916996 Episodes:  35179\n",
      "SARSA_Agent, Average reward: 0.5151746139295897 Number of steps:  1.390107563309901 Episodes:  35421\n",
      "SARSA_Agent, Average reward: 0.5151396319430829 Number of steps:  1.389961065516372 Episodes:  35701\n",
      "SARSA_Agent, Average reward: 0.5151944444444444 Number of steps:  1.3903611111111112 Episodes:  36000\n",
      "SARSA_Agent, Average reward: 0.5153996746353434 Number of steps:  1.3899964154741224 Episodes:  36267\n",
      "SARSA_Agent, Average reward: 0.5160902584275802 Number of steps:  1.3900999836092445 Episodes:  36606\n",
      "SARSA_Agent, Average reward: 0.5157649733416331 Number of steps:  1.3898346369319874 Episodes:  36949\n",
      "SARSA_Agent, Average reward: 0.516263440860215 Number of steps:  1.3897043010752688 Episodes:  37200\n",
      "SARSA_Agent, Average reward: 0.5162201785952286 Number of steps:  1.3899240303878448 Episodes:  37515\n",
      "SARSA_Agent, Average reward: 0.5164797375939054 Number of steps:  1.3897206644799491 Episodes:  37804\n",
      "SARSA_Agent, Average reward: 0.51685629450561 Number of steps:  1.3897574690595687 Episodes:  38057\n",
      "SARSA_Agent, Average reward: 0.5175294332628502 Number of steps:  1.3896415798679091 Episodes:  38307\n",
      "SARSA_Agent, Average reward: 0.5176184060524407 Number of steps:  1.3899108715929112 Episodes:  38596\n",
      "SARSA_Agent, Average reward: 0.5180359947475476 Number of steps:  1.3901233296428848 Episodes:  38839\n",
      "SARSA_Agent, Average reward: 0.5183584760930708 Number of steps:  1.3901048325236511 Episodes:  39110\n",
      "SARSA_Agent, Average reward: 0.5186428607762348 Number of steps:  1.390050358614375 Episodes:  39318\n",
      "SARSA_Agent, Average reward: 0.5186550209521886 Number of steps:  1.3901146059473923 Episodes:  39614\n",
      "SARSA_Agent, Average reward: 0.5188487329532612 Number of steps:  1.390310671321295 Episodes:  39817\n",
      "SARSA_Agent, Average reward: 0.5182741622267589 Number of steps:  1.3899815764577006 Episodes:  40166\n",
      "SARSA_Agent, Average reward: 0.5187430409501422 Number of steps:  1.3898552517629592 Episodes:  40415\n",
      "SARSA_Agent, Average reward: 0.519186860131104 Number of steps:  1.3898504824335274 Episodes:  40731\n",
      "SARSA_Agent, Average reward: 0.5196619608226272 Number of steps:  1.389917444189341 Episodes:  40942\n",
      "SARSA_Agent, Average reward: 0.5199951438630569 Number of steps:  1.3899963578972927 Episodes:  41185\n",
      "SARSA_Agent, Average reward: 0.520623657471098 Number of steps:  1.3896411073299062 Episodes:  41433\n",
      "SARSA_Agent, Average reward: 0.5212116844431632 Number of steps:  1.3897616988565389 Episodes:  41628\n",
      "SARSA_Agent, Average reward: 0.5220721580605135 Number of steps:  1.3898301040374152 Episodes:  41908\n",
      "SARSA_Agent, Average reward: 0.5224613778210209 Number of steps:  1.3899475545219393 Episodes:  42139\n",
      "SARSA_Agent, Average reward: 0.5233254716981132 Number of steps:  1.389882075471698 Episodes:  42400\n",
      "SARSA_Agent, Average reward: 0.5237626546681665 Number of steps:  1.3898809523809523 Episodes:  42672\n",
      "SARSA_Agent, Average reward: 0.5237484552428475 Number of steps:  1.389861729661669 Episodes:  42887\n",
      "SARSA_Agent, Average reward: 0.5242387727672985 Number of steps:  1.389813227047319 Episodes:  43154\n",
      "SARSA_Agent, Average reward: 0.5246181139552566 Number of steps:  1.3902034421583762 Episodes:  43403\n",
      "SARSA_Agent, Average reward: 0.5249141286924662 Number of steps:  1.3905198076482712 Episodes:  43670\n",
      "SARSA_Agent, Average reward: 0.5250267696443625 Number of steps:  1.3904950675506345 Episodes:  43893\n",
      "SARSA_Agent, Average reward: 0.5252826775214835 Number of steps:  1.3907281772953415 Episodes:  44220\n",
      "SARSA_Agent, Average reward: 0.525703987384546 Number of steps:  1.390651047533228 Episodes:  44390\n",
      "SARSA_Agent, Average reward: 0.5263499016627928 Number of steps:  1.3901975683890577 Episodes:  44744\n",
      "SARSA_Agent, Average reward: 0.5267653126871797 Number of steps:  1.3902211770969675 Episodes:  45077\n",
      "SARSA_Agent, Average reward: 0.5269405586690791 Number of steps:  1.3902961034376242 Episodes:  45322\n",
      "SARSA_Agent, Average reward: 0.5271518529082652 Number of steps:  1.3903065142506088 Episodes:  45577\n",
      "SARSA_Agent, Average reward: 0.5278668499007482 Number of steps:  1.3907684924634076 Episodes:  45843\n",
      "SARSA_Agent, Average reward: 0.5279047103410937 Number of steps:  1.3907525717379534 Episodes:  46175\n",
      "SARSA_Agent, Average reward: 0.5279624728336884 Number of steps:  1.3908075656832999 Episodes:  46473\n",
      "SARSA_Agent, Average reward: 0.5282352185365227 Number of steps:  1.3907317386555882 Episodes:  46697\n",
      "SARSA_Agent, Average reward: 0.5282982710160974 Number of steps:  1.390448002725492 Episodes:  46964\n",
      "SARSA_Agent, Average reward: 0.5284353165361 Number of steps:  1.3903662926106288 Episodes:  47230\n",
      "SARSA_Agent, Average reward: 0.5286689995362368 Number of steps:  1.3903621569206122 Episodes:  47438\n",
      "SARSA_Agent, Average reward: 0.5288979198525253 Number of steps:  1.3903052139849592 Episodes:  47737\n",
      "SARSA_Agent, Average reward: 0.5290832169726778 Number of steps:  1.3902840589375405 Episodes:  47983\n",
      "SARSA_Agent, Average reward: 0.5292507413782377 Number of steps:  1.390555981833641 Episodes:  48221\n",
      "SARSA_Agent, Average reward: 0.5294736191006371 Number of steps:  1.3903424671656255 Episodes:  48501\n",
      "SARSA_Agent, Average reward: 0.5298785989664506 Number of steps:  1.3903494381100812 Episodes:  48764\n",
      "SARSA_Agent, Average reward: 0.5302285749240463 Number of steps:  1.3903717146177843 Episodes:  49043\n",
      "SARSA_Agent, Average reward: 0.5306018913105239 Number of steps:  1.3903364584601647 Episodes:  49278\n",
      "SARSA_Agent, Average reward: 0.5310337871911246 Number of steps:  1.3901159858799799 Episodes:  49575\n",
      "SARSA_Agent, Average reward: 0.5313090309875005 Number of steps:  1.3901370523692778 Episodes:  49762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA_Agent, Average reward: 0.5317749160134378 Number of steps:  1.3900775875859863 Episodes:  50008\n",
      "SARSA_Agent, Average reward: 0.531515608864882 Number of steps:  1.3900428945905154 Episodes:  50356\n",
      "SARSA_Agent, Average reward: 0.5313943845515934 Number of steps:  1.3902776132369783 Episodes:  50646\n",
      "SARSA_Agent, Average reward: 0.5318588937774984 Number of steps:  1.3903794783155248 Episodes:  50912\n",
      "SARSA_Agent, Average reward: 0.5317261858248027 Number of steps:  1.3904040009377199 Episodes:  51188\n",
      "SARSA_Agent, Average reward: 0.5320223845795119 Number of steps:  1.3905642779418623 Episodes:  51464\n",
      "SARSA_Agent, Average reward: 0.5319095477386935 Number of steps:  1.3906068805566294 Episodes:  51740\n",
      "SARSA_Agent, Average reward: 0.5315810725066815 Number of steps:  1.3905862446884194 Episodes:  52009\n",
      "SARSA_Agent, Average reward: 0.5321645261928915 Number of steps:  1.390644438915153 Episodes:  52247\n",
      "SARSA_Agent, Average reward: 0.5323041193938932 Number of steps:  1.3907142313256682 Episodes:  52532\n",
      "SARSA_Agent, Average reward: 0.532258064516129 Number of steps:  1.3908640012115705 Episodes:  52824\n",
      "SARSA_Agent, Average reward: 0.5325419257584323 Number of steps:  1.3907292255511587 Episodes:  53070\n",
      "SARSA_Agent, Average reward: 0.5325809838032394 Number of steps:  1.390859328134373 Episodes:  53344\n",
      "SARSA_Agent, Average reward: 0.5329057757559938 Number of steps:  1.390749095790298 Episodes:  53638\n",
      "SARSA_Agent, Average reward: 0.5328926601927326 Number of steps:  1.3909612492340828 Episodes:  53857\n",
      "SARSA_Agent, Average reward: 0.5333518364326024 Number of steps:  1.3912295309464335 Episodes:  54045\n",
      "SARSA_Agent, Average reward: 0.5334744203165256 Number of steps:  1.3911851306588148 Episodes:  54340\n",
      "SARSA_Agent, Average reward: 0.5332063445547456 Number of steps:  1.3911315432799736 Episodes:  54598\n",
      "SARSA_Agent, Average reward: 0.5334257266858747 Number of steps:  1.3911338852620445 Episodes:  54838\n",
      "SARSA_Agent, Average reward: 0.5338069885341522 Number of steps:  1.3910562753257136 Episodes:  55033\n",
      "SARSA_Agent, Average reward: 0.5340222230265301 Number of steps:  1.391183177096529 Episodes:  55258\n",
      "SARSA_Agent, Average reward: 0.534167087147697 Number of steps:  1.3910293375621712 Episodes:  55492\n",
      "SARSA_Agent, Average reward: 0.5342419018889607 Number of steps:  1.390899949723479 Episodes:  55692\n",
      "SARSA_Agent, Average reward: 0.5340980150435046 Number of steps:  1.3910239231030355 Episodes:  55971\n",
      "SARSA_Agent, Average reward: 0.5343357949995551 Number of steps:  1.3911735919565797 Episodes:  56195\n",
      "SARSA_Agent, Average reward: 0.5339926272508153 Number of steps:  1.391446902027506 Episodes:  56424\n",
      "SARSA_Agent, Average reward: 0.5341967172564887 Number of steps:  1.391438011272284 Episodes:  56599\n",
      "SARSA_Agent, Average reward: 0.5342868200689607 Number of steps:  1.3914221377805924 Episodes:  56844\n",
      "SARSA_Agent, Average reward: 0.5345766570352859 Number of steps:  1.391314245687768 Episodes:  57105\n",
      "SARSA_Agent, Average reward: 0.53441931039294 Number of steps:  1.3914226415752482 Episodes:  57337\n",
      "SARSA_Agent, Average reward: 0.5346075725222644 Number of steps:  1.3914032255264484 Episodes:  57603\n",
      "SARSA_Agent, Average reward: 0.5346894297130403 Number of steps:  1.3913998581633888 Episodes:  57813\n",
      "SARSA_Agent, Average reward: 0.5347419538151573 Number of steps:  1.3914690637323277 Episodes:  58071\n",
      "SARSA_Agent, Average reward: 0.5345935662993367 Number of steps:  1.3914205898987129 Episodes:  58349\n",
      "SARSA_Agent, Average reward: 0.5348269326001946 Number of steps:  1.3913184542613686 Episodes:  58561\n",
      "SARSA_Agent, Average reward: 0.534497118865904 Number of steps:  1.3912733082898472 Episodes:  58831\n",
      "SARSA_Agent, Average reward: 0.5346936703720623 Number of steps:  1.391333773243321 Episodes:  59103\n",
      "SARSA_Agent, Average reward: 0.5350032870893245 Number of steps:  1.3912984845675371 Episodes:  59323\n",
      "SARSA_Agent, Average reward: 0.5352859275661349 Number of steps:  1.391072417090232 Episodes:  59613\n",
      "SARSA_Agent, Average reward: 0.5352896914973665 Number of steps:  1.3910208176573866 Episodes:  59805\n",
      "SARSA_Agent, Average reward: 0.5352335576730859 Number of steps:  1.3909842073698941 Episodes:  60028\n",
      "SARSA_Agent, Average reward: 0.5349133790453476 Number of steps:  1.3908377223492001 Episodes:  60378\n",
      "SARSA_Agent, Average reward: 0.5351222971747126 Number of steps:  1.3909221355412247 Episodes:  60631\n",
      "SARSA_Agent, Average reward: 0.5352316443626081 Number of steps:  1.3910005589714924 Episodes:  60826\n",
      "SARSA_Agent, Average reward: 0.5355103643472997 Number of steps:  1.3907857925821703 Episodes:  61123\n",
      "SARSA_Agent, Average reward: 0.5357800257375099 Number of steps:  1.3905748586880387 Episodes:  61389\n",
      "SARSA_Agent, Average reward: 0.5360940213950619 Number of steps:  1.3906627923964743 Episodes:  61603\n",
      "SARSA_Agent, Average reward: 0.5360869705682809 Number of steps:  1.390850644525571 Episodes:  61906\n",
      "SARSA_Agent, Average reward: 0.536013642872082 Number of steps:  1.3909776855382339 Episodes:  62157\n",
      "SARSA_Agent, Average reward: 0.5361074169617536 Number of steps:  1.3910849049045841 Episodes:  62411\n",
      "SARSA_Agent, Average reward: 0.5362716624644943 Number of steps:  1.3910733092905243 Episodes:  62666\n",
      "SARSA_Agent, Average reward: 0.5364608189367185 Number of steps:  1.390983424008145 Episodes:  62862\n",
      "SARSA_Agent, Average reward: 0.5363270862352792 Number of steps:  1.3907179941750032 Episodes:  63176\n",
      "SARSA_Agent, Average reward: 0.5364783843483749 Number of steps:  1.3907068475859892 Episodes:  63380\n",
      "SARSA_Agent, Average reward: 0.5365316901408451 Number of steps:  1.3906721579476862 Episodes:  63616\n",
      "SARSA_Agent, Average reward: 0.5367223682563524 Number of steps:  1.390615220928777 Episodes:  63912\n",
      "SARSA_Agent, Average reward: 0.5367490230878209 Number of steps:  1.3905624834586583 Episodes:  64233\n",
      "SARSA_Agent, Average reward: 0.5368976487933577 Number of steps:  1.3905641343990067 Episodes:  64435\n",
      "SARSA_Agent, Average reward: 0.5368946904434168 Number of steps:  1.3905377607992948 Episodes:  64657\n",
      "SARSA_Agent, Average reward: 0.536997657790927 Number of steps:  1.3905479536489151 Episodes:  64896\n",
      "SARSA_Agent, Average reward: 0.5365984435320792 Number of steps:  1.3905723389913598 Episodes:  65276\n",
      "SARSA_Agent, Average reward: 0.5366565330970531 Number of steps:  1.3904428726378344 Episodes:  65459\n",
      "SARSA_Agent, Average reward: 0.5366384559181685 Number of steps:  1.390449951290794 Episodes:  65696\n",
      "SARSA_Agent, Average reward: 0.5365442705566266 Number of steps:  1.3904886230817104 Episodes:  65879\n",
      "SARSA_Agent, Average reward: 0.5366277926517523 Number of steps:  1.3902981349548487 Episodes:  66111\n",
      "SARSA_Agent, Average reward: 0.5365552544414333 Number of steps:  1.3904546823246011 Episodes:  66420\n",
      "SARSA_Agent, Average reward: 0.5369056014885284 Number of steps:  1.3904536110319163 Episodes:  66643\n",
      "SARSA_Agent, Average reward: 0.5370456210655382 Number of steps:  1.3903883248351452 Episodes:  66877\n",
      "SARSA_Agent, Average reward: 0.5370579999404212 Number of steps:  1.390300574935208 Episodes:  67138\n",
      "SARSA_Agent, Average reward: 0.5368815992407165 Number of steps:  1.3902153280341678 Episodes:  67432\n",
      "SARSA_Agent, Average reward: 0.5370039169314906 Number of steps:  1.3902741852043456 Episodes:  67655\n",
      "SARSA_Agent, Average reward: 0.5373114541597926 Number of steps:  1.390142587791657 Episodes:  67888\n",
      "SARSA_Agent, Average reward: 0.5372348229218626 Number of steps:  1.3902907778527624 Episodes:  68162\n",
      "SARSA_Agent, Average reward: 0.5373885807122053 Number of steps:  1.390410257160839 Episodes:  68323\n",
      "SARSA_Agent, Average reward: 0.5374586183260657 Number of steps:  1.3904825795913605 Episodes:  68569\n",
      "SARSA_Agent, Average reward: 0.5374634954305723 Number of steps:  1.3904717625350516 Episodes:  68827\n",
      "SARSA_Agent, Average reward: 0.5377458144616319 Number of steps:  1.3905248382942395 Episodes:  69107\n",
      "SARSA_Agent, Average reward: 0.537770795197394 Number of steps:  1.3906513498320818 Episodes:  69379\n",
      "SARSA_Agent, Average reward: 0.537949439008293 Number of steps:  1.390255100576774 Episodes:  69698\n",
      "SARSA_Agent, Average reward: 0.5376992921998999 Number of steps:  1.3903624794451992 Episodes:  69935\n",
      "SARSA_Agent, Average reward: 0.5378341769444642 Number of steps:  1.3905610608112926 Episodes:  70135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA_Agent, Average reward: 0.5379613855763771 Number of steps:  1.3906161272004542 Episodes:  70440\n",
      "SARSA_Agent, Average reward: 0.538136913359957 Number of steps:  1.3907015605970487 Episodes:  70614\n",
      "SARSA_Agent, Average reward: 0.5380334999858769 Number of steps:  1.390842583961811 Episodes:  70806\n",
      "SARSA_Agent, Average reward: 0.5381041546410621 Number of steps:  1.3909389122752678 Episodes:  71029\n",
      "SARSA_Agent, Average reward: 0.5383925694512546 Number of steps:  1.3910564435914319 Episodes:  71381\n",
      "SARSA_Agent, Average reward: 0.53831660921385 Number of steps:  1.3909396675645123 Episodes:  71653\n",
      "SARSA_Agent, Average reward: 0.5382464243975736 Number of steps:  1.3909928209694473 Episodes:  71876\n",
      "SARSA_Agent, Average reward: 0.5384764785039469 Number of steps:  1.3909659697848313 Episodes:  72083\n",
      "SARSA_Agent, Average reward: 0.5385966853885953 Number of steps:  1.3909747392302798 Episodes:  72286\n",
      "SARSA_Agent, Average reward: 0.5386079091059511 Number of steps:  1.3909050796977551 Episodes:  72524\n",
      "SARSA_Agent, Average reward: 0.5384351265605472 Number of steps:  1.3909299419043826 Episodes:  72811\n",
      "SARSA_Agent, Average reward: 0.5387447309355669 Number of steps:  1.3908140362402146 Episodes:  73068\n",
      "SARSA_Agent, Average reward: 0.538899870492809 Number of steps:  1.3907709085951878 Episodes:  73355\n",
      "SARSA_Agent, Average reward: 0.5389883014714874 Number of steps:  1.3907390046060408 Episodes:  73599\n",
      "SARSA_Agent, Average reward: 0.5391989601104883 Number of steps:  1.3907845208113305 Episodes:  73854\n",
      "SARSA_Agent, Average reward: 0.5393384237649408 Number of steps:  1.3908345249979763 Episodes:  74126\n",
      "SARSA_Agent, Average reward: 0.5393220658034502 Number of steps:  1.3908945450633967 Episodes:  74373\n",
      "SARSA_Agent, Average reward: 0.5393779397772804 Number of steps:  1.3907374401994024 Episodes:  74623\n",
      "SARSA_Agent, Average reward: 0.5395042602633617 Number of steps:  1.3909025347899249 Episodes:  74878\n",
      "SARSA_Agent, Average reward: 0.5396110815130527 Number of steps:  1.3909962706446457 Episodes:  75080\n",
      "SARSA_Agent, Average reward: 0.5396445931946768 Number of steps:  1.3908013918771749 Episodes:  75294\n",
      "SARSA_Agent, Average reward: 0.5397258098666102 Number of steps:  1.3907606394240948 Episodes:  75568\n",
      "SARSA_Agent, Average reward: 0.5398390076537345 Number of steps:  1.3907759303246239 Episodes:  75780\n",
      "SARSA_Agent, Average reward: 0.5399424040396071 Number of steps:  1.3910870908780097 Episodes:  76047\n",
      "SARSA_Agent, Average reward: 0.5400327761389708 Number of steps:  1.3912159947558178 Episodes:  76275\n",
      "SARSA_Agent, Average reward: 0.540183471851968 Number of steps:  1.3911713972087187 Episodes:  76524\n",
      "SARSA_Agent, Average reward: 0.5401222102067672 Number of steps:  1.3913202089820593 Episodes:  76753\n",
      "SARSA_Agent, Average reward: 0.5401176455311579 Number of steps:  1.391177883678955 Episodes:  77011\n",
      "SARSA_Agent, Average reward: 0.5402751509184651 Number of steps:  1.3911832525843977 Episodes:  77194\n",
      "SARSA_Agent, Average reward: 0.5402232114057157 Number of steps:  1.3910973485581575 Episodes:  77505\n",
      "SARSA_Agent, Average reward: 0.5404508259996912 Number of steps:  1.3909731871751325 Episodes:  77724\n",
      "SARSA_Agent, Average reward: 0.5405068976580045 Number of steps:  1.3909528392685275 Episodes:  77925\n",
      "SARSA_Agent, Average reward: 0.5406356355075616 Number of steps:  1.3908748944445866 Episodes:  78158\n",
      "SARSA_Agent, Average reward: 0.5407328988150661 Number of steps:  1.3908113416920702 Episodes:  78401\n",
      "SARSA_Agent, Average reward: 0.5405608189737394 Number of steps:  1.390907356774973 Episodes:  78635\n",
      "SARSA_Agent, Average reward: 0.5407688307735234 Number of steps:  1.3908582444481083 Episodes:  78847\n",
      "SARSA_Agent, Average reward: 0.5408249743855699 Number of steps:  1.3908698786951188 Episodes:  79057\n",
      "SARSA_Agent, Average reward: 0.5410315200685328 Number of steps:  1.3909647509385472 Episodes:  79378\n",
      "SARSA_Agent, Average reward: 0.5410801511860065 Number of steps:  1.39082336100054 Episodes:  79637\n",
      "SARSA_Agent, Average reward: 0.5411794165518968 Number of steps:  1.3906723425566545 Episodes:  79870\n",
      "SARSA_Agent, Average reward: 0.5413171559816258 Number of steps:  1.390740463351308 Episodes:  80112\n",
      "SARSA_Agent, Average reward: 0.54138549266665 Number of steps:  1.3907343310341393 Episodes:  80318\n",
      "SARSA_Agent, Average reward: 0.5415617128463476 Number of steps:  1.390651561588763 Episodes:  80591\n",
      "SARSA_Agent, Average reward: 0.5416414050803627 Number of steps:  1.3906410462627288 Episodes:  80821\n",
      "SARSA_Agent, Average reward: 0.5416296515645049 Number of steps:  1.3906450498470042 Episodes:  81048\n",
      "SARSA_Agent, Average reward: 0.5416938230917744 Number of steps:  1.3906836040777677 Episodes:  81319\n",
      "SARSA_Agent, Average reward: 0.5415787924861445 Number of steps:  1.390639560547354 Episodes:  81556\n",
      "SARSA_Agent, Average reward: 0.5416753299169551 Number of steps:  1.390726856891259 Episodes:  81763\n",
      "SARSA_Agent, Average reward: 0.5415813840155945 Number of steps:  1.390801656920078 Episodes:  82080\n",
      "SARSA_Agent, Average reward: 0.5416130207700717 Number of steps:  1.390805295760962 Episodes:  82330\n",
      "SARSA_Agent, Average reward: 0.5417949152953152 Number of steps:  1.3909139381013549 Episodes:  82522\n",
      "SARSA_Agent, Average reward: 0.5418035162287481 Number of steps:  1.3909389489953632 Episodes:  82816\n",
      "SARSA_Agent, Average reward: 0.5419864804617368 Number of steps:  1.3909701051921293 Episodes:  82991\n",
      "SARSA_Agent, Average reward: 0.5421524555878747 Number of steps:  1.3909709368013654 Episodes:  83198\n",
      "SARSA_Agent, Average reward: 0.5422583312362943 Number of steps:  1.3909000491306276 Episodes:  83451\n",
      "SARSA_Agent, Average reward: 0.5422953326404568 Number of steps:  1.3908540300326129 Episodes:  83709\n",
      "SARSA_Agent, Average reward: 0.5423199733117285 Number of steps:  1.3909474336367535 Episodes:  83932\n",
      "SARSA_Agent, Average reward: 0.5423052722804601 Number of steps:  1.3909869053696295 Episodes:  84233\n",
      "SARSA_Agent, Average reward: 0.5422402670422936 Number of steps:  1.390928137687764 Episodes:  84481\n",
      "SARSA_Agent, Average reward: 0.542510264760017 Number of steps:  1.3909103780263343 Episodes:  84756\n",
      "SARSA_Agent, Average reward: 0.5425028821494954 Number of steps:  1.3908900548196599 Episodes:  85006\n",
      "SARSA_Agent, Average reward: 0.5426051051051051 Number of steps:  1.3910707582582582 Episodes:  85248\n",
      "SARSA_Agent, Average reward: 0.5427145661929693 Number of steps:  1.3909522251308901 Episodes:  85568\n",
      "SARSA_Agent, Average reward: 0.5429193798269013 Number of steps:  1.390834857362517 Episodes:  85847\n",
      "SARSA_Agent, Average reward: 0.5429179310104286 Number of steps:  1.3907548858893424 Episodes:  86013\n",
      "SARSA_Agent, Average reward: 0.5429830665738807 Number of steps:  1.3907446068197633 Episodes:  86220\n",
      "SARSA_Agent, Average reward: 0.543077012092808 Number of steps:  1.3907076317768905 Episodes:  86415\n",
      "SARSA_Agent, Average reward: 0.5431447470188279 Number of steps:  1.390744225241553 Episodes:  86627\n",
      "SARSA_Agent, Average reward: 0.5428275743115046 Number of steps:  1.390685908123958 Episodes:  86965\n",
      "SARSA_Agent, Average reward: 0.5427903672983068 Number of steps:  1.390772861627294 Episodes:  87286\n",
      "SARSA_Agent, Average reward: 0.5429543845222595 Number of steps:  1.3907581260421664 Episodes:  87558\n",
      "SARSA_Agent, Average reward: 0.5428825156831715 Number of steps:  1.3907870618104812 Episodes:  87833\n",
      "SARSA_Agent, Average reward: 0.5428620102214651 Number of steps:  1.3908574673480976 Episodes:  88050\n",
      "SARSA_Agent, Average reward: 0.5427995287293819 Number of steps:  1.3909506978430306 Episodes:  88272\n",
      "SARSA_Agent, Average reward: 0.5429361942405421 Number of steps:  1.3909768492377188 Episodes:  88550\n",
      "SARSA_Agent, Average reward: 0.5429534286100717 Number of steps:  1.3910103241513008 Episodes:  88724\n",
      "SARSA_Agent, Average reward: 0.5430398813003012 Number of steps:  1.391158221302999 Episodes:  88964\n",
      "SARSA_Agent, Average reward: 0.543157729625563 Number of steps:  1.3913101933806888 Episodes:  89254\n",
      "SARSA_Agent, Average reward: 0.5431956631084782 Number of steps:  1.3912703291790085 Episodes:  89465\n",
      "SARSA_Agent, Average reward: 0.543374313133227 Number of steps:  1.3913106476888952 Episodes:  89719\n",
      "SARSA_Agent, Average reward: 0.5435955631209461 Number of steps:  1.3913865803322096 Episodes:  89883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARSA_Agent, Average reward: 0.5436463475511676 Number of steps:  1.3913361805979256 Episodes:  90145\n",
      "SARSA_Agent, Average reward: 0.5438130642591609 Number of steps:  1.3913192600460258 Episodes:  90384\n",
      "SARSA_Agent, Average reward: 0.5438625529661016 Number of steps:  1.3912429378531073 Episodes:  90624\n",
      "SARSA_Agent, Average reward: 0.5440176114474409 Number of steps:  1.391326362135388 Episodes:  90850\n",
      "SARSA_Agent, Average reward: 0.5441696501131147 Number of steps:  1.3912341584484613 Episodes:  91058\n",
      "SARSA_Agent, Average reward: 0.544312806587246 Number of steps:  1.3911067799579537 Episodes:  91328\n",
      "SARSA_Agent, Average reward: 0.5444808743169399 Number of steps:  1.3911038251366121 Episodes:  91500\n",
      "SARSA_Agent, Average reward: 0.5445263754963131 Number of steps:  1.391083816920459 Episodes:  91676\n",
      "SARSA_Agent, Average reward: 0.5446314050305442 Number of steps:  1.391095458596926 Episodes:  91998\n",
      "SARSA_Agent, Average reward: 0.5447051432037783 Number of steps:  1.3908314918324018 Episodes:  92316\n",
      "SARSA_Agent, Average reward: 0.5447942673713563 Number of steps:  1.3908865903613155 Episodes:  92523\n",
      "SARSA_Agent, Average reward: 0.5448858979336526 Number of steps:  1.390761830809715 Episodes:  92724\n",
      "SARSA_Agent, Average reward: 0.5449430345020495 Number of steps:  1.3907004765951954 Episodes:  92951\n",
      "SARSA_Agent, Average reward: 0.5448491802223961 Number of steps:  1.3906945323139281 Episodes:  93257\n",
      "SARSA_Agent, Average reward: 0.5449188882829126 Number of steps:  1.3905339364580325 Episodes:  93513\n",
      "SARSA_Agent, Average reward: 0.544851348900718 Number of steps:  1.3904824893592056 Episodes:  93743\n",
      "SARSA_Agent, Average reward: 0.5451807869927005 Number of steps:  1.3905169294941369 Episodes:  93978\n",
      "SARSA_Agent, Average reward: 0.5452404193014472 Number of steps:  1.3907397190510546 Episodes:  94252\n",
      "SARSA_Agent, Average reward: 0.5453409968985847 Number of steps:  1.3907042223704127 Episodes:  94473\n",
      "SARSA_Agent, Average reward: 0.5453623708835893 Number of steps:  1.3908662681396675 Episodes:  94682\n",
      "SARSA_Agent, Average reward: 0.5452505609573672 Number of steps:  1.3908371696145458 Episodes:  94927\n",
      "SARSA_Agent, Average reward: 0.5453256153547154 Number of steps:  1.390948533969261 Episodes:  95189\n",
      "SARSA_Agent, Average reward: 0.5454974118238782 Number of steps:  1.391013684850263 Episodes:  95434\n",
      "SARSA_Agent, Average reward: 0.5456665655688842 Number of steps:  1.3910497087338025 Episodes:  95617\n",
      "SARSA_Agent, Average reward: 0.5457353340150677 Number of steps:  1.3910511926873552 Episodes:  95834\n",
      "SARSA_Agent, Average reward: 0.5458615304528891 Number of steps:  1.3911296199895888 Episodes:  96050\n",
      "SARSA_Agent, Average reward: 0.5459211237169098 Number of steps:  1.3913269334663176 Episodes:  96252\n",
      "SARSA_Agent, Average reward: 0.5459031348482335 Number of steps:  1.3913066014264388 Episodes:  96464\n",
      "SARSA_Agent, Average reward: 0.5458966187973348 Number of steps:  1.3914249058477839 Episodes:  96652\n",
      "SARSA_Agent, Average reward: 0.5460183474877975 Number of steps:  1.391499066114935 Episodes:  96907\n",
      "SARSA_Agent, Average reward: 0.5462440250535685 Number of steps:  1.391462007582001 Episodes:  97072\n",
      "SARSA_Agent, Average reward: 0.5461545578846727 Number of steps:  1.3914219037534312 Episodes:  97271\n",
      "SARSA_Agent, Average reward: 0.5460804432587728 Number of steps:  1.3913502975579726 Episodes:  97460\n",
      "SARSA_Agent, Average reward: 0.5461579399844434 Number of steps:  1.391421377983379 Episodes:  97708\n",
      "SARSA_Agent, Average reward: 0.5461594254717077 Number of steps:  1.3914535851832177 Episodes:  97889\n",
      "SARSA_Agent, Average reward: 0.5460723382577687 Number of steps:  1.3914824248599083 Episodes:  98150\n",
      "SARSA_Agent, Average reward: 0.546171056645988 Number of steps:  1.3915386962269907 Episodes:  98330\n",
      "SARSA_Agent, Average reward: 0.5462193401731259 Number of steps:  1.3916136430521306 Episodes:  98541\n",
      "SARSA_Agent, Average reward: 0.5462854251012146 Number of steps:  1.3918016194331984 Episodes:  98800\n",
      "SARSA_Agent, Average reward: 0.546228329681647 Number of steps:  1.3918377237709636 Episodes:  99041\n",
      "SARSA_Agent, Average reward: 0.5462586130475078 Number of steps:  1.391757666115969 Episodes:  99268\n",
      "SARSA_Agent, Average reward: 0.5463575493133332 Number of steps:  1.3918323849355558 Episodes:  99466\n",
      "SARSA_Agent, Average reward: 0.5465189714801263 Number of steps:  1.3917999097789584 Episodes:  99755\n",
      "SARSA_Agent, Average reward: 0.5465910568373888 Number of steps:  1.3916809185194075 Episodes:  99987\n",
      "SARSA_Agent, Average reward: 0.54662 Number of steps:  1.39166\n"
     ]
    }
   ],
   "source": [
    "# TRAINING LOOP BONE STRUCTURE...\n",
    "# I WROTE FOR YOU A RANDOM AGENT (THE RANDOM AGENT WILL BE SLOWER TO GIVE CHECKMATE THAN AN OPTIMISED ONE, \n",
    "# SO DON'T GET CONCERNED BY THE TIME IT TAKES), CHANGE WITH YOURS ...\n",
    "\n",
    "# Create a q model\n",
    "q_model = define_q_model(N_in, N_h, N_a)\n",
    "# And a frozen copy\n",
    "frozen_model = define_q_model(N_in, N_h, N_a)\n",
    "frozen_model.set_weights(q_model.get_weights())\n",
    "\n",
    "# Create an Adam optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate=eta, clipnorm=1.0)\n",
    "loss_function = keras.losses.Huber()\n",
    "\n",
    "#accumulate history for batch \n",
    "state_history               = []\n",
    "state_next_history          = []\n",
    "action_next_allowed_history = []\n",
    "action_history              = []\n",
    "rewards_history             = []\n",
    "done_history                = []\n",
    "\n",
    "R_save_sarsa = []\n",
    "N_moves_save_sarsa = []\n",
    "N_actions = 0\n",
    "for n in range(N_episodes):\n",
    "\n",
    "    epsilon_f = epsilon_0 / (1 + beta * n)   ## DECAYING EPSILON\n",
    "    Done=0                                   ## SET DONE TO ZERO (BEGINNING OF THE EPISODE)\n",
    "    i = 1                                    ## COUNTER FOR NUMBER OF ACTIONS\n",
    "    \n",
    "    S,X,allowed_a=env.Initialise_game()      ## INITIALISE GAME\n",
    "    \n",
    "    while Done==0:                           ## START THE EPISODE\n",
    "        ## THIS IS A RANDOM AGENT, CHANGE IT...\n",
    "        #a,_=np.where(allowed_a==1)\n",
    "        #a_agent=np.random.permutation(a)[0]\n",
    "        \n",
    "        #applying my model to the state\n",
    "        Qvalues = q_model(tf.expand_dims(X, 0), training=False)\n",
    "        \n",
    "        a_agent = EpsilonGreedy_Policy(Qvalues, epsilon_f, allowed_a)\n",
    "        S_next,X_next,allowed_a_next,R,Done=env.OneStep(a_agent)\n",
    "        \n",
    "        # Add new values to history\n",
    "        if (len(state_history) < H_size):\n",
    "            state_history.append(np.copy(X))\n",
    "            state_next_history.append(np.copy(X_next))\n",
    "            action_next_allowed_history.append(np.copy(allowed_a_next))\n",
    "            action_history.append(a_agent)\n",
    "            rewards_history.append(R)\n",
    "            done_history.append(Done)\n",
    "        # Reuse old history once buffers are full.\n",
    "        else:\n",
    "            state_history[N_actions % H_size]               = np.copy(X)\n",
    "            state_next_history[N_actions % H_size]          = np.copy(X_next)\n",
    "            action_next_allowed_history[N_actions % H_size] = np.copy(allowed_a_next)\n",
    "            action_history[N_actions % H_size]              = a_agent\n",
    "            rewards_history[N_actions % H_size]             = R\n",
    "            done_history[N_actions % H_size]                = Done\n",
    "        N_actions += 1\n",
    "        # Update model's variables.\n",
    "        if N_actions % update_after_actions == 0 and len(state_history) > batch_size:\n",
    "            for i in range(batches_per_training):\n",
    "                update_sarsa_model(\n",
    "                    q_model,\n",
    "                    frozen_model,\n",
    "                    optimizer, \n",
    "                    gamma, \n",
    "                    state_history, \n",
    "                    state_next_history,\n",
    "                    action_next_allowed_history,\n",
    "                    action_history, \n",
    "                    rewards_history, \n",
    "                    done_history,\n",
    "                    # Take a partial function fixing epsilon.\n",
    "                    epsilon_f)\n",
    "\n",
    "        # Update frozen model with current model\n",
    "        if N_actions % update_frozen_model_actions == 0:\n",
    "            frozen_model.set_weights(q_model.get_weights())\n",
    "            print('SARSA_Agent, Average reward:',np.mean(R_save_sarsa),'Number of steps: ',np.mean(N_moves_save_sarsa), 'Episodes: ', n)\n",
    "        ## THE EPISODE HAS ENDED, UPDATE...BE CAREFUL, THIS IS THE LAST STEP OF THE EPISODE\n",
    "        if Done==1:\n",
    "            # Keep a reward and moves history to make pretty graphs.\n",
    "            R_save_sarsa.append(R)\n",
    "            N_moves_save_sarsa.append(i)\n",
    "            break\n",
    "        # IF THE EPISODE IS NOT OVER...\n",
    "        else:\n",
    "            ## ONLY TO PUT SUMETHING\n",
    "            PIPPO=1            \n",
    "        # NEXT STATE AND CO. BECOME ACTUAL STATE...     \n",
    "        S=np.copy(S_next)\n",
    "        X=np.copy(X_next)\n",
    "        allowed_a=np.copy(allowed_a_next)\n",
    "        \n",
    "        i += 1  # UPDATE COUNTER FOR NUMBER OF ACTIONS\n",
    "print('SARSA_Agent, Average reward:',np.mean(R_save_sarsa),'Number of steps: ',np.mean(N_moves_save_sarsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b288ad57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "R_ma_s = pd.DataFrame({'R': R_save_sarsa}).ewm(com=400).mean()\n",
    "\n",
    "plt.plot(R_ma_s, label=\"SARSA\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward per game\")\n",
    "plt.savefig(f\"s_rewards_{N_episodes}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768f65ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per game using an exponential average with 500 decay.\n",
    "N_ma_s = pd.DataFrame({'N': N_moves_save_sarsa}).ewm(com=400).mean()\n",
    "plt.plot(N_ma_s, label=\"SARSA Steps\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Steps\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"s_steps_{N_episodes}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
